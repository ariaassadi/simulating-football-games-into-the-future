{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c078666b",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa43b454-7b17-42fc-be8a-de1770ba3a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.animation import FuncAnimation\n",
    "import matplotlib.pyplot as plt\n",
    "from mplsoccer import Pitch\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "from settings import *\n",
    "from visualize_game import visualize_frame_prediction, visualize_game_snippet, visualize_offside_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e407f5",
   "metadata": {},
   "source": [
    "### General functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60749349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flip the coordinates to match the team direction\n",
    "def flip_xy_based_on_team_direction(frames_df):\n",
    "    # TODO: What do to with the ball?\n",
    "    for period in [1, 2]:\n",
    "        # Flip the x coordinates for the team attacking to the left\n",
    "        home_team_attacking_to_right = frames_df[(frames_df['period'] == period) & (frames_df['team'] == 'home_team')].iloc[0]['team_direction'] == 'right'\n",
    "        if home_team_attacking_to_right:\n",
    "            frames_df.loc[(frames_df['period'] == period) & (frames_df['team'] == 'away_team'), 'x'] = pitch_length - frames_df[(frames_df['period'] == period) & (frames_df['team'] == 'away_team')]['x']\n",
    "        else:\n",
    "            frames_df.loc[(frames_df['period'] == period) & (frames_df['team'] == 'home_team'), 'x'] = pitch_length - frames_df[(frames_df['period'] == period) & (frames_df['team'] == 'home_team')]['x']\n",
    "    return frames_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b00acdb",
   "metadata": {},
   "source": [
    "### Functions for adding features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb4fc19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the features x_future and y_future (the x and y coordinate of each player n frames into the future)\n",
    "def add_xy_future(frames_df, n=50):\n",
    "    # Shift the DataFrame by n frames for each player\n",
    "    future_df = frames_df.groupby(['team', 'jersey_number']).shift(-n)\n",
    "\n",
    "    # Merge the original DataFrame with the shifted DataFrame to get future coordinates\n",
    "    frames_df[['x_future', 'y_future']] = future_df[['x', 'y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b97713f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the features v_x and v_y (current velocity (m/s) in the x and y axis respectivly). delta_frames determines the time stamp\n",
    "def add_velocity_xy(frames_df, delta_frames=1):\n",
    "    # Create a copy of the DataFrame and shift it by delta_frames\n",
    "    past_df = frames_df.copy()\n",
    "    past_df['frame'] += delta_frames\n",
    "\n",
    "    # Merge the original DataFrame with the shifted DataFrame to get future coordinates\n",
    "    past_coordinates = frames_df.merge(past_df, on=['frame', 'team', 'jersey_number'], suffixes=('', '_past'), how='outer')\n",
    "\n",
    "    # Use the past coordinates to calculate the current velocity\n",
    "    v_x = (frames_df['x'] - past_coordinates['x_past']) * FPS / delta_frames\n",
    "    v_y = (frames_df['y'] - past_coordinates['y_past']) * FPS / delta_frames\n",
    "    \n",
    "    # The player can't surely run faster than Usian Bolt's max speed \n",
    "    usain_bolt_max_speed = 13\n",
    "    frames_df['v_x'] = v_x.clip(lower=-usain_bolt_max_speed, upper=usain_bolt_max_speed)\n",
    "    frames_df['v_y'] = v_y.clip(lower=-usain_bolt_max_speed, upper=usain_bolt_max_speed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8575c9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the features a_x and a_y (current velocity (m/sÂ²) in the x and y axis respectivly). delta_frames determines the time stamp\n",
    "def add_acceleration_xy(frames_df, delta_frames=1):\n",
    "    # Create a copy of the DataFrame and shift it by delta_frames twice\n",
    "    past_df = frames_df.copy()\n",
    "    past_df['frame'] += delta_frames\n",
    "    more_past_df = frames_df.copy()\n",
    "    more_past_df['frame'] += 2 * delta_frames\n",
    "\n",
    "    # Merge the original DataFrame with the shifted DataFrames to get past and future coordinates\n",
    "    past_coordinates = frames_df.merge(past_df, on=['frame', 'team', 'jersey_number'], suffixes=('', '_past'), how='outer')\n",
    "    more_past_coordinates = frames_df.merge(more_past_df, on=['frame', 'team', 'jersey_number'], suffixes=('', '_more_past'), how='outer')\n",
    "\n",
    "    # Use past and future coordinates to calculate current acceleration\n",
    "    a_x = ((frames_df['x'] - 2 * past_coordinates['x_past'] + more_past_coordinates['x_more_past']) * FPS / (delta_frames ** 2)).fillna(0)\n",
    "    a_y = ((frames_df['y'] - 2 * past_coordinates['y_past'] + more_past_coordinates['y_more_past']) * FPS / (delta_frames ** 2)).fillna(0)\n",
    "\n",
    "    # Clip acceleration values to reasonable limits\n",
    "    max_acceleration = 10  # This is a very high acceleration\n",
    "    frames_df['a_x'] = a_x.clip(lower=-max_acceleration, upper=max_acceleration)\n",
    "    frames_df['a_y'] = a_y.clip(lower=-max_acceleration, upper=max_acceleration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "239f9dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a vector indicating if the ball is in motion\n",
    "def add_ball_in_motion(frames_df):\n",
    "    # Initialize variables\n",
    "    ball_in_motion_vec = []\n",
    "    x_ball = 0\n",
    "    y_ball = 0\n",
    "    i = - 1\n",
    "\n",
    "    # For all objects in each frame\n",
    "    while (i < len(frames_df)-1):        \n",
    "        # Update i to be the last row in the next frame\n",
    "        objects_tracked = frames_df.iloc[i+1]['objects_tracked']\n",
    "        i += objects_tracked\n",
    "\n",
    "        # Determine if the ball is motion\n",
    "        ball_in_motion = False\n",
    "        # If the ball exists, it will surely be the last row\n",
    "        if frames_df.iloc[i]['team'] == 'ball':\n",
    "            # If either x_ball or y_ball has changed since the last recorded positions\n",
    "            if x_ball != frames_df.iloc[i]['x'] or y_ball != frames_df.iloc[i]['y']:\n",
    "                # Update varibles\n",
    "                x_ball = frames_df.iloc[i]['x']\n",
    "                y_ball = frames_df.iloc[i]['y']\n",
    "                ball_in_motion = True\n",
    "\n",
    "        # Store the result in ball_in_motion_vec\n",
    "        [ball_in_motion_vec.append(ball_in_motion) for _ in range(objects_tracked)]\n",
    "\n",
    "    # Add the new column based on the vector\n",
    "    frames_df['ball_in_motion'] = ball_in_motion_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "384f4d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a vector for determining which players that are standing behind the offside line\n",
    "def add_offside(frames_df):\n",
    "    # Create the empty column\n",
    "    frames_df[\"offside\"] = None\n",
    "\n",
    "    # Group the DataFrame by frame\n",
    "    grouped_frames = frames_df.groupby(\"frame\")\n",
    "\n",
    "    # Iterate over each unique frame\n",
    "    for frame, frame_df in grouped_frames:\n",
    "        # Ball has to exist in order for the calculation to work\n",
    "        if frame_df.iloc[-1]['team'] == 'ball':\n",
    "            # Find x_ball\n",
    "            x_ball = frame_df.iloc[-1]['x']\n",
    "        else:\n",
    "            # Setting ball to half way line will make the position of the ball irrelevant\n",
    "            x_ball = pitch_length / 2\n",
    "\n",
    "        # Find the x coordinates of each team\n",
    "        x_players_attacking_right = sorted(frame_df[frame_df[\"team_direction\"] == 'left']['x'].tolist())\n",
    "        x_players_attacking_left = sorted(frame_df[frame_df[\"team_direction\"] == 'right']['x'].tolist())\n",
    "\n",
    "        # Find offside for the team attacking to the right\n",
    "        if len(x_players_attacking_left) >= 2:\n",
    "            # Find the x of the second to last defender\n",
    "            x_second_to_last_defender = x_players_attacking_left[-2]\n",
    "\n",
    "            # The offside will be determined by the second to last defender, half way line, or ball\n",
    "            x_offside_line = max(x_second_to_last_defender, pitch_length / 2, x_ball)\n",
    "\n",
    "            # Determine which players that are standing behind the offside line\n",
    "            for x_player in x_players_attacking_right:\n",
    "                if x_player > x_offside_line:\n",
    "                    # Set 'offside' to value of x_offside_line\n",
    "                    frames_df.loc[(frames_df[\"frame\"] == frame) & (frames_df[\"team_direction\"] == 'left') & (frames_df[\"x\"] == x_player), \"offside\"] = x_offside_line\n",
    "\n",
    "        # Find offsides on the left side of the pitch\n",
    "        if len(x_players_attacking_right) >= 2:\n",
    "            # Find the x of the second to last defender\n",
    "            x_second_to_last_defender = x_players_attacking_right[1]\n",
    "\n",
    "            # The offside will be determined by the second to last defender, half way line, or ball\n",
    "            x_offside_line = min(x_second_to_last_defender, pitch_length / 2, x_ball)\n",
    "\n",
    "            # Determine which players that are standing behind the offside line\n",
    "            for x_player in x_players_attacking_left:\n",
    "                if x_player < x_offside_line:\n",
    "                    # Set 'offside' to value of x_offside_line\n",
    "                    frames_df.loc[(frames_df[\"frame\"] == frame) & (frames_df[\"team_direction\"] == 'right') & (frames_df[\"x\"] == x_player), \"offside\"] = x_offside_line\n",
    "\n",
    "# TODO: Examine that this is correct\n",
    "# Create a small df for testing\n",
    "# small_frames_df = frames_dfs[0].head(1000).copy()\n",
    "# add_offside(small_frames_df)\n",
    "# offsides_df = small_frames_df.groupby(\"frame\").filter(lambda x: x['offside'].notna().any()).copy()\n",
    "# offsides_df[[\"team_name\", \"player\", \"jersey_number\", \"x\", \"y\", \"second\", \"frame\"]]\n",
    "# frame = 1546\n",
    "# visualize_offside_frame(offsides_df, frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ff5c6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_frames_df = frames_dfs[0].head(40000).copy()\n",
    "add_offside(small_frames_df)\n",
    "visualize_game_snippet(small_frames_df, 0, 1500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b196e924",
   "metadata": {},
   "source": [
    "### Predictive models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c25da76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NAIVE: Always predict that all players will stand still\n",
    "# The calculations are based on x, y\n",
    "def predict_two_seconds_naive_static(frames_df):\n",
    "    frames_df['x_future_pred'] = frames_df['x']\n",
    "    frames_df['y_future_pred'] = frames_df['y']\n",
    "\n",
    "# NAIVE: Always predict that all players will continue with the same velocity\n",
    "# The calculations are based on x, y, v_x, and v_y\n",
    "def predict_two_seconds_naive_velocity(frames_df):\n",
    "    frames_df['x_future_pred'] = frames_df['x'] + frames_df['v_x'] * seconds_into_the_future\n",
    "    frames_df['y_future_pred'] = frames_df['y'] + frames_df['v_y'] * seconds_into_the_future\n",
    "\n",
    "# Make a prediction with a LSTM neural network model\n",
    "def predict_two_seconds_LSTM(frames_df):\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851f2328",
   "metadata": {},
   "source": [
    "### Calculate error loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ec3286b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column for distance wrongly predicted (in metres) for each object. Also return average_pred_error\n",
    "def total_error_loss(frames_df, include_ball=False, ball_has_to_be_in_motion=False):\n",
    "    # Create a vector with the Eculidian distance between the true position and the predicted position\n",
    "    frames_df['pred_error'] = round(((frames_df['x_future_pred'] - frames_df['x_future'])**2 + (frames_df['y_future_pred'] - frames_df['y_future'])**2)**0.5, 2)\n",
    "    \n",
    "    # If ball_has_to_be_in_motion, filter to only look at frames where the ball is in motion\n",
    "    if ball_has_to_be_in_motion:\n",
    "        frames_df = frames_df[frames_df[\"ball_in_motion\"]].copy()\n",
    "\n",
    "    # Calculate average pred_error\n",
    "    if include_ball:\n",
    "        average_pred_error = frames_df['pred_error'].mean()\n",
    "    else:\n",
    "        # Calculate average pred_error for all entries where team != 'ball'\n",
    "        average_pred_error = frames_df[frames_df['team'] != 'ball']['pred_error'].mean()\n",
    "\n",
    "    return round(average_pred_error, 2)\n",
    "\n",
    "# Find a frame with approximatly the same error as the average_pred_error, with an interval\n",
    "def find_frame_with_average_error(frames_df, average_pred_error, error_margin):\n",
    "    # For all frames\n",
    "    frames = frames_df['frame'].unique()\n",
    "    for frame in frames:\n",
    "        current_error = frames_df[frames_df['frame'] == frame]['pred_error'].mean()\n",
    "        # If the current error is within the error_margin,\n",
    "        if (current_error >= average_pred_error - error_margin) and (current_error <= average_pred_error + error_margin):\n",
    "            # Return the result\n",
    "            return frame\n",
    "\n",
    "    # If no frame was found\n",
    "    print(f\"No frame found within the error margin of {error_margin}\")\n",
    "    return None\n",
    "\n",
    "# Calculate the average error for a list of games\n",
    "def calculate_average_error(frames_dfs, predict_function, include_ball, ball_has_to_be_in_motion):\n",
    "    errors = []  # Initialize a list to store errors for each game\n",
    "\n",
    "    # Iterate over each DataFrame in frames_dfs for testing the model\n",
    "    for frames_df in frames_dfs:\n",
    "        # Predict game outcome\n",
    "        predict_function(frames_df)\n",
    "        # Calculate and append the error for the predicted outcome\n",
    "        error = total_error_loss(frames_df, include_ball, ball_has_to_be_in_motion)\n",
    "        errors.append(error)\n",
    "\n",
    "    # Calculate the average error\n",
    "    avg_error = round(sum(errors) / len(errors), 2)\n",
    "    return avg_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fc772d-0f36-40b9-bc33-a5e0ad294428",
   "metadata": {},
   "source": [
    "### Functions for processing and loading frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f65348d3-1b48-4f4a-bfda-674bf8147126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the unprocessed/ frames, and store the results to the processed/ fodler\n",
    "def process_frames():\n",
    "    # Load frames_df\n",
    "    for selected_season in seasons:\n",
    "        for selected_competition in competitions:\n",
    "            # Define paths\n",
    "            DATA_FOLDER_UNPROCESSED = f\"{DATA_LOCAL_FOLDER}/data/{selected_season}/{selected_competition}/unprocessed\"\n",
    "            FOLDER_OUT = f\"{DATA_LOCAL_FOLDER}/data/{selected_season}/{selected_competition}/processed\"\n",
    "            \n",
    "            # Create output folder if not exists\n",
    "            if not os.path.exists(FOLDER_OUT):\n",
    "                    os.makedirs(FOLDER_OUT)\n",
    "\n",
    "            # Find all frames parquet files\n",
    "            match_paths = glob.glob(os.path.join(DATA_FOLDER_UNPROCESSED, \"*.parquet\"))\n",
    "\n",
    "            # Extract IDs without the \".parquet\" extension\n",
    "            # TODO: Uncomment this line in production\n",
    "            # match_ids = [os.path.splitext(os.path.basename(path))[0] for path in match_paths]\n",
    "            match_ids = [os.path.splitext(os.path.basename(path))[0] for path in match_paths][0:2]\n",
    "\n",
    "            # For all matches\n",
    "            for match_id in match_ids:\n",
    "                # Convert parquet file to a DataFrame\n",
    "                file_path_match = f\"{DATA_FOLDER_UNPROCESSED}/{match_id}.parquet\"\n",
    "                frames_df = pd.read_parquet(file_path_match)\n",
    "\n",
    "                # Process frames_df\n",
    "                flip_xy_based_on_team_direction(frames_df)\n",
    "                add_velocity_xy(frames_df, 1)\n",
    "                add_acceleration_xy(frames_df, 1)\n",
    "                add_xy_future(frames_df, FPS*seconds_into_the_future)\n",
    "                add_ball_in_motion(frames_df)\n",
    "\n",
    "                # Add match_id\n",
    "                frames_df[\"match_id\"] = match_id\n",
    "\n",
    "                # Convert DataFrame to a parquet file\n",
    "                frames_df.to_parquet(f\"{FOLDER_OUT}/{match_id}.parquet\")\n",
    "\n",
    "# Load the processed/frames\n",
    "def load_all_processed_frames():\n",
    "    # Create DataFrame for storing all frames\n",
    "    frames_dfs = []\n",
    "    # Load frames_df\n",
    "    for selected_season in seasons:\n",
    "        for selected_competition in competitions:\n",
    "            # Define paths\n",
    "            DATA_FOLDER_PROCESSED = f\"{DATA_LOCAL_FOLDER}/data/{selected_season}/{selected_competition}/processed\"\n",
    "\n",
    "            # Find all frames parquet files\n",
    "            match_paths = glob.glob(os.path.join(DATA_FOLDER_PROCESSED, \"*.parquet\"))\n",
    "\n",
    "            # Extract IDs without the \".parquet\" extension\n",
    "            match_ids = [os.path.splitext(os.path.basename(path))[0] for path in match_paths]\n",
    "\n",
    "            # For all matches\n",
    "            for match_id in match_ids:\n",
    "                # Convert parquet file to a DataFrame\n",
    "                file_path_match = f\"{DATA_FOLDER_PROCESSED}/{match_id}.parquet\"\n",
    "                frames_df = pd.read_parquet(file_path_match)\n",
    "                \n",
    "                # Append the DataFrame to frames_dfs\n",
    "                frames_dfs.append(frames_df)\n",
    "\n",
    "    return frames_dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef596153",
   "metadata": {},
   "source": [
    "## Run an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "873cbc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load frames_df\n",
    "# process_frames()\n",
    "frames_dfs = load_all_processed_frames()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "896c5a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model error naive static: 4.04\n",
      "Model error naive velocity: 2.17\n"
     ]
    }
   ],
   "source": [
    "# Test model 1\n",
    "error_naive_static = calculate_average_error(frames_dfs, predict_two_seconds_naive_static, include_ball=False, ball_has_to_be_in_motion=True)\n",
    "print(f\"Model error naive static: {error_naive_static}\")\n",
    "\n",
    "# Test model 2\n",
    "error_naive_velocity = calculate_average_error(frames_dfs, predict_two_seconds_naive_velocity, include_ball=False, ball_has_to_be_in_motion=True)\n",
    "print(f\"Model error naive velocity: {error_naive_velocity}\")\n",
    "\n",
    "# Visualize one frame with average error for the first model, together with the corresponding frame for the second model\n",
    "frames_df = frames_dfs[0]\n",
    "frame_with_average_error = find_frame_with_average_error(frames_df, error_naive_static, error_margin=0.1)\n",
    "visualize_frame_prediction(frames_df, frame_with_average_error, \"naive_static\")\n",
    "visualize_frame_prediction(frames_df, frame_with_average_error, \"naive_velocity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9692b2d",
   "metadata": {},
   "source": [
    "### Print results for different models and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0866720c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the prediction functions (models) you want to test\n",
    "# prediction_functions = {\n",
    "#     \"Naive Static\": predict_two_seconds_naive_static,\n",
    "#     \"Naive Velocity\": predict_two_seconds_naive_velocity\n",
    "# }\n",
    "\n",
    "# # Initialize an empty list to store the results\n",
    "# results = []\n",
    "\n",
    "# # Define the combinations of include_ball and ball_has_to_be_in_motion\n",
    "# combinations = [(True, True), (True, False), (False, True), (False, False)]\n",
    "\n",
    "# # Load all processed frames\n",
    "# frames_dfs = load_all_processed_frames()\n",
    "\n",
    "# # Loop through each combination\n",
    "# for include_ball, ball_has_to_be_in_motion in combinations:\n",
    "#     # Add the combination of parameters\n",
    "#     result = {\"Include Ball\": include_ball, \"Ball in Motion\": ball_has_to_be_in_motion}\n",
    "#     # Loop through each prediction function (model)\n",
    "#     for model_name, predict_function in prediction_functions.items():\n",
    "#         # Calculate average error for the current prediction function (model)\n",
    "#         avg_error = calculate_average_error(frames_dfs, predict_function, include_ball, ball_has_to_be_in_motion)\n",
    "#         result[model_name] = avg_error\n",
    "    \n",
    "#     # Append the results to the list\n",
    "#     results.append(result)\n",
    "\n",
    "# # Create a DataFrame from the list of results\n",
    "# results_df = pd.DataFrame(results)\n",
    "\n",
    "# # Print the results DataFrame\n",
    "# results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b944b0c",
   "metadata": {},
   "source": [
    "### Store df as xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b157f06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Store frames_df as xslx\n",
    "# frames_df_head = frames_df.head(19979)\n",
    "\n",
    "# # Specify the file path for the Excel file\n",
    "# excel_file_path = f\"{DATA_LOCAL_FOLDER}/Brommapojkarna_vs_Sirius.xlsx\"\n",
    "\n",
    "# # Write the DataFrame to an Excel file\n",
    "# frames_df_head.to_excel(excel_file_path, index=False)\n",
    "\n",
    "# print(f\"DataFrame saved to {excel_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "61c9fe0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BK HÃ¤cken', 'Varbergs BoIS FC', 'IF Elfsborg', 'Kalmar FF', 'GIF Sundsvall', 'Helsingborgs IF', 'Ãsters IF', 'MjÃ¤llby AIF', 'IFK NorrkÃ¶ping FK', 'MalmÃ¶ FF', 'AIK', 'IFK VÃ¤rnamo', 'IFK GÃ¶teborg', 'DjurgÃ¥rden', 'IK Sirius FK', 'Hammarby', 'Degerfors IF']\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "import json\n",
    "import os\n",
    "\n",
    "DATA_FOLDER_UNPROCESSED = f\"{DATA_LOCAL_FOLDER}/signality/2022/Allsvenskan/\"\n",
    "\n",
    "# Find all frames parquet files\n",
    "match_paths = glob.glob(os.path.join(DATA_FOLDER_UNPROCESSED, \"*.json\"))\n",
    "\n",
    "# Initialize a set to store unique team names\n",
    "unique_team_names = set()\n",
    "\n",
    "# Iterate over each JSON file\n",
    "for json_file in match_paths:\n",
    "    # Load JSON data\n",
    "    with open(json_file, 'r') as f:\n",
    "        data = json.load(f, object_pairs_hook=OrderedDict)\n",
    "\n",
    "    # Extract team_home_name\n",
    "    team_home_name = data.get('team_home_name')\n",
    "    \n",
    "    # Add team_home_name to the set of unique team names\n",
    "    if team_home_name:\n",
    "        unique_team_names.add(team_home_name)\n",
    "\n",
    "# Convert set to list for easier manipulation if needed\n",
    "unique_team_names_list = list(unique_team_names)\n",
    "\n",
    "# Print unique team names\n",
    "print(unique_team_names_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "My Python",
   "language": "python",
   "name": "my_python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
