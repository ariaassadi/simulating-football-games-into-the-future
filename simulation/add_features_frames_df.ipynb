{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c078666b",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa43b454-7b17-42fc-be8a-de1770ba3a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.animation import FuncAnimation\n",
    "import matplotlib.pyplot as plt\n",
    "from mplsoccer import Pitch\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "from settings import *\n",
    "from visualize_game import visualize_frame_prediction, visualize_game_snippet, visualize_offside_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e407f5",
   "metadata": {},
   "source": [
    "### General functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60749349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flip the coordinates to match the team direction\n",
    "def flip_xy_based_on_team_direction(frames_df):\n",
    "    # TODO: What do to with the ball?\n",
    "    for period in [1, 2]:\n",
    "        # Flip the x coordinates for the team attacking to the left\n",
    "        home_team_attacking_to_right = frames_df[(frames_df['period'] == period) & (frames_df['team'] == 'home_team')].iloc[0]['team_direction'] == 'right'\n",
    "        if home_team_attacking_to_right:\n",
    "            frames_df.loc[(frames_df['period'] == period) & (frames_df['team'] == 'away_team'), 'x'] = pitch_length - frames_df[(frames_df['period'] == period) & (frames_df['team'] == 'away_team')]['x']\n",
    "        else:\n",
    "            frames_df.loc[(frames_df['period'] == period) & (frames_df['team'] == 'home_team'), 'x'] = pitch_length - frames_df[(frames_df['period'] == period) & (frames_df['team'] == 'home_team')]['x']\n",
    "    return frames_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b00acdb",
   "metadata": {},
   "source": [
    "### Functions for adding features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb4fc19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the features x_future and y_future (the x and y coordinate of each player n frames into the future)\n",
    "def add_xy_future(frames_df, n=50):\n",
    "    # Shift the DataFrame by n frames for each player\n",
    "    future_df = frames_df.groupby(['team', 'jersey_number']).shift(-n)\n",
    "\n",
    "    # Merge the original DataFrame with the shifted DataFrame to get future coordinates\n",
    "    frames_df[['x_future', 'y_future']] = future_df[['x', 'y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b97713f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the features v_x and v_y (current velocity (m/s) in the x and y axis respectivly). delta_frames determines the time stamp\n",
    "def add_velocity_xy(frames_df, delta_frames=1):\n",
    "    # Create a copy of the DataFrame and shift it by delta_frames\n",
    "    past_df = frames_df.copy()\n",
    "    past_df['frame'] += delta_frames\n",
    "\n",
    "    # Merge the original DataFrame with the shifted DataFrame to get future coordinates\n",
    "    past_coordinates = frames_df.merge(past_df, on=['frame', 'team', 'jersey_number'], suffixes=('', '_past'), how='outer')\n",
    "\n",
    "    # Use the past coordinates to calculate the current velocity\n",
    "    v_x = (frames_df['x'] - past_coordinates['x_past']) * FPS / delta_frames\n",
    "    v_y = (frames_df['y'] - past_coordinates['y_past']) * FPS / delta_frames\n",
    "    \n",
    "    # The player can't surely run faster than Usian Bolt's max speed \n",
    "    usain_bolt_max_speed = 13\n",
    "    frames_df['v_x'] = v_x.clip(lower=-usain_bolt_max_speed, upper=usain_bolt_max_speed)\n",
    "    frames_df['v_y'] = v_y.clip(lower=-usain_bolt_max_speed, upper=usain_bolt_max_speed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8575c9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the features a_x and a_y (current velocity (m/s²) in the x and y axis respectivly). delta_frames determines the time stamp\n",
    "def add_acceleration_xy(frames_df, delta_frames=1):\n",
    "    # Create a copy of the DataFrame and shift it by delta_frames twice\n",
    "    past_df = frames_df.copy()\n",
    "    past_df['frame'] += delta_frames\n",
    "    more_past_df = frames_df.copy()\n",
    "    more_past_df['frame'] += 2 * delta_frames\n",
    "\n",
    "    # Merge the original DataFrame with the shifted DataFrames to get past and future coordinates\n",
    "    past_coordinates = frames_df.merge(past_df, on=['frame', 'team', 'jersey_number'], suffixes=('', '_past'), how='outer')\n",
    "    more_past_coordinates = frames_df.merge(more_past_df, on=['frame', 'team', 'jersey_number'], suffixes=('', '_more_past'), how='outer')\n",
    "\n",
    "    # Use past and future coordinates to calculate current acceleration\n",
    "    a_x = ((frames_df['x'] - 2 * past_coordinates['x_past'] + more_past_coordinates['x_more_past']) * FPS / (delta_frames ** 2)).fillna(0)\n",
    "    a_y = ((frames_df['y'] - 2 * past_coordinates['y_past'] + more_past_coordinates['y_more_past']) * FPS / (delta_frames ** 2)).fillna(0)\n",
    "\n",
    "    # Clip acceleration values to reasonable limits\n",
    "    max_acceleration = 10  # This is a very high acceleration\n",
    "    frames_df['a_x'] = a_x.clip(lower=-max_acceleration, upper=max_acceleration)\n",
    "    frames_df['a_y'] = a_y.clip(lower=-max_acceleration, upper=max_acceleration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "239f9dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a vector indicating if the ball is in motion\n",
    "def add_ball_in_motion(frames_df):\n",
    "    # Initialize variables\n",
    "    ball_in_motion_vec = []\n",
    "    x_ball = 0\n",
    "    y_ball = 0\n",
    "    i = - 1\n",
    "\n",
    "    # For all objects in each frame\n",
    "    while (i < len(frames_df)-1):        \n",
    "        # Update i to be the last row in the next frame\n",
    "        objects_tracked = frames_df.iloc[i+1]['objects_tracked']\n",
    "        i += objects_tracked\n",
    "\n",
    "        # Determine if the ball is motion\n",
    "        ball_in_motion = False\n",
    "        # If the ball exists, it will surely be the last row\n",
    "        if frames_df.iloc[i]['team'] == 'ball':\n",
    "            # If either x_ball or y_ball has changed since the last recorded positions\n",
    "            if x_ball != frames_df.iloc[i]['x'] or y_ball != frames_df.iloc[i]['y']:\n",
    "                # Update varibles\n",
    "                x_ball = frames_df.iloc[i]['x']\n",
    "                y_ball = frames_df.iloc[i]['y']\n",
    "                ball_in_motion = True\n",
    "\n",
    "        # Store the result in ball_in_motion_vec\n",
    "        [ball_in_motion_vec.append(ball_in_motion) for _ in range(objects_tracked)]\n",
    "\n",
    "    # Add the new column based on the vector\n",
    "    frames_df['ball_in_motion'] = ball_in_motion_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "384f4d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a vector for determining which players that are standing behind the offside line\n",
    "def add_offside(frames_df):\n",
    "    # Create the empty column\n",
    "    frames_df[\"offside\"] = None\n",
    "\n",
    "    # Group the DataFrame by frame\n",
    "    grouped_frames = frames_df.groupby(\"frame\")\n",
    "\n",
    "    # Iterate over each unique frame\n",
    "    for frame, frame_df in grouped_frames:\n",
    "        # Ball has to exist in order for the calculation to work\n",
    "        if frame_df.iloc[-1]['team'] == 'ball':\n",
    "            # Find x_ball\n",
    "            x_ball = frame_df.iloc[-1]['x']\n",
    "        else:\n",
    "            # Setting ball to half way line will make the position of the ball irrelevant\n",
    "            x_ball = pitch_length / 2\n",
    "\n",
    "        # Find the x coordinates of each team\n",
    "        x_players_attacking_right = sorted(frame_df[frame_df[\"team_direction\"] == 'left']['x'].tolist())\n",
    "        x_players_attacking_left = sorted(frame_df[frame_df[\"team_direction\"] == 'right']['x'].tolist())\n",
    "\n",
    "        # Find offside for the team attacking to the right\n",
    "        if len(x_players_attacking_left) >= 2:\n",
    "            # Find the x of the second to last defender\n",
    "            x_second_to_last_defender = x_players_attacking_left[-2]\n",
    "\n",
    "            # The offside will be determined by the second to last defender, half way line, or ball\n",
    "            x_offside_line = max(x_second_to_last_defender, pitch_length / 2, x_ball)\n",
    "\n",
    "            # Determine which players that are standing behind the offside line\n",
    "            for x_player in x_players_attacking_right:\n",
    "                if x_player > x_offside_line:\n",
    "                    # Set 'offside' to value of x_offside_line\n",
    "                    frames_df.loc[(frames_df[\"frame\"] == frame) & (frames_df[\"team_direction\"] == 'left') & (frames_df[\"x\"] == x_player), \"offside\"] = x_offside_line\n",
    "\n",
    "        # Find offsides on the left side of the pitch\n",
    "        if len(x_players_attacking_right) >= 2:\n",
    "            # Find the x of the second to last defender\n",
    "            x_second_to_last_defender = x_players_attacking_right[1]\n",
    "\n",
    "            # The offside will be determined by the second to last defender, half way line, or ball\n",
    "            x_offside_line = min(x_second_to_last_defender, pitch_length / 2, x_ball)\n",
    "\n",
    "            # Determine which players that are standing behind the offside line\n",
    "            for x_player in x_players_attacking_left:\n",
    "                if x_player < x_offside_line:\n",
    "                    # Set 'offside' to value of x_offside_line\n",
    "                    frames_df.loc[(frames_df[\"frame\"] == frame) & (frames_df[\"team_direction\"] == 'right') & (frames_df[\"x\"] == x_player), \"offside\"] = x_offside_line\n",
    "\n",
    "# TODO: Examine that this is correct\n",
    "# Create a small df for testing\n",
    "# small_frames_df = frames_dfs[0].head(1000).copy()\n",
    "# add_offside(small_frames_df)\n",
    "# offsides_df = small_frames_df.groupby(\"frame\").filter(lambda x: x['offside'].notna().any()).copy()\n",
    "# offsides_df[[\"team_name\", \"player\", \"jersey_number\", \"x\", \"y\", \"second\", \"frame\"]]\n",
    "# frame = 1546\n",
    "# visualize_offside_frame(offsides_df, frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ff5c6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_frames_df = frames_dfs[0].head(40000).copy()\n",
    "add_offside(small_frames_df)\n",
    "visualize_game_snippet(small_frames_df, 0, 1500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b196e924",
   "metadata": {},
   "source": [
    "### Predictive models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c25da76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NAIVE: Always predict that all players will stand still\n",
    "# The calculations are based on x, y\n",
    "def predict_two_seconds_naive_static(frames_df):\n",
    "    frames_df['x_future_pred'] = frames_df['x']\n",
    "    frames_df['y_future_pred'] = frames_df['y']\n",
    "\n",
    "# NAIVE: Always predict that all players will continue with the same velocity\n",
    "# The calculations are based on x, y, v_x, and v_y\n",
    "def predict_two_seconds_naive_velocity(frames_df):\n",
    "    frames_df['x_future_pred'] = frames_df['x'] + frames_df['v_x'] * seconds_into_the_future\n",
    "    frames_df['y_future_pred'] = frames_df['y'] + frames_df['v_y'] * seconds_into_the_future\n",
    "\n",
    "# Make a prediction with a LSTM neural network model\n",
    "def predict_two_seconds_LSTM(frames_df):\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851f2328",
   "metadata": {},
   "source": [
    "### Calculate error loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ec3286b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column for distance wrongly predicted (in metres) for each object. Also return average_pred_error\n",
    "def total_error_loss(frames_df, include_ball=False, ball_has_to_be_in_motion=False):\n",
    "    # Create a vector with the Eculidian distance between the true position and the predicted position\n",
    "    frames_df['pred_error'] = round(((frames_df['x_future_pred'] - frames_df['x_future'])**2 + (frames_df['y_future_pred'] - frames_df['y_future'])**2)**0.5, 2)\n",
    "    \n",
    "    # If ball_has_to_be_in_motion, filter to only look at frames where the ball is in motion\n",
    "    if ball_has_to_be_in_motion:\n",
    "        frames_df = frames_df[frames_df[\"ball_in_motion\"]].copy()\n",
    "\n",
    "    # Calculate average pred_error\n",
    "    if include_ball:\n",
    "        average_pred_error = frames_df['pred_error'].mean()\n",
    "    else:\n",
    "        # Calculate average pred_error for all entries where team != 'ball'\n",
    "        average_pred_error = frames_df[frames_df['team'] != 'ball']['pred_error'].mean()\n",
    "\n",
    "    return round(average_pred_error, 2)\n",
    "\n",
    "# Find a frame with approximatly the same error as the average_pred_error, with an interval\n",
    "def find_frame_with_average_error(frames_df, average_pred_error, error_margin):\n",
    "    # For all frames\n",
    "    frames = frames_df['frame'].unique()\n",
    "    for frame in frames:\n",
    "        current_error = frames_df[frames_df['frame'] == frame]['pred_error'].mean()\n",
    "        # If the current error is within the error_margin,\n",
    "        if (current_error >= average_pred_error - error_margin) and (current_error <= average_pred_error + error_margin):\n",
    "            # Return the result\n",
    "            return frame\n",
    "\n",
    "    # If no frame was found\n",
    "    print(f\"No frame found within the error margin of {error_margin}\")\n",
    "    return None\n",
    "\n",
    "# Calculate the average error for a list of games\n",
    "def calculate_average_error(frames_dfs, predict_function, include_ball, ball_has_to_be_in_motion):\n",
    "    errors = []  # Initialize a list to store errors for each game\n",
    "\n",
    "    # Iterate over each DataFrame in frames_dfs for testing the model\n",
    "    for frames_df in frames_dfs:\n",
    "        # Predict game outcome\n",
    "        predict_function(frames_df)\n",
    "        # Calculate and append the error for the predicted outcome\n",
    "        error = total_error_loss(frames_df, include_ball, ball_has_to_be_in_motion)\n",
    "        errors.append(error)\n",
    "\n",
    "    # Calculate the average error\n",
    "    avg_error = round(sum(errors) / len(errors), 2)\n",
    "    return avg_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fc772d-0f36-40b9-bc33-a5e0ad294428",
   "metadata": {},
   "source": [
    "### Functions for processing and loading frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f65348d3-1b48-4f4a-bfda-674bf8147126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the unprocessed/ frames, and store the results to the processed/ fodler\n",
    "def process_frames():\n",
    "    # Load frames_df\n",
    "    for selected_season in seasons:\n",
    "        for selected_competition in competitions:\n",
    "            # Define paths\n",
    "            DATA_FOLDER_UNPROCESSED = f\"{DATA_LOCAL_FOLDER}/data/{selected_season}/{selected_competition}/unprocessed\"\n",
    "            FOLDER_OUT = f\"{DATA_LOCAL_FOLDER}/data/{selected_season}/{selected_competition}/processed\"\n",
    "            \n",
    "            # Create output folder if not exists\n",
    "            if not os.path.exists(FOLDER_OUT):\n",
    "                    os.makedirs(FOLDER_OUT)\n",
    "\n",
    "            # Find all frames parquet files\n",
    "            match_paths = glob.glob(os.path.join(DATA_FOLDER_UNPROCESSED, \"*.parquet\"))\n",
    "\n",
    "            # Extract IDs without the \".parquet\" extension\n",
    "            # TODO: Uncomment this line in production\n",
    "            # match_ids = [os.path.splitext(os.path.basename(path))[0] for path in match_paths]\n",
    "            match_ids = [os.path.splitext(os.path.basename(path))[0] for path in match_paths][0:2]\n",
    "\n",
    "            # For all matches\n",
    "            for match_id in match_ids:\n",
    "                # Convert parquet file to a DataFrame\n",
    "                file_path_match = f\"{DATA_FOLDER_UNPROCESSED}/{match_id}.parquet\"\n",
    "                frames_df = pd.read_parquet(file_path_match)\n",
    "\n",
    "                # Process frames_df\n",
    "                flip_xy_based_on_team_direction(frames_df)\n",
    "                add_velocity_xy(frames_df, 1)\n",
    "                add_acceleration_xy(frames_df, 1)\n",
    "                add_xy_future(frames_df, FPS*seconds_into_the_future)\n",
    "                add_ball_in_motion(frames_df)\n",
    "\n",
    "                # Add match_id\n",
    "                frames_df[\"match_id\"] = match_id\n",
    "\n",
    "                # Convert DataFrame to a parquet file\n",
    "                frames_df.to_parquet(f\"{FOLDER_OUT}/{match_id}.parquet\")\n",
    "\n",
    "# Load the processed/frames\n",
    "def load_all_processed_frames():\n",
    "    # Create DataFrame for storing all frames\n",
    "    frames_dfs = []\n",
    "    # Load frames_df\n",
    "    for selected_season in seasons:\n",
    "        for selected_competition in competitions:\n",
    "            # Define paths\n",
    "            DATA_FOLDER_PROCESSED = f\"{DATA_LOCAL_FOLDER}/data/{selected_season}/{selected_competition}/processed\"\n",
    "\n",
    "            # Find all frames parquet files\n",
    "            match_paths = glob.glob(os.path.join(DATA_FOLDER_PROCESSED, \"*.parquet\"))\n",
    "\n",
    "            # Extract IDs without the \".parquet\" extension\n",
    "            match_ids = [os.path.splitext(os.path.basename(path))[0] for path in match_paths]\n",
    "\n",
    "            # For all matches\n",
    "            for match_id in match_ids:\n",
    "                # Convert parquet file to a DataFrame\n",
    "                file_path_match = f\"{DATA_FOLDER_PROCESSED}/{match_id}.parquet\"\n",
    "                frames_df = pd.read_parquet(file_path_match)\n",
    "                \n",
    "                # Append the DataFrame to frames_dfs\n",
    "                frames_dfs.append(frames_df)\n",
    "\n",
    "    return frames_dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef596153",
   "metadata": {},
   "source": [
    "## Run an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "873cbc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load frames_df\n",
    "# process_frames()\n",
    "frames_dfs = load_all_processed_frames()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "896c5a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model error naive static: 4.04\n",
      "Model error naive velocity: 2.17\n"
     ]
    }
   ],
   "source": [
    "# Test model 1\n",
    "error_naive_static = calculate_average_error(frames_dfs, predict_two_seconds_naive_static, include_ball=False, ball_has_to_be_in_motion=True)\n",
    "print(f\"Model error naive static: {error_naive_static}\")\n",
    "\n",
    "# Test model 2\n",
    "error_naive_velocity = calculate_average_error(frames_dfs, predict_two_seconds_naive_velocity, include_ball=False, ball_has_to_be_in_motion=True)\n",
    "print(f\"Model error naive velocity: {error_naive_velocity}\")\n",
    "\n",
    "# Visualize one frame with average error for the first model, together with the corresponding frame for the second model\n",
    "frames_df = frames_dfs[0]\n",
    "frame_with_average_error = find_frame_with_average_error(frames_df, error_naive_static, error_margin=0.1)\n",
    "visualize_frame_prediction(frames_df, frame_with_average_error, \"naive_static\")\n",
    "visualize_frame_prediction(frames_df, frame_with_average_error, \"naive_velocity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9692b2d",
   "metadata": {},
   "source": [
    "### Print results for different models and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0866720c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the prediction functions (models) you want to test\n",
    "# prediction_functions = {\n",
    "#     \"Naive Static\": predict_two_seconds_naive_static,\n",
    "#     \"Naive Velocity\": predict_two_seconds_naive_velocity\n",
    "# }\n",
    "\n",
    "# # Initialize an empty list to store the results\n",
    "# results = []\n",
    "\n",
    "# # Define the combinations of include_ball and ball_has_to_be_in_motion\n",
    "# combinations = [(True, True), (True, False), (False, True), (False, False)]\n",
    "\n",
    "# # Load all processed frames\n",
    "# frames_dfs = load_all_processed_frames()\n",
    "\n",
    "# # Loop through each combination\n",
    "# for include_ball, ball_has_to_be_in_motion in combinations:\n",
    "#     # Add the combination of parameters\n",
    "#     result = {\"Include Ball\": include_ball, \"Ball in Motion\": ball_has_to_be_in_motion}\n",
    "#     # Loop through each prediction function (model)\n",
    "#     for model_name, predict_function in prediction_functions.items():\n",
    "#         # Calculate average error for the current prediction function (model)\n",
    "#         avg_error = calculate_average_error(frames_dfs, predict_function, include_ball, ball_has_to_be_in_motion)\n",
    "#         result[model_name] = avg_error\n",
    "    \n",
    "#     # Append the results to the list\n",
    "#     results.append(result)\n",
    "\n",
    "# # Create a DataFrame from the list of results\n",
    "# results_df = pd.DataFrame(results)\n",
    "\n",
    "# # Print the results DataFrame\n",
    "# results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b944b0c",
   "metadata": {},
   "source": [
    "### Store df as xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b157f06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Store frames_df as xslx\n",
    "# frames_df_head = frames_df.head(19979)\n",
    "\n",
    "# # Specify the file path for the Excel file\n",
    "# excel_file_path = f\"{DATA_LOCAL_FOLDER}/Brommapojkarna_vs_Sirius.xlsx\"\n",
    "\n",
    "# # Write the DataFrame to an Excel file\n",
    "# frames_df_head.to_excel(excel_file_path, index=False)\n",
    "\n",
    "# print(f\"DataFrame saved to {excel_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "61c9fe0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BK Häcken', 'Varbergs BoIS FC', 'IF Elfsborg', 'Kalmar FF', 'GIF Sundsvall', 'Helsingborgs IF', 'Östers IF', 'Mjällby AIF', 'IFK Norrköping FK', 'Malmö FF', 'AIK', 'IFK Värnamo', 'IFK Göteborg', 'Djurgården', 'IK Sirius FK', 'Hammarby', 'Degerfors IF']\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "import json\n",
    "import os\n",
    "\n",
    "DATA_FOLDER_UNPROCESSED = f\"{DATA_LOCAL_FOLDER}/signality/2022/Allsvenskan/\"\n",
    "\n",
    "# Find all frames parquet files\n",
    "match_paths = glob.glob(os.path.join(DATA_FOLDER_UNPROCESSED, \"*.json\"))\n",
    "\n",
    "# Initialize a set to store unique team names\n",
    "unique_team_names = set()\n",
    "\n",
    "# Iterate over each JSON file\n",
    "for json_file in match_paths:\n",
    "    # Load JSON data\n",
    "    with open(json_file, 'r') as f:\n",
    "        data = json.load(f, object_pairs_hook=OrderedDict)\n",
    "\n",
    "    # Extract team_home_name\n",
    "    team_home_name = data.get('team_home_name')\n",
    "    \n",
    "    # Add team_home_name to the set of unique team names\n",
    "    if team_home_name:\n",
    "        unique_team_names.add(team_home_name)\n",
    "\n",
    "# Convert set to list for easier manipulation if needed\n",
    "unique_team_names_list = list(unique_team_names)\n",
    "\n",
    "# Print unique team names\n",
    "print(unique_team_names_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "My Python",
   "language": "python",
   "name": "my_python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
