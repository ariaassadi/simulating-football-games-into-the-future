{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c078666b",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa43b454-7b17-42fc-be8a-de1770ba3a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import matplotlib.pyplot as plt\n",
    "from mplsoccer import Pitch\n",
    "# import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "\n",
    "\n",
    "from settings import *\n",
    "from visualize_game import visualize_frame_prediction, visualize_game_snippet, visualize_offside_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e407f5",
   "metadata": {},
   "source": [
    "### General functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60749349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flip the coordinates to match the 'team_direction'\n",
    "def flip_xy_based_on_team_direction(frames_df):\n",
    "    # Flip x and y whenever 'team_direction' is 'left'\n",
    "    frames_df.loc[(frames_df['team_direction'] == 'left'), 'x'] = pitch_length - frames_df['x']\n",
    "    frames_df.loc[(frames_df['team_direction'] == 'left'), 'y'] = pitch_width - frames_df['y']\n",
    "\n",
    "    # Always flip the ball\n",
    "    frames_df.loc[(frames_df['team_direction'] == 'ball'), 'x'] = pitch_length - frames_df['x']\n",
    "    frames_df.loc[(frames_df['team_direction'] == 'ball'), 'y'] = pitch_width - frames_df['y']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994e70be",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2035d40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_x_ball(frames_df):\n",
    "    # Create an 'x_ball' column with dtype float\n",
    "    x_ball = pd.Series(dtype=float, index=frames_df['frame'])\n",
    "\n",
    "    # Fill the values in 'x_ball' with the 'x' of the ball\n",
    "    ball_positions = frames_df.loc[frames_df['team'] == 'ball', ['frame', 'x']].set_index('frame')['x']\n",
    "    x_ball.update(ball_positions)\n",
    "\n",
    "    # Add the 'x_ball' column to the DataFrame\n",
    "    frames_df[\"x_ball\"] = x_ball.values\n",
    "\n",
    "def add_x_ball_prev(frames_df, frames_to_shift=1):\n",
    "    # Create an 'x_ball_prev' column with dtype float\n",
    "    x_ball = pd.Series(dtype=float, index=frames_df['frame'])\n",
    "    \n",
    "    # Shift the coordinates one frame\n",
    "    ball_positions = frames_df.loc[frames_df['team'] == 'ball', ['frame', 'x']].set_index('frame')['x'].shift(frames_to_shift)\n",
    "    x_ball.update(ball_positions)\n",
    "\n",
    "    # Add the 'x_ball_prev' column to the DataFrame\n",
    "    frames_df[\"x_ball_prev\"] = x_ball.values\n",
    "\n",
    "def add_y_ball(frames_df):\n",
    "    # Create a 'y_ball' column with dtype float\n",
    "    y_ball = pd.Series(dtype=float, index=frames_df['frame'])\n",
    "\n",
    "    # Fill the values in 'y_ball' with the 'y' of the ball\n",
    "    ball_positions = frames_df.loc[frames_df['team'] == 'ball', ['frame', 'y']].set_index('frame')['y']\n",
    "    y_ball.update(ball_positions)\n",
    "\n",
    "    # Add the 'y_ball' column to the DataFrame\n",
    "    frames_df[\"y_ball\"] = y_ball.values\n",
    "\n",
    "def add_y_ball_prev(frames_df, frames_to_shift=1):\n",
    "    # Create a 'y_ball_prev' column with dtype float\n",
    "    y_ball = pd.Series(dtype=float, index=frames_df['frame'])\n",
    "    \n",
    "    # Shift the coordinates one frame\n",
    "    ball_positions = frames_df.loc[frames_df['team'] == 'ball', ['frame', 'y']].set_index('frame')['y'].shift(frames_to_shift)\n",
    "    y_ball.update(ball_positions)\n",
    "\n",
    "    # Add the 'y_ball_prev' column to the DataFrame\n",
    "    frames_df[\"y_ball_prev\"] = y_ball.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b00acdb",
   "metadata": {},
   "source": [
    "### Functions for adding features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb4fc19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the features x_future and y_future (the x and y coordinate of each player n frames into the future)\n",
    "def add_xy_future(frames_df, n=50):\n",
    "    # Shift the DataFrame by n frames for each player\n",
    "    future_df = frames_df.groupby(['team', 'jersey_number']).shift(-n)\n",
    "\n",
    "    # Merge the original DataFrame with the shifted DataFrame to get future coordinates\n",
    "    frames_df[['x_future', 'y_future']] = future_df[['x', 'y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b97713f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the features v_x and v_y (current velocity (m/s) in the x and y axis respectivly). delta_frames determines the time stamp\n",
    "def add_velocity_xy(frames_df, delta_frames=1):\n",
    "    # Create a copy of the DataFrame and shift it by delta_frames\n",
    "    past_df = frames_df.copy()\n",
    "    past_df['frame'] += delta_frames\n",
    "\n",
    "    # Merge the original DataFrame with the shifted DataFrame to get future coordinates\n",
    "    past_coordinates = frames_df.merge(past_df, on=['frame', 'team', 'jersey_number'], suffixes=('', '_past'), how='outer')\n",
    "\n",
    "    # Use the past coordinates to calculate the current velocity\n",
    "    v_x = (frames_df['x'] - past_coordinates['x_past']) * FPS / delta_frames\n",
    "    v_y = (frames_df['y'] - past_coordinates['y_past']) * FPS / delta_frames\n",
    "    \n",
    "    # The player can't surely run faster than Usian Bolt's max speed \n",
    "    usain_bolt_max_speed = 13\n",
    "    frames_df['v_x'] = v_x.clip(lower=-usain_bolt_max_speed, upper=usain_bolt_max_speed)\n",
    "    frames_df['v_y'] = v_y.clip(lower=-usain_bolt_max_speed, upper=usain_bolt_max_speed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8575c9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the features a_x and a_y (current velocity (m/sÂ²) in the x and y axis respectivly). delta_frames determines the time stamp\n",
    "def add_acceleration_xy(frames_df, delta_frames=1):\n",
    "    # Create a copy of the DataFrame and shift it by delta_frames twice\n",
    "    past_df = frames_df.copy()\n",
    "    past_df['frame'] += delta_frames\n",
    "    more_past_df = frames_df.copy()\n",
    "    more_past_df['frame'] += 2 * delta_frames\n",
    "\n",
    "    # Merge the original DataFrame with the shifted DataFrames to get past and future coordinates\n",
    "    past_coordinates = frames_df.merge(past_df, on=['frame', 'team', 'jersey_number'], suffixes=('', '_past'), how='outer')\n",
    "    more_past_coordinates = frames_df.merge(more_past_df, on=['frame', 'team', 'jersey_number'], suffixes=('', '_more_past'), how='outer')\n",
    "\n",
    "    # Use past and future coordinates to calculate current acceleration\n",
    "    a_x = ((frames_df['x'] - 2 * past_coordinates['x_past'] + more_past_coordinates['x_more_past']) * FPS / (delta_frames ** 2)).fillna(0)\n",
    "    a_y = ((frames_df['y'] - 2 * past_coordinates['y_past'] + more_past_coordinates['y_more_past']) * FPS / (delta_frames ** 2)).fillna(0)\n",
    "\n",
    "    # Clip acceleration values to reasonable limits\n",
    "    max_acceleration = 10  # This is a very high acceleration\n",
    "    frames_df['a_x'] = a_x.clip(lower=-max_acceleration, upper=max_acceleration)\n",
    "    frames_df['a_y'] = a_y.clip(lower=-max_acceleration, upper=max_acceleration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "239f9dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a vector indicating if the ball is in motion\n",
    "def add_ball_in_motion(frames_df):\n",
    "    # Initialize the 'ball_in_motion' column with False for all rows\n",
    "    frames_df['ball_in_motion_opt'] = False\n",
    "    \n",
    "    # Add 'x_ball' and 'y_ball'columns\n",
    "    add_x_ball(frames_df)\n",
    "    add_y_ball(frames_df)\n",
    "\n",
    "    # Add 'x_ball_prev' and 'y_ball_prev' columns\n",
    "    add_x_ball_prev(frames_df)\n",
    "    add_y_ball_prev(frames_df)\n",
    "\n",
    "    # Update the 'ball_in_motion' column to True if 'x_ball' or 'y_ball' exists, and any of the coordinates have changed\n",
    "    frames_df.loc[(frames_df['x_ball'].notna()) & (frames_df['x_ball'] != frames_df['x_ball_prev']), 'ball_in_motion'] = True\n",
    "    frames_df.loc[(frames_df['y_ball'].notna()) & (frames_df['y_ball'] != frames_df['y_ball_prev']), 'ball_in_motion'] = True\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    frames_df.drop(columns=[\"x_ball\", \"x_ball_prev\", \"y_ball\", \"y_ball_prev\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40a5c8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a vector with the 'x' position of the second to last defender, for both team directions\n",
    "def add_second_to_last_defender(frames_df):\n",
    "    # Sort the DataFrame based on 'team', 'frame', 'x'\n",
    "    sorted_frames_df = frames_df.sort_values(by=['team', 'frame', 'x']).copy()\n",
    "\n",
    "    # Find the x coordinates of players attacking left and right for each frame\n",
    "    x_players_attacking_left = sorted_frames_df[sorted_frames_df[\"team_direction\"] == 'left'].groupby(\"frame\")[\"x\"].apply(list)\n",
    "    x_players_attacking_right = sorted_frames_df[sorted_frames_df[\"team_direction\"] == 'right'].groupby(\"frame\")[\"x\"].apply(list)\n",
    "\n",
    "    # Find the x of the second to last defender\n",
    "    x_second_to_last_player_left = x_players_attacking_left.apply(lambda x: x[-2] if len(x) >= 2 else pitch_length / 2)\n",
    "    x_second_to_last_player_right = x_players_attacking_right.apply(lambda x: x[1] if len(x) >= 2 else pitch_length / 2)\n",
    "\n",
    "    # Add 'x_second_to_last_player_left' and 'x_second_to_last_player_right' columns\n",
    "    frames_df[\"x_second_to_last_player_left\"] = x_second_to_last_player_left.reindex(frames_df['frame']).values\n",
    "    frames_df[\"x_second_to_last_player_right\"] = x_second_to_last_player_right.reindex(frames_df['frame']).values\n",
    "\n",
    "# Add a vector with the 'offside_line'\n",
    "def add_offside_line(frames_df):\n",
    "    # Create a vector for the values of the half way line\n",
    "    frames_df[\"half_way_line\"] = pitch_length / 2\n",
    "\n",
    "    # Add 'x_ball' column and fill None values with the half way line\n",
    "    add_x_ball(frames_df)\n",
    "    frames_df['x_ball'].fillna(pitch_length / 2, inplace=True)\n",
    "\n",
    "    # Add 'x_second_to_last_player_left' and 'x_second_to_last_player_right' columns\n",
    "    add_second_to_last_defender(frames_df)\n",
    "\n",
    "    # Update \"offside_line\" column based on team direction\n",
    "    frames_df[\"offside_line\"] = np.where(\n",
    "        frames_df[\"team_direction\"] == 'right',\n",
    "        # If team_direction is 'right', the offside line will be the max value of the second to last defender, ball, and half way line\n",
    "        np.maximum.reduce([frames_df[\"x_second_to_last_player_left\"], frames_df[\"x_ball\"], frames_df[\"half_way_line\"]]),\n",
    "        # If team_direction is 'left', the offside line will be the min value of the second to last defender, ball, and half way line\n",
    "        np.minimum.reduce([frames_df[\"x_second_to_last_player_right\"], frames_df[\"x_ball\"], frames_df[\"half_way_line\"]])\n",
    "    )\n",
    "\n",
    "    # Set offside line to half way line if the 'team' is ball\n",
    "    frames_df.loc[frames_df['team'] == 'ball', 'offside_line'] = pitch_length / 2\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    frames_df.drop(columns=[\"half_way_line\", \"x_ball\", \"x_second_to_last_player_left\", \"x_second_to_last_player_right\"], inplace=True)\n",
    "\n",
    "# Add a vector the sets the value to 'offside_line' if a player is standing in an offside position\n",
    "def add_offside(frames_df):\n",
    "    # Add 'offside_line' column\n",
    "    add_offside_line(frames_df)\n",
    "    \n",
    "    # Create the empty column\n",
    "    frames_df[\"offside\"] = None\n",
    "    \n",
    "    # Fill the 'offside' column based on conditions\n",
    "    frames_df.loc[(frames_df['team_direction'] == 'right') & (frames_df['x'] > frames_df['offside_line']), 'offside'] = frames_df['offside_line']\n",
    "    frames_df.loc[(frames_df['team_direction'] == 'left') & (frames_df['x'] < frames_df['offside_line']), 'offside'] = frames_df['offside_line']\n",
    "\n",
    "    # Drop the 'offside_line' column\n",
    "    frames_df.drop(columns=[\"offside_line\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63ecb230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fix 'team_direction'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ef43b7",
   "metadata": {},
   "source": [
    "### Functions for processing and loading frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98345c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the unprocessed/ frames, and store the results to the processed/ fodler\n",
    "def process_frames():\n",
    "    # Load frames_df\n",
    "    for selected_season in seasons:\n",
    "        for selected_competition in competitions:\n",
    "            # Define paths\n",
    "            DATA_FOLDER_UNPROCESSED = f\"{DATA_LOCAL_FOLDER}/data/{selected_season}/{selected_competition}/unprocessed\"\n",
    "            FOLDER_OUT = f\"{DATA_LOCAL_FOLDER}/data/{selected_season}/{selected_competition}/processed\"\n",
    "            \n",
    "            # Create output folder if not exists\n",
    "            if not os.path.exists(FOLDER_OUT):\n",
    "                    os.makedirs(FOLDER_OUT)\n",
    "\n",
    "            # Find all frames parquet files\n",
    "            match_paths = glob.glob(os.path.join(DATA_FOLDER_UNPROCESSED, \"*.parquet\"))\n",
    "\n",
    "            # Extract IDs without the \".parquet\" extension\n",
    "            # TODO: Uncomment this line in production\n",
    "            # match_ids = [os.path.splitext(os.path.basename(path))[0] for path in match_paths]\n",
    "            match_ids = [os.path.splitext(os.path.basename(path))[0] for path in match_paths][10:11]\n",
    "            # match_ids = ['49e6bfdf-abf3-499d-b60e-cf727c6523c1']\n",
    "\n",
    "            # For all matches\n",
    "            for match_id in match_ids:\n",
    "                # Convert parquet file to a DataFrame\n",
    "                file_path_match = f\"{DATA_FOLDER_UNPROCESSED}/{match_id}.parquet\"\n",
    "                frames_df = pd.read_parquet(file_path_match)\n",
    "\n",
    "                # Process frames_df\n",
    "                flip_xy_based_on_team_direction(frames_df)\n",
    "                add_velocity_xy(frames_df, 1)\n",
    "                add_acceleration_xy(frames_df, 1)\n",
    "                add_xy_future(frames_df, FPS*seconds_into_the_future)\n",
    "                add_ball_in_motion(frames_df)\n",
    "                add_offside(frames_df)\n",
    "\n",
    "                # Add match_id\n",
    "                frames_df[\"match_id\"] = match_id\n",
    "\n",
    "                # Convert DataFrame to a parquet file\n",
    "                frames_df.to_parquet(f\"{FOLDER_OUT}/{match_id}.parquet\")\n",
    "\n",
    "                # Print that the match is processed\n",
    "                print(f\"Match {match_id} is processed\")\n",
    "\n",
    "# Load the processed/frames\n",
    "def load_all_processed_frames():\n",
    "    # Create DataFrame for storing all frames\n",
    "    frames_dfs = []\n",
    "    # Load frames_df\n",
    "    for selected_season in seasons:\n",
    "        for selected_competition in competitions:\n",
    "            # Define paths\n",
    "            DATA_FOLDER_PROCESSED = f\"{DATA_LOCAL_FOLDER}/data/{selected_season}/{selected_competition}/processed\"\n",
    "\n",
    "            # Find all frames parquet files\n",
    "            match_paths = glob.glob(os.path.join(DATA_FOLDER_PROCESSED, \"*.parquet\"))\n",
    "\n",
    "            # Extract IDs without the \".parquet\" extension\n",
    "            match_ids = [os.path.splitext(os.path.basename(path))[0] for path in match_paths]\n",
    "            # match_ids = ['49e6bfdf-abf3-499d-b60e-cf727c6523c1']\n",
    "\n",
    "            # For all matches\n",
    "            for match_id in match_ids:\n",
    "                # Convert parquet file to a DataFrame\n",
    "                file_path_match = f\"{DATA_FOLDER_PROCESSED}/{match_id}.parquet\"\n",
    "                frames_df = pd.read_parquet(file_path_match)\n",
    "                \n",
    "                # Append the DataFrame to frames_dfs\n",
    "                frames_dfs.append(frames_df)\n",
    "\n",
    "    return frames_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49ed36a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process_frames()\n",
    "frames_dfs = load_all_processed_frames()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b196e924",
   "metadata": {},
   "source": [
    "### Predictive models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "553b03fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the games into train, test, and validtion. This way, each game will be treated seperatly\n",
    "def split_match_ids(match_ids, train_size=0.7, test_size=0.1, val_size=0.2, random_state=42):\n",
    "    # Calculate the remaining size after the test and validation sizes are removed\n",
    "    remaining_size = 1.0 - test_size - val_size\n",
    "\n",
    "    # Check if the sum of sizes is not equal to 1\n",
    "    if remaining_size < 0 or abs(train_size + test_size + val_size - 1.0) > 1e-6:\n",
    "        raise ValueError(\"The sum of train_size, test_size, and val_size must be equal to 1.\")\n",
    "    \n",
    "    # Split the match IDs into train, test, and validation sets\n",
    "    train_ids, remaining_ids = train_test_split(match_ids, train_size=train_size, random_state=random_state)\n",
    "    test_ids, val_ids = train_test_split(remaining_ids, test_size=test_size / remaining_size, random_state=random_state)\n",
    "    \n",
    "    return train_ids, test_ids, val_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1746338",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-01 22:23:34.191790: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def prepare_data(frames_dfs):\n",
    "    # Define numerical and categorical columns\n",
    "    numerical_cols = ['x', 'y', 'v_x', 'v_y', 'a_x', 'a_y', 'distance_ran', 'minute']\n",
    "    categorical_cols = ['role', 'team_direction']\n",
    "\n",
    "    # Initialize lists to store features and labels\n",
    "    X_data = []\n",
    "    y_data = []\n",
    "\n",
    "    for frames_df in frames_dfs:\n",
    "        # Fill NaN values with zeros for numerical columns\n",
    "        frames_df[numerical_cols] = frames_df[numerical_cols].fillna(0)\n",
    "\n",
    "        # Drop rows with NaN values in the labels (y)\n",
    "        frames_df.dropna(subset=['x_future', 'y_future'], inplace=True)\n",
    "\n",
    "        # Extract features and labels from frames_df\n",
    "        X = frames_df[numerical_cols + categorical_cols]\n",
    "        y = frames_df[['x_future', 'y_future']]\n",
    "\n",
    "        # Add features and labels to the lists\n",
    "        X_data.append(X)\n",
    "        y_data.append(y)\n",
    "\n",
    "    # Concatenate the lists to create the final feature and label DataFrame\n",
    "    X_data = pd.concat(X_data)\n",
    "    y_data = pd.concat(y_data)\n",
    "\n",
    "    # Define column transformer for one-hot encoding team_direction\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', StandardScaler(), numerical_cols),\n",
    "            ('cat', OneHotEncoder(), categorical_cols)\n",
    "        ],\n",
    "        remainder='passthrough'\n",
    "    )\n",
    "\n",
    "    # Create pipeline for preprocessing and apply it to X_data\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor)])\n",
    "    X_data_scaled = pipeline.fit_transform(X_data)\n",
    "\n",
    "    return X_data_scaled, y_data\n",
    "\n",
    "def train_NN(train_frames_dfs, val_frames_dfs):\n",
    "    # Prepare the data for training\n",
    "    X_train, y_train = prepare_data(train_frames_dfs)\n",
    "\n",
    "    # Prepare the data for validation\n",
    "    X_val, y_val = prepare_data(val_frames_dfs)\n",
    "\n",
    "    # Train the model\n",
    "    train_model(X_train, y_train, X_val, y_val, val_frames_dfs)\n",
    "\n",
    "def define_model(input_shape):\n",
    "    # Define the neural network model\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(64, activation='relu', input_shape=(input_shape,)),\n",
    "        tf.keras.layers.Dense(32, activation='relu'),\n",
    "        tf.keras.layers.Dense(2)  # Output layer with 2 units for x_future and y_future\n",
    "    ])\n",
    "\n",
    "    return model\n",
    "\n",
    "def train_model(X_train, y_train, X_val, y_val, val_frames_dfs):\n",
    "    # Define the model\n",
    "    model = define_model(X_train.shape[1])\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, batch_size=32)\n",
    "\n",
    "    # Validate the model\n",
    "    validate_model(model, X_val, y_val, val_frames_dfs)\n",
    "\n",
    "def validate_model(model, X_val, y_val, val_frames_dfs):\n",
    "    for frames_df in val_frames_dfs:\n",
    "        # Predict future positions\n",
    "        y_pred = model.predict(X_val)\n",
    "\n",
    "        # Add predicted values to DataFrame\n",
    "        frames_df['x_future_pred'] = y_pred[:, 0]  # Predicted x_future values\n",
    "        frames_df['y_future_pred'] = y_pred[:, 1]  # Predicted y_future values\n",
    "\n",
    "        # Calculate and print the error using the provided error function\n",
    "        error = total_error_loss(frames_df, include_ball=False, ball_has_to_be_in_motion=True)\n",
    "        print(\"Total error loss:\", error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5caf3eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a match_id for each game\n",
    "match_ids = range(len(frames_dfs))\n",
    "\n",
    "# Split match IDs into train, test, and validation sets\n",
    "train_ids, test_ids, val_ids = split_match_ids(match_ids=match_ids)\n",
    "\n",
    "# Select frames data for training, testing, and validation\n",
    "train_frames_dfs = [frames_dfs[i] for i in train_ids]\n",
    "test_frames_dfs = [frames_dfs[i] for i in test_ids]\n",
    "val_frames_dfs = [frames_dfs[i] for i in val_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3fab3f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-01 22:24:22.619814: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 79266 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:ca:00.0, compute capability: 8.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "# Train the NN model\n",
    "train_NN(train_frames_dfs, val_frames_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c25da76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NAIVE: Always predict that all players will stand still\n",
    "# The calculations are based on x, y\n",
    "def predict_two_seconds_naive_static(frames_df):\n",
    "    frames_df['x_future_pred'] = frames_df['x']\n",
    "    frames_df['y_future_pred'] = frames_df['y']\n",
    "\n",
    "# NAIVE: Always predict that all players will continue with the same velocity\n",
    "# The calculations are based on x, y, v_x, and v_y\n",
    "def predict_two_seconds_naive_velocity(frames_df):\n",
    "    frames_df['x_future_pred'] = frames_df['x'] + frames_df['v_x'] * seconds_into_the_future\n",
    "    frames_df['y_future_pred'] = frames_df['y'] + frames_df['v_y'] * seconds_into_the_future\n",
    "\n",
    "# Make a prediction with a LSTM neural network model\n",
    "def predict_two_seconds_LSTM(frames_df):\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851f2328",
   "metadata": {},
   "source": [
    "### Calculate error loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2ec3286b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column for distance wrongly predicted (in metres) for each object\n",
    "def add_pred_error(frames_df):\n",
    "    # Create a vector with the Eculidian distance between the true position and the predicted position\n",
    "    frames_df['pred_error'] = round(((frames_df['x_future_pred'] - frames_df['x_future'])**2 + (frames_df['y_future_pred'] - frames_df['y_future'])**2)**0.5, 2)\n",
    "    \n",
    "# Add a column for distance wrongly predicted (in metres) for each object. Also return average_pred_error\n",
    "def total_error_loss(frames_df, include_ball=False, ball_has_to_be_in_motion=True):\n",
    "    # Add 'pred_error' column if empty\n",
    "    if frames_df['pred_error'].empty:\n",
    "        add_pred_error(frames_df)\n",
    "    \n",
    "    # Create a new column to store modified pred_error values\n",
    "    frames_df['pred_error_tmp'] = frames_df['pred_error']\n",
    "    \n",
    "    # If specified, set pred_error to None for frames where the ball is not in motion\n",
    "    if ball_has_to_be_in_motion:\n",
    "        frames_df.loc[frames_df[\"ball_in_motion\"] != True, 'pred_error_tmp'] = None\n",
    "\n",
    "    # If specified, set pred_error to None for rows where 'team' is 'ball'\n",
    "    if not include_ball:\n",
    "        frames_df.loc[frames_df['team'] == 'ball', 'pred_error_tmp'] = None\n",
    "\n",
    "    # Calculate average pred_error_tmp, excluding rows where pred_error is None\n",
    "    average_pred_error = frames_df['pred_error_tmp'].mean()\n",
    "\n",
    "    # Drop the temporary column\n",
    "    frames_df.drop(columns=['pred_error_tmp'], inplace=True)\n",
    "\n",
    "    return round(average_pred_error, 2)\n",
    "\n",
    "# Calculate the average error for a list of games\n",
    "def calculate_average_error(frames_dfs, predict_function, include_ball, ball_has_to_be_in_motion):\n",
    "    # Predict the future positions\n",
    "    [predict_function(frames_df) for frames_df in frames_dfs]\n",
    "    [add_pred_error(frames_df) for frames_df in frames_dfs]\n",
    "\n",
    "    # Concatenate all frames dataframes into a single dataframe\n",
    "    concatted_frames_df = pd.concat(frames_dfs)    \n",
    "    \n",
    "    # Calculate the total error loss\n",
    "    error = total_error_loss(concatted_frames_df, include_ball, ball_has_to_be_in_motion)\n",
    "    \n",
    "    return error\n",
    "\n",
    "# Find a frame with approximatly the same error as the average_pred_error, with an interval\n",
    "def find_frame_with_average_error(frames_df, average_pred_error, error_margin):\n",
    "    # For all frames\n",
    "    frames = frames_df['frame'].unique()\n",
    "    for frame in frames:\n",
    "        current_error = frames_df[frames_df['frame'] == frame]['pred_error'].mean()\n",
    "        # If the current error is within the error_margin,\n",
    "        if (current_error >= average_pred_error - error_margin) and (current_error <= average_pred_error + error_margin):\n",
    "            # Return the result\n",
    "            return frame\n",
    "\n",
    "    # If no frame was found\n",
    "    print(f\"No frame found within the error margin of {error_margin}\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef596153",
   "metadata": {},
   "source": [
    "## Run an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "896c5a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model error naive static: 3.97\n",
      "Model error naive velocity: 2.04\n"
     ]
    }
   ],
   "source": [
    "# Test model 1\n",
    "error_naive_static = calculate_average_error(frames_dfs, predict_two_seconds_naive_static, include_ball=False, ball_has_to_be_in_motion=True)\n",
    "print(f\"Model error naive static: {error_naive_static}\")\n",
    "\n",
    "# Test model 2\n",
    "error_naive_velocity = calculate_average_error(frames_dfs, predict_two_seconds_naive_velocity, include_ball=False, ball_has_to_be_in_motion=True)\n",
    "print(f\"Model error naive velocity: {error_naive_velocity}\")\n",
    "\n",
    "# Visualize one frame with average error for the first model, together with the corresponding frame for the second model\n",
    "frames_df = frames_dfs[0]\n",
    "frame_with_average_error = find_frame_with_average_error(frames_df, error_naive_static, error_margin=0.1)\n",
    "visualize_frame_prediction(frames_df, frame_with_average_error, \"naive_static\")\n",
    "visualize_frame_prediction(frames_df, frame_with_average_error, \"naive_velocity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9692b2d",
   "metadata": {},
   "source": [
    "### Print results for different models and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0866720c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the prediction functions (models) you want to test\n",
    "# prediction_functions = {\n",
    "#     \"Naive Static\": predict_two_seconds_naive_static,\n",
    "#     \"Naive Velocity\": predict_two_seconds_naive_velocity\n",
    "# }\n",
    "\n",
    "# # Initialize an empty list to store the results\n",
    "# results = []\n",
    "\n",
    "# # Define the combinations of include_ball and ball_has_to_be_in_motion\n",
    "# combinations = [(True, True), (True, False), (False, True), (False, False)]\n",
    "\n",
    "# # Load all processed frames\n",
    "# frames_dfs = load_all_processed_frames()\n",
    "\n",
    "# # Loop through each combination\n",
    "# for include_ball, ball_has_to_be_in_motion in combinations:\n",
    "#     # Add the combination of parameters\n",
    "#     result = {\"Include Ball\": include_ball, \"Ball in Motion\": ball_has_to_be_in_motion}\n",
    "#     # Loop through each prediction function (model)\n",
    "#     for model_name, predict_function in prediction_functions.items():\n",
    "#         # Calculate average error for the current prediction function (model)\n",
    "#         avg_error = calculate_average_error(frames_dfs, predict_function, include_ball, ball_has_to_be_in_motion)\n",
    "#         result[model_name] = avg_error\n",
    "    \n",
    "#     # Append the results to the list\n",
    "#     results.append(result)\n",
    "\n",
    "# # Create a DataFrame from the list of results\n",
    "# results_df = pd.DataFrame(results)\n",
    "\n",
    "# # Print the results DataFrame\n",
    "# results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "My Python",
   "language": "python",
   "name": "my_python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
