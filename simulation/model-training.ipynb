{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c078666b",
   "metadata": {},
   "source": [
    "# Notebook for training predictive models\n",
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa43b454-7b17-42fc-be8a-de1770ba3a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Embedding, Flatten, Concatenate, Dense, BatchNormalization, Dropout, Reshape, LSTM\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from datetime import date\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import glob\n",
    "import os\n",
    "\n",
    "from utils import load_processed_frames, split_match_ids, embedding_config, get_next_model_filename, euclidean_distance_loss, total_error_loss, define_regularizers, prepare_EL_input_data, prepare_LSTM_input_data, create_embeddings, smooth_predictions_xy, run_model, evaluate_model, print_column_variance\n",
    "from utils import prepare_df, add_can_be_sequentialized, extract_variables, load_tf_model, prepare_LSTM_df\n",
    "from visualize_game import visualize_training_results\n",
    "from settings import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2bf81b0",
   "metadata": {},
   "source": [
    "### Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfca7ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters for model training\n",
    "batch_size = 32\n",
    "sequence_length = 10        # Sequence length for LSTM model\n",
    "downsampling_factor = 5     # Keep every n:th frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f24a32",
   "metadata": {},
   "source": [
    "## Predictive model 1\n",
    "### NN with Embedding layers\n",
    "Player-based model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005fb1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the architecture of the neural network model with embeddings layers\n",
    "def define_NN_model(numerical_input_shape, categorical_cols, l1=0, l2=0):\n",
    "    # Inputs for each categorical feature\n",
    "    categorical_inputs = []\n",
    "    categorical_flats = []\n",
    "    for col in categorical_cols:\n",
    "        # Replace spaces with underscores in the input name\n",
    "        input_name = f'input_{col.replace(\" \", \"_\")}'\n",
    "        embedding_name = f'embedding_{col.replace(\" \", \"_\")}'\n",
    "\n",
    "        cat_input = Input(shape=(1,), name=input_name)  # Input for each categorical feature\n",
    "        emb_layer = Embedding(\n",
    "            input_dim=embedding_config[col]['n_categories'],\n",
    "            output_dim=embedding_config[col]['output_dim'],\n",
    "            input_length=1,\n",
    "            name=embedding_name\n",
    "        )(cat_input)\n",
    "        flat_layer = Flatten()(emb_layer)\n",
    "        categorical_inputs.append(cat_input)\n",
    "        categorical_flats.append(flat_layer)\n",
    "\n",
    "    # Prepare input layer for numerical data\n",
    "    numerical_input = Input(shape=(numerical_input_shape,), name='numerical_input')\n",
    "\n",
    "    # Concatenate all flattened embeddings with the numerical input\n",
    "    concatenated_features = Concatenate()([*categorical_flats, numerical_input]) if categorical_flats else numerical_input\n",
    "\n",
    "    # Dense layers\n",
    "    regularizer = define_regularizers(l1, l2)  # Set regularizer\n",
    "    dense_layer_1 = Dense(64, activation='relu', kernel_regularizer=regularizer)(concatenated_features)\n",
    "    dense_layer_2 = Dense(32, activation='relu', kernel_regularizer=regularizer)(dense_layer_1)\n",
    "    output_layer = Dense(len(y_cols), name='output_layer')(dense_layer_2)  # Output layer 'x_future' and 'y_future'\n",
    "\n",
    "    # Building the model\n",
    "    model = Model(inputs=[*categorical_inputs, numerical_input], outputs=output_layer)\n",
    "\n",
    "    return model\n",
    "\n",
    "def train_NN_model_with_embedding(train_ids, val_ids, numerical_cols, categorical_cols, positions, l1=0, l2=0, special_text=None):\n",
    "    # Start time to later display how many seconds the execution too\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Prepare inputs\n",
    "    X_train_input, y_train = prepare_EL_input_data(train_ids, numerical_cols, categorical_cols, positions, downsampling_factor)\n",
    "    X_val_input, y_val = prepare_EL_input_data(val_ids, numerical_cols, categorical_cols, positions, downsampling_factor)\n",
    "\n",
    "    # Define the model\n",
    "    model = define_NN_model(len(numerical_cols), categorical_cols, l1, l2)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss=euclidean_distance_loss)\n",
    "\n",
    "    # Train the model with the corrected input format\n",
    "    history = model.fit(X_train_input, y_train, validation_data=(X_val_input, y_val), epochs=n_epochs, batch_size=batch_size, verbose=2)\n",
    "\n",
    "    # Save the trained model to disk\n",
    "    model_filename = get_next_model_filename(\"NN_model\")\n",
    "    model.save(model_filename)\n",
    "\n",
    "    # Generate the corresponding txt filename\n",
    "    output_txt_filename = os.path.splitext(model_filename)[0] + \".txt\"\n",
    "\n",
    "    # Write the output directly to the txt file\n",
    "    with open(output_txt_filename, 'w') as f:\n",
    "        # Write the some general info at the begging of the file\n",
    "        today_date = date.today().strftime(\"%Y-%m-%d\")\n",
    "        f.write(f\"{today_date}\\n\")\n",
    "        f.write(f\"epochs={n_epochs}\\n\")\n",
    "        f.write(f\"matches={n_matches}\\n\")\n",
    "        f.write(f\"numerical_cols={numerical_cols}\\n\")\n",
    "        f.write(f\"categorical_cols={categorical_cols}\\n\")\n",
    "        f.write(f\"positions={positions}\\n\")\n",
    "        if l1 != 0: f.write(f\"l1={l1}\\n\")\n",
    "        if l2 != 0: f.write(f\"l2={l2}\\n\")\n",
    "        if special_text: f.write(f\"{special_text}\\n\")\n",
    "\n",
    "        # Write the execution time\n",
    "        end_time = time.time()\n",
    "        execution_time_minutes = (end_time - start_time) / 60\n",
    "        f.write(f\"\\nExecution time: {execution_time_minutes:.0f} minutes\\n\")\n",
    "\n",
    "        # Write the training results\n",
    "        f.write(\"\\nTraining results:\\n\")\n",
    "        for key, value in history.history.items():\n",
    "            rounded_values = [round(v, 2) for v in value]\n",
    "            f.write(f\"{key}: {rounded_values}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078b2f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the NN model with embedding layers\n",
    "n_epochs = 1\n",
    "n_matches = 10\n",
    "categorical_cols = ['position']\n",
    "positions=['Attacking Midfielder', 'Central Midfielder', 'Centre-Back', 'Defensive Midfielder', 'Forward', 'Full-Back', 'Goalkeeper', 'Wide Midfielder', 'Winger']\n",
    "# positions = ['Goalkeeper', 'Centre-Back', 'Full-Back']\n",
    "numerical_cols = ['x', 'y', 'v_x', 'v_y', 'a_x', 'a_y', 'distance_to_ball', 'angle_to_ball', 'tiredness', 'v_x_avg', 'v_y_avg']\n",
    "\n",
    "train_ids, _, val_ids = split_match_ids(n_matches)\n",
    "# train_NN_model_with_embedding(train_ids, val_ids, numerical_cols, categorical_cols, positions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980ccb12",
   "metadata": {},
   "source": [
    "## Predictive model 2\n",
    "### LSTM model\n",
    "Player-based model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46e9af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the architecture of the LSTM model with embeddings layers\n",
    "def define_LSTM_model(numerical_input_shape, categorical_cols, sequence_length, l1=0, l2=0):\n",
    "    categorical_inputs = []\n",
    "    categorical_flats = []\n",
    "    \n",
    "    # Create inputs for each categorical feature\n",
    "    for col in categorical_cols:\n",
    "        input_name = f'input_{col.replace(\" \", \"_\")}'\n",
    "        embedding_name = f'embedding_{col.replace(\" \", \"_\")}'\n",
    "\n",
    "        cat_input = Input(shape=(1,), name=input_name)\n",
    "        emb_layer = Embedding(\n",
    "            input_dim=embedding_config[col]['n_categories'],\n",
    "            output_dim=embedding_config[col]['output_dim'],\n",
    "            input_length=1,\n",
    "            name=embedding_name\n",
    "        )(cat_input)\n",
    "        flat_layer = Flatten()(emb_layer)\n",
    "        categorical_inputs.append(cat_input)\n",
    "        categorical_flats.append(flat_layer)\n",
    "\n",
    "    # Prepare input layer for sequential numerical data\n",
    "    numerical_input = Input(shape=(sequence_length, numerical_input_shape), name='numerical_input')\n",
    "    lstm_layer = LSTM(64, return_sequences=False, name='lstm_numerical')(numerical_input)\n",
    "\n",
    "    # Concatenate embeddings with numerical input\n",
    "    if categorical_flats:\n",
    "        concatenated_features = Concatenate()([*categorical_flats, lstm_layer])\n",
    "    else:\n",
    "        concatenated_features = lstm_layer  # Only use LSTM output if no categorical data\n",
    "\n",
    "    # Dense layers\n",
    "    regularizer = define_regularizers(l1, l2)  # Set regularizer\n",
    "    dense_layer_1 = Dense(64, activation='relu', kernel_regularizer=regularizer)(concatenated_features)\n",
    "    dense_layer_2 = Dense(32, activation='relu', kernel_regularizer=regularizer)(dense_layer_1)\n",
    "    output_layer = Dense(len(y_cols), name='output_layer')(dense_layer_2)  # Output layer\n",
    "\n",
    "    # Building the model\n",
    "    model = Model(inputs=[*categorical_inputs, numerical_input], outputs=output_layer)\n",
    "\n",
    "    return model\n",
    "\n",
    "def train_LSTM_model(train_ids, val_ids, numerical_cols, categorical_cols, sequence_length, positions, l1=0, l2=0, special_text=None):\n",
    "    # Prepare inputs\n",
    "    start_time = time.time()\n",
    "    X_train_input, y_train = prepare_LSTM_input_data(train_ids, numerical_cols, categorical_cols, sequence_length, positions, downsampling_factor)\n",
    "    X_val_input, y_val = prepare_LSTM_input_data(val_ids, numerical_cols, categorical_cols, sequence_length, positions, downsampling_factor)\n",
    "    data_preparation_time = time.time() - start_time\n",
    "    print(f\"Data preparation time: {data_preparation_time:.2f} seconds\")\n",
    "\n",
    "    # Define the model\n",
    "    model = define_LSTM_model(len(numerical_cols), categorical_cols, sequence_length, l1, l2)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss=euclidean_distance_loss)\n",
    "\n",
    "    # Train the model with the corrected input format\n",
    "    start_time = time.time()\n",
    "    history = model.fit(X_train_input, y_train, validation_data=(X_val_input, y_val), epochs=n_epochs, batch_size=batch_size, verbose=2)\n",
    "    training_time = time.time() - start_time\n",
    "    print(f\"Training time: {training_time:.2f} seconds\")\n",
    "\n",
    "    # Save the trained model to disk\n",
    "    model_filename = get_next_model_filename(\"LSTM_model\")\n",
    "    model.save(model_filename)\n",
    "\n",
    "    # Generate the corresponding txt filename\n",
    "    output_txt_filename = os.path.splitext(model_filename)[0] + \".txt\"\n",
    "\n",
    "    # Write the output directly to the txt file\n",
    "    with open(output_txt_filename, 'w') as f:\n",
    "        # Write the some general info at the begging of the file\n",
    "        today_date = date.today().strftime(\"%Y-%m-%d\")\n",
    "        f.write(f\"{today_date}\\n\")\n",
    "        f.write(f\"epochs={n_epochs}\\n\")\n",
    "        f.write(f\"matches={n_matches}\\n\")\n",
    "        f.write(f\"sequence_length={sequence_length}\\n\")\n",
    "        f.write(f\"numerical_cols={numerical_cols}\\n\")\n",
    "        f.write(f\"categorical_cols={categorical_cols}\\n\")\n",
    "        f.write(f\"positions={positions}\\n\")\n",
    "        if l1 != 0: f.write(f\"l1={l1}\\n\")\n",
    "        if l2 != 0: f.write(f\"l2={l2}\\n\")\n",
    "        if special_text: f.write(f\"{special_text}\\n\")\n",
    "\n",
    "        # Write the execution time\n",
    "        end_time = time.time()\n",
    "        execution_time_minutes = (end_time - start_time) / 60\n",
    "        f.write(f\"\\nExecution time: {execution_time_minutes:.0f} minutes\\n\")\n",
    "\n",
    "        # Write the training results\n",
    "        f.write(\"\\nTraining results:\\n\")\n",
    "        for key, value in history.history.items():\n",
    "            rounded_values = [round(v, 2) for v in value]\n",
    "            f.write(f\"{key}: {rounded_values}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5140068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.keras.backend.clear_session()\n",
    "n_epochs = 5\n",
    "n_matches = 60\n",
    "positions=['Attacking Midfielder', 'Central Midfielder', 'Centre-Back', 'Defensive Midfielder', 'Forward', 'Full-Back', 'Goalkeeper', 'Wide Midfielder', 'Winger']\n",
    "# positions=['Goalkeeper']\n",
    "categorical_cols = ['position']\n",
    "sequence_length = 10\n",
    "numerical_cols=['x', 'y', 'v_x', 'v_y', 'a_x', 'a_y', 'distance_to_ball', 'tiredness', 'v_x_avg', 'v_y_avg']\n",
    "\n",
    "# Only use 3 matches\n",
    "# n_matches = 3\n",
    "# train_ids, test_ids, val_ids = ['3acbc760-5bad-426c-ab7c-ef2d80f5ecf9'], ['b37b8919-e5bf-460e-a431-48feb878729f'], ['c820079c-2c34-485e-8b0a-73226152d986']\n",
    "\n",
    "train_ids, _, val_ids = split_match_ids(n_matches)\n",
    "train_LSTM_model(train_ids, val_ids, numerical_cols, categorical_cols, sequence_length, positions=positions, l2=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f887b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols=['x', 'y', 'v_x', 'v_y', 'a_x', 'a_y', 'distance_to_ball', 'tiredness', 'tiredness_short', 'v_x_avg', 'v_y_avg']\n",
    "train_LSTM_model(train_ids, val_ids, numerical_cols, categorical_cols, sequence_length, positions=positions, l2=1e-5)\n",
    "numerical_cols=['x', 'y', 'v_x', 'v_y', 'a_x', 'a_y', 'distance_to_ball', 'tiredness', 'v_x_avg', 'v_y_avg', 'distance_to_onside']\n",
    "train_LSTM_model(train_ids, val_ids, numerical_cols, categorical_cols, sequence_length, positions=positions, l2=1e-5)\n",
    "numerical_cols=['x', 'y', 'v_x', 'v_y', 'a_x', 'a_y', 'distance_to_ball', 'angle_to_ball', 'tiredness', 'tiredness_short', 'v_x_avg', 'v_y_avg']\n",
    "train_LSTM_model(train_ids, val_ids, numerical_cols, categorical_cols, sequence_length, positions=positions, l2=1e-5)\n",
    "numerical_cols=['x', 'y', 'v_x', 'v_y', 'a_x', 'a_y', 'distance_to_ball', 'angle_to_ball', 'tiredness', 'tiredness_short', 'v_x_avg', 'v_y_avg']\n",
    "train_LSTM_model(train_ids, val_ids, numerical_cols, categorical_cols, sequence_length, positions=positions, l2=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e61943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_matches = 160\n",
    "# train_ids, _, val_ids = split_match_ids(n_matches)\n",
    "# train_LSTM_model(train_ids, val_ids, numerical_cols, categorical_cols, sequence_length, positions=positions, l2=1e-6)\n",
    "\n",
    "# n_matches = 280\n",
    "# train_ids, _, val_ids = split_match_ids(n_matches)\n",
    "# train_LSTM_model(train_ids, val_ids, numerical_cols, categorical_cols, sequence_length, positions=positions, l2=1e-6)\n",
    "\n",
    "# n_matches = 560\n",
    "# train_ids, _, val_ids = split_match_ids(n_matches)\n",
    "# train_LSTM_model(train_ids, val_ids, numerical_cols, categorical_cols, sequence_length, positions=positions, l2=1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4d70d0",
   "metadata": {},
   "source": [
    "### Visualize training results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1730e7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Visualize training results\n",
    "# model_name = 'NN_model_v3'\n",
    "# training_results = {\n",
    "#     'loss': [2.0478146076202393, 2.0088889598846436, 2.0007753372192383, 1.9968146085739136, 1.9937269687652588, 1.9921172857284546, 1.990675687789917, 1.9893001317977905, 1.9881930351257324, 1.9875684976577759, 1.9872304201126099, 1.9865171909332275, 1.9859004020690918, 1.985435128211975, 1.9848004579544067, 1.983401894569397, 1.9824390411376953, 1.9820188283920288, 1.981824517250061, 1.9817743301391602],\n",
    "#     'val_loss': [4.535243034362793, 4.51762580871582, 4.469428539276123, 4.436275482177734, 4.456634521484375, 4.815524578094482, 4.3103556632995605, 4.498797416687012, 4.790141582489014, 4.464589595794678, 4.674554347991943, 4.561259746551514, 4.533383369445801, 4.472135066986084, 4.466953754425049, 4.478504180908203, 4.723540782928467, 4.859069347381592, 4.496937274932861, 4.377903461456299]\n",
    "# }\n",
    "\n",
    "# visualize_training_results(training_results, model_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "My Python",
   "language": "python",
   "name": "my_python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
