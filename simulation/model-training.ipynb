{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c078666b",
   "metadata": {},
   "source": [
    "# Notebook for training predictive models\n",
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa43b454-7b17-42fc-be8a-de1770ba3a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-03 17:56:16.234227: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Embedding, Flatten, Concatenate, Dense, BatchNormalization, Dropout, Reshape, LSTM\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from datetime import date\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import glob\n",
    "import os\n",
    "\n",
    "from utils import load_processed_frames, split_match_ids, get_next_model_filename, euclidean_distance_loss, total_error_loss, define_regularizers, prepare_EL_input_data, create_embeddings, smooth_predictions_xy, run_model, evaluate_model\n",
    "from visualize_game import visualize_training_results\n",
    "from settings import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2bf81b0",
   "metadata": {},
   "source": [
    "### Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfca7ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define numerical, categorical, and y columns\n",
    "numerical_cols = ['x', 'y', 'v_x', 'v_y', 'a_x', 'a_y']\n",
    "categorical_cols = ['team_direction', 'role']\n",
    "y_cols = ['x_future', 'y_future']\n",
    "\n",
    "# Define parameters for model training\n",
    "n_epochs = 1\n",
    "batch_size = 32\n",
    "n_matches = 40\n",
    "downsampling_factor = 5     # Keep every n:th frame\n",
    "sequence_length = 1    # Sequence length for LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7dd5b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define denominators for normalization\n",
    "denominators = {\n",
    "    'x': pitch_length,\n",
    "    'y': pitch_width,\n",
    "    'v_y': 13,\n",
    "    'v_y': 13,\n",
    "    'a_y': 10,\n",
    "    'a_y': 10,\n",
    "    'acc': 20,\n",
    "    'pac': 20,\n",
    "    'sta': 20,\n",
    "    'height': 2.10,\n",
    "    'weight': 110,\n",
    "    'distance_to_ball': round(np.sqrt((pitch_length**2 + pitch_width**2)), 2),\n",
    "    'angle_to_ball': 360,\n",
    "    'orientation': 360,\n",
    "    'tiredness': 10,\n",
    "    'minute': 45,\n",
    "    'period': 2,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ef43b7",
   "metadata": {},
   "source": [
    "### Load frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98345c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load every frames_df to a list\n",
    "frames_dfs = load_processed_frames(n_matches=n_matches)\n",
    "\n",
    "# Create an internal match_id for each game\n",
    "match_ids = range(len(frames_dfs))\n",
    "\n",
    "# Split match IDs into train, test, and validation sets\n",
    "train_ids, test_ids, val_ids = split_match_ids(match_ids=match_ids)\n",
    "\n",
    "# Select frames data for training, testing, and validation\n",
    "train_frames_dfs = [frames_dfs[i] for i in train_ids]\n",
    "test_frames_dfs = [frames_dfs[i] for i in test_ids]\n",
    "val_frames_dfs = [frames_dfs[i] for i in val_ids]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f24a32",
   "metadata": {},
   "source": [
    "## Predictive model 1\n",
    "### NN with Embedding layers\n",
    "Player-based model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "005fb1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network model with embeddings for categorical features.\n",
    "def define_NN_model_with_embedding(numerical_input_shape, l1=0, l2=0):\n",
    "    if categorical_cols:\n",
    "        categorical_inputs, categorical_flats = create_embeddings(categorical_cols)  # Create embeddings\n",
    "        numerical_input = Input(shape=(numerical_input_shape,), name='numerical_input')  # Numerical input\n",
    "        concatenated_features = Concatenate()([*categorical_flats, numerical_input])  # Combine all features\n",
    "        model_inputs = [*categorical_inputs, numerical_input]  # Model inputs\n",
    "    else:\n",
    "        numerical_input = Input(shape=(numerical_input_shape,), name='numerical_input')  # Numerical input\n",
    "        concatenated_features = numerical_input  # Use only numerical input\n",
    "        model_inputs = numerical_input  # Model inputs\n",
    "    \n",
    "    # Dense layers\n",
    "    regularizer = define_regularizers(l1, l2)  # Set regularizer\n",
    "    dense_layer_1 = Dense(64, activation='relu', kernel_regularizer=regularizer)(concatenated_features)\n",
    "    dense_layer_2 = Dense(32, activation='relu', kernel_regularizer=regularizer)(dense_layer_1)\n",
    "\n",
    "    output_layer = Dense(2)(dense_layer_2)  # Output layer for x_future and y_future\n",
    "    model = Model(inputs=model_inputs, outputs=output_layer)  # Build model\n",
    "\n",
    "    return model\n",
    "\n",
    "def train_NN_model_with_embedding(train_frames_dfs, val_frames_dfs, positions=[], l1=0, l2=0, special_text=None):\n",
    "    # Prepare inputs\n",
    "    X_train_input, y_train = prepare_EL_input_data(train_frames_dfs, numerical_cols, categorical_cols, positions=positions)\n",
    "    X_val_input, y_val = prepare_EL_input_data(val_frames_dfs, numerical_cols, categorical_cols, positions=positions)\n",
    "\n",
    "    # Define the model\n",
    "    model = define_NN_model_with_embedding(numerical_input_shape=len(numerical_cols), l1=l1, l2=l2)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss=euclidean_distance_loss)\n",
    "\n",
    "    # Train the model with the corrected input format\n",
    "    history = model.fit(X_train_input, y_train, validation_data=(X_val_input, y_val), epochs=n_epochs, batch_size=batch_size, verbose=2)\n",
    "\n",
    "    # Save the trained model to disk\n",
    "    model_filename = get_next_model_filename(\"NN_model\")\n",
    "    model.save(model_filename)\n",
    "\n",
    "    # Generate the corresponding txt filename\n",
    "    output_txt_filename = os.path.splitext(model_filename)[0] + \".txt\"\n",
    "\n",
    "    # Write the output directly to the txt file\n",
    "    with open(output_txt_filename, 'w') as f:\n",
    "        # Write the some general info at the begging of the file\n",
    "        today_date = date.today().strftime(\"%Y-%m-%d\")\n",
    "        f.write(f\"{today_date}\\n\")\n",
    "        f.write(f\"epochs={n_epochs}\\n\")\n",
    "        f.write(f\"matches={n_matches}\\n\")\n",
    "        f.write(f\"numerical_cols={numerical_cols}\\n\")\n",
    "        f.write(f\"categorical_cols={categorical_cols}\\n\")\n",
    "        f.write(f\"positions={positions}\\n\")\n",
    "        if l1 != 0: f.write(f\"l1={l1}\\n\")\n",
    "        if l2 != 0: f.write(f\"l2={l2}\\n\")\n",
    "        if special_text: f.write(f\"{special_text}\\n\")\n",
    "\n",
    "        # Write the training results\n",
    "        f.write(\"\\nTraining results:\\n\")\n",
    "        for key, value in history.history.items():\n",
    "            rounded_values = [round(v, 2) for v in value]\n",
    "            f.write(f\"{key}: {rounded_values}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "078b2f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train the NN model with embedding layers\n",
    "# n_epochs = 5\n",
    "# categorical_cols = ['position']\n",
    "# # positions = [\"Attacking Midfielder\", \"Central Midfielder\", \"Centre-Back\", \"Defensive Midfielder\", \"Forward\", \"Full-Back\", \"Goalkeeper\", \"Wide Midfielder\", \"Winger\"]\n",
    "# positions = [\"Central Midfielder\", \"Winger\"]\n",
    "# # positions = [\"Goalkeeper\"]\n",
    "\n",
    "# numerical_cols = ['x', 'y', 'v_x', 'v_y', 'a_x', 'a_y', 'distance_to_ball']\n",
    "# train_NN_model_with_embedding(train_frames_dfs, val_frames_dfs, positions=positions)\n",
    "\n",
    "# numerical_cols = ['x', 'y', 'v_x', 'v_y', 'a_x', 'a_y', 'distance_to_ball', 'minute', 'distance_ran', 'sta']\n",
    "# train_NN_model_with_embedding(train_frames_dfs, val_frames_dfs, positions=positions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58786e12",
   "metadata": {},
   "source": [
    "### Test for different values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "696c04ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_names = [\"NN_model_v2\"]\n",
    "# for model_name in model_names:\n",
    "#     error = evaluate_model(test_frames_dfs, model_name, LSTM=False)\n",
    "#     print(f\"{model_name}: {error}\")\n",
    "\n",
    "# for i in range(2, 5):\n",
    "#     model_name = f\"NN_model_v{i}\"\n",
    "#     error = evaluate_model(test_frames_dfs, model_name, LSTM=False)\n",
    "#     print(f\"{model_name}: {error}\\n\")\n",
    "\n",
    "# Test different alpha values\n",
    "\n",
    "# frames_df = run_model(test_frames_dfs, \"LSTM_model_v5\", LSTM=True)\n",
    "# alpha = 1.0\n",
    "# for i in range(10):\n",
    "#     frames_df = frames_df.copy()\n",
    "#     smooth_predictions_xy(frames_df, alpha=alpha)\n",
    "#     error = total_error_loss(frames_df)\n",
    "#     print(f\"{round(alpha, 2)}: {error}\")\n",
    "#     alpha -= 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a91f8754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates how the average 'pred_error' varies with each value in 'column_to_analyze'\n",
    "def find_column_variance(frames_df, column_to_analyze):\n",
    "    # Convert 'pred_error' to numeric, coercing non-numeric values to NaN\n",
    "    frames_df['pred_error'] = pd.to_numeric(frames_df['pred_error'], errors='coerce')\n",
    "\n",
    "    # Group by 'column_to_analyze' and calculate the average 'pred_error'\n",
    "    column_variance_df = frames_df.groupby(column_to_analyze)['pred_error'].mean().reset_index()\n",
    "\n",
    "    # Round to 2 decimal places\n",
    "    column_variance_df['pred_error'] = round(column_variance_df['pred_error'], 2)\n",
    "\n",
    "    # Sort by 'column_to_analyze' in ascending order\n",
    "    column_variance_df = column_variance_df.sort_values(by=column_to_analyze, ascending=True)\n",
    "\n",
    "    # Return DataFrame with results\n",
    "    return column_variance_df\n",
    "\n",
    "# alpha = 1\n",
    "# frames_df = run_model(\"NN_model_v3\")\n",
    "# total_error_loss(frames_df)\n",
    "# column_to_analyze = 'position'\n",
    "\n",
    "# # Call the function\n",
    "# column_variance_df = find_column_variance(frames_df, column_to_analyze)\n",
    "\n",
    "# # Print the DataFrame with results\n",
    "# print(f\"Average Pred Error per {column_to_analyze}:\")\n",
    "# print(column_variance_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980ccb12",
   "metadata": {},
   "source": [
    "## Predictive model 2\n",
    "### LSTM model\n",
    "Player-based model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "873f454c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a vector indicating if the row can be sequentialized, i.e. the player has 'sequence_length' consecutive frames\n",
    "def add_can_be_sequentialized(frames_df, sequence_length):\n",
    "    # Calculate the expected sequence start frame\n",
    "    frames_df['expected_sequence_start_frame'] = frames_df['frame'] - sequence_length * FPS // downsampling_factor\n",
    "    \n",
    "    # Group by each unique player\n",
    "    grouped = frames_df.groupby(['team', 'jersey_number'])\n",
    "    \n",
    "    # For each player, shift the 'frame' column to identify potential sequences\n",
    "    frames_df['shifted_frame'] = grouped['frame'].shift(sequence_length)\n",
    "    \n",
    "    # Check if the shifted frame matches 'expected_sequence_start_frame' and set 'can_be_sequentialized' to True if it does\n",
    "    frames_df['can_be_sequentialized'] = frames_df['expected_sequence_start_frame'] == frames_df['shifted_frame']\n",
    "    \n",
    "    # Drop temporary columns\n",
    "    frames_df.drop(['expected_sequence_start_frame', 'shifted_frame'], axis=1, inplace=True)\n",
    "\n",
    "# Sequentialize the numerical and categorical columns\n",
    "def sequentialize_data(X_df, y_df, numerical_cols, categorical_cols, sequence_length):\n",
    "    # Initialize empty lists with sequentialized data\n",
    "    X_seq_num_data = []\n",
    "    X_seq_cat_data = []\n",
    "    y_seq_data = []\n",
    "    \n",
    "    # Combined the values in y_df with X_df\n",
    "    X_df['future_xy'] = y_df.values.tolist()\n",
    "\n",
    "    # Add vector 'can_be_sequentialized'\n",
    "    add_can_be_sequentialized(X_df, sequence_length=sequence_length)\n",
    "\n",
    "    # Create a vector containg a list of all values in the numerical columns\n",
    "    X_df['numerical_data_list'] = X_df[numerical_cols].values.tolist()\n",
    "    \n",
    "    # Create a similar list for the categorical columns, if any\n",
    "    if categorical_cols:\n",
    "        # X_df['categorical_data_list'] = X_df[categorical_cols].values.tolist()\n",
    "        X_df['categorical_data_list'] = X_df[categorical_cols].apply(lambda x: x.tolist(), axis=1)\n",
    "\n",
    "    # Sort the DataFrame by 'team', 'match_id', and most importantly 'player'\n",
    "    X_df_sorted = X_df.sort_values(by=['team', 'match_id', 'player'])\n",
    "\n",
    "    # Group by each unique player\n",
    "    grouped = X_df_sorted.groupby(['team', 'jersey_number', 'match_id'])\n",
    "\n",
    "    # Iterate through each player and create sequences\n",
    "    for _, group in grouped:\n",
    "        # Create temporary columns with shifted version of 'numerical_cols' and 'categorical_cols'\n",
    "        for i in range(sequence_length):\n",
    "            group['numerical_data_list_' + str(i)] = group[\"numerical_data_list\"].shift(i)\n",
    "\n",
    "        # Concatenate the termporary columns to create the column 'sequential_numerical_data'\n",
    "        columns_to_sequentialize = ['numerical_data_list_' + str(i) for i in range(sequence_length)][::-1]\n",
    "        group['sequential_numerical_data'] = group[columns_to_sequentialize].values.tolist()\n",
    "\n",
    "        # Only consider rows that can be sequentialized\n",
    "        group = group[group['can_be_sequentialized']]\n",
    "\n",
    "        # Add the X data to the sequentialized lists\n",
    "        X_seq_num_data.append(group['sequential_numerical_data'])\n",
    "        \n",
    "        if categorical_cols:\n",
    "            X_seq_cat_data.append(group['categorical_data_list'])\n",
    "\n",
    "        # Add the y data to the sequentialized lists\n",
    "        y_seq_data.append(group['future_xy'])\n",
    "\n",
    "    # Combine all the sequentialized data to create Series\n",
    "    X_seq_num = pd.concat(X_seq_num_data)\n",
    "    y_seq = pd.concat(y_seq_data)\n",
    "\n",
    "    # Convert the Pandas Series of lists to a NumPy array\n",
    "    X_seq_num_np = np.array(X_seq_num.tolist()).astype('float32')\n",
    "    y_seq_np = np.array(y_seq.tolist()).astype('float32')\n",
    "    \n",
    "    # Add the data from categorical columns to X_seq_np\n",
    "    if categorical_cols:\n",
    "        X_seq_cat = pd.concat(X_seq_cat_data)\n",
    "        X_seq_cat_np = np.array(X_seq_cat.tolist()).astype('float32')\n",
    "        X_seq_np = [X_seq_cat_np, X_seq_num_np]\n",
    "\n",
    "        return X_seq_np, y_seq_np\n",
    "    \n",
    "    # Return the resuls without adding categorical data\n",
    "    else:\n",
    "        return X_seq_num_np, y_seq_np\n",
    "\n",
    "def prepare_LSTM_input_data(frames_dfs, numerical_cols, categorical_cols, sequence_length, positions=[]):\n",
    "    # Definie columns to temporarely give to prepare_data()\n",
    "    unchanged_cols=['player', 'frame', 'team', 'jersey_number', 'match_id']\n",
    "\n",
    "    # Prepare data\n",
    "    X_df, y_df = prepare_data(frames_dfs, numerical_cols=numerical_cols, categorical_cols=categorical_cols, unchanged_cols=unchanged_cols, positions=positions, include_ball=False, ball_has_to_be_in_motion=True)\n",
    "\n",
    "    # Sequentialize the data\n",
    "    X_seq, y_seq = sequentialize_data(X_df, y_df, numerical_cols, categorical_cols, sequence_length)\n",
    "\n",
    "    return X_seq, y_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c46e9af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the NN model with LSTM layer\n",
    "def define_LSTM_model(numerical_input_shape, sequence_length, l1=0, l2=0):  \n",
    "    # Handle case where we have categorical columns\n",
    "    if categorical_cols:\n",
    "        # Create embeddings for categorical data\n",
    "        categorical_inputs, categorical_flats = create_embeddings(categorical_cols)\n",
    "        \n",
    "        # Input for numerical data\n",
    "        numerical_input = Input(shape=(sequence_length, numerical_input_shape), name='numerical_input')\n",
    "\n",
    "        # Processing sequence with LSTM\n",
    "        lstm_out = LSTM(64)(numerical_input)\n",
    "\n",
    "        # Assuming we want to concatenate LSTM output with categorical embeddings\n",
    "        # Note: This might need adjustment based on how you want to use categorical data\n",
    "        concatenated_features = Concatenate()([lstm_out] + categorical_flats)\n",
    "\n",
    "        model_inputs = categorical_inputs + [numerical_input]\n",
    "\n",
    "    # Handle case where we only have numerical columns3\n",
    "    else:\n",
    "        numerical_input = Input(shape=(sequence_length, numerical_input_shape), name='numerical_input')  # Numerical input\n",
    "        lstm_layer = LSTM(64)(numerical_input)  # LSTM layer directly using numerical input\n",
    "        concatenated_features = lstm_layer  # Directly use LSTM output\n",
    "        model_inputs = [numerical_input]  # Model inputs\n",
    "\n",
    "    # Dense layers\n",
    "    regularizer = define_regularizers(l1, l2)  # Set regularizer\n",
    "    dense_layer_1 = Dense(64, activation='relu', kernel_regularizer=regularizer)(concatenated_features)\n",
    "    dense_layer_2 = Dense(32, activation='relu', kernel_regularizer=regularizer)(dense_layer_1)\n",
    "\n",
    "    output_layer = Dense(2)(dense_layer_2)  # Output layer for x_future and y_future\n",
    "    model = Model(inputs=model_inputs, outputs=output_layer)  # Build model\n",
    "\n",
    "    return model\n",
    "\n",
    "def train_LSTM_model(train_frames_dfs, val_frames_dfs, sequence_length, positions=[], l1=0, l2=0, special_text=None):\n",
    "    # Prepare inputs\n",
    "    X_train_input, y_train = prepare_LSTM_input_data(train_frames_dfs, numerical_cols, categorical_cols, sequence_length, positions=positions)\n",
    "    X_val_input, y_val = prepare_LSTM_input_data(val_frames_dfs, numerical_cols, categorical_cols, sequence_length, positions=positions)\n",
    "\n",
    "    # Define the model\n",
    "    model = define_LSTM_model(numerical_input_shape=len(numerical_cols), sequence_length=sequence_length, l1=l1, l2=l2)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss=euclidean_distance_loss)\n",
    "\n",
    "    # Train the model with the corrected input format\n",
    "    history = model.fit(X_train_input, y_train, validation_data=(X_val_input, y_val), epochs=n_epochs, batch_size=batch_size, verbose=2)\n",
    "\n",
    "    # Save the trained model to disk\n",
    "    model_filename = get_next_model_filename(\"LSTM_model\")\n",
    "    model.save(model_filename)\n",
    "\n",
    "    # Generate the corresponding txt filename\n",
    "    output_txt_filename = os.path.splitext(model_filename)[0] + \".txt\"\n",
    "\n",
    "    # Write the output directly to the txt file\n",
    "    with open(output_txt_filename, 'w') as f:\n",
    "        # Write the some general info at the begging of the file\n",
    "        today_date = date.today().strftime(\"%Y-%m-%d\")\n",
    "        f.write(f\"{today_date}\\n\")\n",
    "        f.write(f\"epochs={n_epochs}\\n\")\n",
    "        f.write(f\"matches={n_matches}\\n\")\n",
    "        f.write(f\"sequence_length={sequence_length}\\n\")\n",
    "        f.write(f\"numerical_cols={numerical_cols}\\n\")\n",
    "        f.write(f\"categorical_cols={categorical_cols}\\n\")\n",
    "        f.write(f\"positions={positions}\\n\")\n",
    "        if l1 != 0: f.write(f\"l1={l1}\\n\")\n",
    "        if l2 != 0: f.write(f\"l2={l2}\\n\")\n",
    "        if special_text: f.write(f\"{special_text}\\n\")\n",
    "\n",
    "        # Write the training results\n",
    "        f.write(\"\\nTraining results:\\n\")\n",
    "        for key, value in history.history.items():\n",
    "            rounded_values = [round(v, 2) for v in value]\n",
    "            f.write(f\"{key}: {rounded_values}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f5140068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "426189/426189 - 993s - loss: 1.7130 - val_loss: 1.5130 - 993s/epoch - 2ms/step\n",
      "Epoch 2/4\n",
      "426189/426189 - 996s - loss: 1.6162 - val_loss: 1.4690 - 996s/epoch - 2ms/step\n",
      "Epoch 3/4\n",
      "426189/426189 - 1004s - loss: 1.6021 - val_loss: 1.4677 - 1004s/epoch - 2ms/step\n",
      "Epoch 4/4\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 4\n",
    "positions=['Attacking Midfielder', 'Central Midfielder', 'Centre-Back', 'Defensive Midfielder', 'Forward', 'Full-Back', 'Goalkeeper', 'Wide Midfielder', 'Winger']\n",
    "categorical_cols = []\n",
    "sequence_length = 10\n",
    "\n",
    "numerical_cols=['x', 'y', 'v_x', 'v_y', 'a_x', 'a_y', 'distance_to_ball']\n",
    "train_LSTM_model(train_frames_dfs, val_frames_dfs, sequence_length, positions=positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8ad0032a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "2585/2585 [==============================] - 3s 1ms/step\n",
      "LSTM_model_v4: 1.331\n"
     ]
    }
   ],
   "source": [
    "model_name = \"LSTM_model_v4\"\n",
    "error = evaluate_model(test_frames_dfs, model_name, LSTM=True)\n",
    "print(f\"{model_name}: {error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9135d067",
   "metadata": {},
   "source": [
    "### Test LSTM prepare data on smaller dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7392c08e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player</th>\n",
       "      <th>frame</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>v_x</th>\n",
       "      <th>x_future</th>\n",
       "      <th>y_future</th>\n",
       "      <th>can_be_sequentialized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>Peter Abrahamsson</td>\n",
       "      <td>25</td>\n",
       "      <td>10.4</td>\n",
       "      <td>33.5</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>8.35</td>\n",
       "      <td>32.28</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>Noel Törnqvist</td>\n",
       "      <td>25</td>\n",
       "      <td>97.2</td>\n",
       "      <td>35.5</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>95.20</td>\n",
       "      <td>34.93</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>Peter Abrahamsson</td>\n",
       "      <td>30</td>\n",
       "      <td>10.1</td>\n",
       "      <td>33.3</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>8.18</td>\n",
       "      <td>32.22</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>Noel Törnqvist</td>\n",
       "      <td>30</td>\n",
       "      <td>97.1</td>\n",
       "      <td>35.5</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>94.85</td>\n",
       "      <td>34.88</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>Peter Abrahamsson</td>\n",
       "      <td>35</td>\n",
       "      <td>9.9</td>\n",
       "      <td>33.1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>8.01</td>\n",
       "      <td>32.18</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790</th>\n",
       "      <td>Noel Törnqvist</td>\n",
       "      <td>35</td>\n",
       "      <td>97.0</td>\n",
       "      <td>35.5</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>94.44</td>\n",
       "      <td>34.85</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>Peter Abrahamsson</td>\n",
       "      <td>40</td>\n",
       "      <td>9.8</td>\n",
       "      <td>33.0</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>7.79</td>\n",
       "      <td>32.15</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>Noel Törnqvist</td>\n",
       "      <td>40</td>\n",
       "      <td>97.0</td>\n",
       "      <td>35.4</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>94.01</td>\n",
       "      <td>34.86</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Peter Abrahamsson</td>\n",
       "      <td>45</td>\n",
       "      <td>9.6</td>\n",
       "      <td>32.9</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>7.51</td>\n",
       "      <td>32.10</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>Noel Törnqvist</td>\n",
       "      <td>45</td>\n",
       "      <td>96.9</td>\n",
       "      <td>35.3</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>93.64</td>\n",
       "      <td>34.88</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 player  frame     x     y  v_x  x_future  y_future  \\\n",
       "560   Peter Abrahamsson     25  10.4  33.5 -1.0      8.35     32.28   \n",
       "570      Noel Törnqvist     25  97.2  35.5 -0.2     95.20     34.93   \n",
       "670   Peter Abrahamsson     30  10.1  33.3 -1.0      8.18     32.22   \n",
       "680      Noel Törnqvist     30  97.1  35.5 -0.3     94.85     34.88   \n",
       "780   Peter Abrahamsson     35   9.9  33.1 -1.0      8.01     32.18   \n",
       "790      Noel Törnqvist     35  97.0  35.5 -0.3     94.44     34.85   \n",
       "890   Peter Abrahamsson     40   9.8  33.0 -0.8      7.79     32.15   \n",
       "900      Noel Törnqvist     40  97.0  35.4 -0.3     94.01     34.86   \n",
       "996   Peter Abrahamsson     45   9.6  32.9 -0.8      7.51     32.10   \n",
       "1006     Noel Törnqvist     45  96.9  35.3 -0.7     93.64     34.88   \n",
       "\n",
       "      can_be_sequentialized  \n",
       "560                   False  \n",
       "570                   False  \n",
       "670                   False  \n",
       "680                   False  \n",
       "780                    True  \n",
       "790                    True  \n",
       "890                    True  \n",
       "900                    True  \n",
       "996                    True  \n",
       "1006                   True  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames_df = val_frames_dfs[0]\n",
    "frames_df = frames_df[frames_df['frame'] % 5 == 0]\n",
    "frames_df = frames_df[frames_df['position'] == \"Goalkeeper\"].iloc[10:20]\n",
    "frames_df['x'] = round(frames_df['x'], 1)\n",
    "frames_df['y'] = round(frames_df['y'], 1)\n",
    "frames_df['v_x'] = round(frames_df['v_x'], 1)\n",
    "\n",
    "add_can_be_sequentialized(frames_df, sequence_length=2)\n",
    "\n",
    "numerical_cols = ['x', 'y', 'v_x']\n",
    "frames_df['numerical_cols_list'] = frames_df[numerical_cols].values.tolist()\n",
    "frames_df[['player', 'frame', 'x', 'y', 'v_x', 'x_future', 'y_future', 'can_be_sequentialized']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dd25e222",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_seq_data, y_seq_data = prepare_LSTM_input_data([frames_df], numerical_cols, categorical_cols, sequence_length=2, positions=positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "df98a825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]], dtype=float32),\n",
       " array([[[ 0.9247619 ,  0.52205884, -0.3       ],\n",
       "         [ 0.9238095 ,  0.52205884, -0.3       ]],\n",
       " \n",
       "        [[ 0.9238095 ,  0.52205884, -0.3       ],\n",
       "         [ 0.9238095 ,  0.5205882 , -0.3       ]],\n",
       " \n",
       "        [[ 0.9238095 ,  0.5205882 , -0.3       ],\n",
       "         [ 0.92285717,  0.51911765, -0.7       ]],\n",
       " \n",
       "        [[ 0.09619047,  0.4897059 , -1.        ],\n",
       "         [ 0.09428571,  0.4867647 , -1.        ]],\n",
       " \n",
       "        [[ 0.09428571,  0.4867647 , -1.        ],\n",
       "         [ 0.09333333,  0.4852941 , -0.8       ]],\n",
       " \n",
       "        [[ 0.09333333,  0.4852941 , -0.8       ],\n",
       "         [ 0.09142857,  0.48382354, -0.8       ]]], dtype=float32)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_seq_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4d70d0",
   "metadata": {},
   "source": [
    "### Visualize training results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1730e7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Visualize training results\n",
    "# model_name = 'NN_embedding_model_3'\n",
    "# training_results = {\n",
    "#     'loss': [2.0478146076202393, 2.0088889598846436, 2.0007753372192383, 1.9968146085739136, 1.9937269687652588, 1.9921172857284546, 1.990675687789917, 1.9893001317977905, 1.9881930351257324, 1.9875684976577759, 1.9872304201126099, 1.9865171909332275, 1.9859004020690918, 1.985435128211975, 1.9848004579544067, 1.983401894569397, 1.9824390411376953, 1.9820188283920288, 1.981824517250061, 1.9817743301391602],\n",
    "#     'val_loss': [4.535243034362793, 4.51762580871582, 4.469428539276123, 4.436275482177734, 4.456634521484375, 4.815524578094482, 4.3103556632995605, 4.498797416687012, 4.790141582489014, 4.464589595794678, 4.674554347991943, 4.561259746551514, 4.533383369445801, 4.472135066986084, 4.466953754425049, 4.478504180908203, 4.723540782928467, 4.859069347381592, 4.496937274932861, 4.377903461456299]\n",
    "# }\n",
    "\n",
    "# visualize_training_results(training_results, model_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "My Python",
   "language": "python",
   "name": "my_python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
