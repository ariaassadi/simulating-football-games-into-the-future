{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c078666b",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa43b454-7b17-42fc-be8a-de1770ba3a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-24 12:21:07.136772: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import glob\n",
    "import os\n",
    "\n",
    "from add_features import add_xy_future, add_velocity_xy, add_acceleration_xy, add_average_velocity, add_orientation, add_ball_in_motion, add_distance_to_ball, add_angle_to_ball, add_offside, add_distance_to_onside, load_FM_data, add_FM_data, add_tiredness, add_tiredness_short_term\n",
    "from visualize_game import visualize_game_animation, visualize_prediction_animation\n",
    "from utils import denominators, google_sheet_to_df, load_processed_frames, extract_variables, load_tf_model, prepare_EL_input_data, prepare_df, prepare_LSTM_df, prepare_LSTM_input_data, total_error_loss, smooth_predictions_xy, run_model, print_column_variance\n",
    "from settings import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9ceda5",
   "metadata": {},
   "source": [
    "### Necessary columns\n",
    "| Column Name    | Description                                        |\n",
    "|----------------|----------------------------------------------------|\n",
    "| player         | The name of the player                             |\n",
    "| jersey_number  | The jersey number of the player                    |\n",
    "| team           | 'home_team', 'away_team', or 'ball'                |\n",
    "| team_name      | The team of the player                             |\n",
    "| period         | The period of the game (1 or 2)                    |\n",
    "| minute         | The minute of the game                             |\n",
    "| second         | The second within the current minute               |\n",
    "| frame          | The frame of the game                              |\n",
    "| distance_ran   | The cumulative distance covered by the player      |\n",
    "| x              | The x-coordinate of the player                     |\n",
    "| y              | The y-coordinate of the player                     |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc047404",
   "metadata": {},
   "source": [
    "## Define make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0022d7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add all features\n",
    "def add_all_features(frames_df):\n",
    "    # Add the following features\n",
    "    frames_df = add_xy_future(frames_df, FPS * seconds_into_the_future)\n",
    "    frames_df = add_velocity_xy(frames_df, 1, smooth=True)\n",
    "    frames_df = add_acceleration_xy(frames_df, 1, smooth=True)\n",
    "    frames_df = add_average_velocity(frames_df)\n",
    "    frames_df = add_orientation(frames_df)\n",
    "    frames_df = add_ball_in_motion(frames_df)\n",
    "    frames_df = add_distance_to_ball(frames_df)\n",
    "    frames_df = add_angle_to_ball(frames_df)\n",
    "    # frames_df = add_offside(frames_df)\n",
    "    frames_df = add_distance_to_onside(frames_df)\n",
    "    frames_df = add_FM_data(frames_df, load_FM_data())\n",
    "    frames_df = add_tiredness(frames_df)\n",
    "    frames_df = add_tiredness_short_term(frames_df, window=FPS*20)\n",
    "\n",
    "    # Add an imaginary 'match_id'\n",
    "    frames_df['match_id'] = 1\n",
    "\n",
    "    return frames_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "547d39c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage: run_model(test_frames_dfs, \"NN_model_v1\") \n",
    "def run_model(frames_dfs, model_name):\n",
    "    # Load varibles\n",
    "    numerical_cols, categorical_cols, positions, sequence_length = extract_variables(model_name)\n",
    "\n",
    "    # Load model\n",
    "    model = load_tf_model(f\"models/{model_name}.h5\", euclidean_distance_loss=True)\n",
    "\n",
    "    # Prepare the input data for LSTM model\n",
    "    if \"LSTM\" in model_name:\n",
    "        # Prepare X_test_input and y_test\n",
    "        X_test_input, y_test = prepare_LSTM_input_data(frames_dfs, numerical_cols, categorical_cols, sequence_length, positions, downsampling_factor=1)\n",
    "\n",
    "        # Create the DataFrame that will recieve the predictions\n",
    "        prepared_frames_df = prepare_LSTM_df(frames_dfs, numerical_cols, categorical_cols, sequence_length, positions, downsampling_factor=1)\n",
    "\n",
    "    # Prepare the input data for non-LSTM model\n",
    "    else:\n",
    "        # Prepare X_test_input and y_test\n",
    "        X_test_input, y_test = prepare_EL_input_data(frames_dfs, numerical_cols, categorical_cols, positions, downsampling_factor=1)\n",
    "\n",
    "        # Create the DataFrame that will recieve the predictions\n",
    "        prepared_frames_dfs = [prepare_df(frames_df, numerical_cols, categorical_cols, positions=positions, downsampling_factor=1) for frames_df in frames_dfs]\n",
    "        prepared_frames_df = pd.concat(prepared_frames_dfs, ignore_index=True)\n",
    "\n",
    "    # Make predictions using the loaded tf model\n",
    "    predictions = model.predict(X_test_input)\n",
    "\n",
    "    # Extract the predicted values\n",
    "    x_future_pred = predictions[:, 0]\n",
    "    y_future_pred = predictions[:, 1]\n",
    "\n",
    "    # Add the predicted values to 'x_future_pred' and 'y_future_pred' columns\n",
    "    if \"LSTM\" in model_name:\n",
    "        # Check that the length of x_future_pred and y_future_pred matches the number of True values in 'can_be_sequentialized'\n",
    "        assert len(x_future_pred) == prepared_frames_df['can_be_sequentialized'].sum()\n",
    "        assert len(y_future_pred) == prepared_frames_df['can_be_sequentialized'].sum()\n",
    "\n",
    "        # Add the predicted values to 'x_future_pred' and 'y_future_pred' columns where 'can_be_sequentialized' is True\n",
    "        prepared_frames_df.loc[prepared_frames_df['can_be_sequentialized'], 'x_future_pred'] = x_future_pred\n",
    "        prepared_frames_df.loc[prepared_frames_df['can_be_sequentialized'], 'y_future_pred'] = y_future_pred\n",
    "\n",
    "        if normalize:\n",
    "            # Unnormalize the numerical columns\n",
    "            for col in numerical_cols:\n",
    "                if col in denominators:\n",
    "                    prepared_frames_df[col] = prepared_frames_df[col] * denominators[col]\n",
    "    else:\n",
    "        prepared_frames_df['x_future_pred'] = x_future_pred\n",
    "        prepared_frames_df['y_future_pred'] = y_future_pred\n",
    "\n",
    "    # Clip values to stay on the pitch\n",
    "    prepared_frames_df['x_future_pred'] = prepared_frames_df['x_future_pred'].clip(lower=0, upper=pitch_length)\n",
    "    prepared_frames_df['y_future_pred'] = prepared_frames_df['y_future_pred'].clip(lower=0, upper=pitch_width)\n",
    "\n",
    "    # Smooth the predicted coordinates\n",
    "    # smooth_predictions_xy(frames_df, alpha=0.98)\n",
    "\n",
    "    return prepared_frames_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28974278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the vectors 'x_future_pred' and 'y_future_pred' on frames_df\n",
    "def make_predictions(frames_df, model_name):\n",
    "    # Prepare the DataFrame by adding all features\n",
    "    frames_df = add_all_features(frames_df)\n",
    "\n",
    "    # Run the model and add the vectors 'x_future_pred' and 'y_future_pred' to frames_df\n",
    "    frames_df = run_model([frames_df], model_name)\n",
    "\n",
    "    # Calculate the error\n",
    "    error = total_error_loss(frames_df)\n",
    "    print(f\"Error: {error}\")\n",
    "\n",
    "    # Define the file path\n",
    "    file_path = f\"models/{model_name}.txt\"\n",
    "    # if 'Testing results' does not exists in txt file\n",
    "    with open(file_path, 'r') as file:\n",
    "        if 'Testing results' not in file.read():\n",
    "            # Write the following with f.write\n",
    "            with open(file_path, 'a') as file:  # 'a' mode to append data\n",
    "                file.write(f\"\\nTesting results:\\ntest_loss: {error}\\n\")\n",
    "            print(\"Testing results added to the file.\")\n",
    "\n",
    "    return frames_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d69186",
   "metadata": {},
   "source": [
    "## Example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33a0fe33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-24 12:21:14.186898: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 31132 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:89:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Started prepare_data\n",
      "Ended prepare_data, Duration: 0.02 seconds\n",
      "Started sequentialization\n",
      "Ended sequentialization, Duration: 0.11 seconds\n",
      "Started prepare_data\n",
      "Ended prepare_data, Duration: 0.01 seconds\n",
      "Started sequentialization\n",
      "Ended sequentialization, Duration: 0.11 seconds\n",
      " 44/195 [=====>........................] - ETA: 0s  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-24 12:21:16.287763: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195/195 [==============================] - 1s 1ms/step\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'x_future'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/apps/Arch/software/SciPy-bundle/2022.05-foss-2022a/lib/python3.10/site-packages/pandas/core/indexes/base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3620\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/apps/Arch/software/SciPy-bundle/2022.05-foss-2022a/lib/python3.10/site-packages/pandas/_libs/index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/apps/Arch/software/SciPy-bundle/2022.05-foss-2022a/lib/python3.10/site-packages/pandas/_libs/index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'x_future'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [5], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39m# Make the prediction\u001b[39;00m\n\u001b[1;32m     10\u001b[0m model_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mLSTM_best_v1\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> 11\u001b[0m frames_df \u001b[39m=\u001b[39m make_predictions(frames_df, model_name)\n",
      "Cell \u001b[0;32mIn [4], line 10\u001b[0m, in \u001b[0;36mmake_predictions\u001b[0;34m(frames_df, model_name)\u001b[0m\n\u001b[1;32m      7\u001b[0m frames_df \u001b[39m=\u001b[39m run_model([frames_df], model_name)\n\u001b[1;32m      9\u001b[0m \u001b[39m# Calculate the error\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m error \u001b[39m=\u001b[39m total_error_loss(frames_df)\n\u001b[1;32m     11\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mError: \u001b[39m\u001b[39m{\u001b[39;00merror\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[39m# Define the file path\u001b[39;00m\n",
      "File \u001b[0;32m~/football/simulating-football-games-into-the-future/simulation/utils.py:149\u001b[0m, in \u001b[0;36mtotal_error_loss\u001b[0;34m(frames_df, include_ball, ball_has_to_be_in_motion)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtotal_error_loss\u001b[39m(frames_df, include_ball\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, ball_has_to_be_in_motion\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m    148\u001b[0m     \u001b[39m# Add 'pred_error' column\u001b[39;00m\n\u001b[0;32m--> 149\u001b[0m     add_pred_error(frames_df)\n\u001b[1;32m    151\u001b[0m     \u001b[39m# Create a new column to store modified pred_error values\u001b[39;00m\n\u001b[1;32m    152\u001b[0m     frames_df[\u001b[39m'\u001b[39m\u001b[39mpred_error_tmp\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m frames_df[\u001b[39m'\u001b[39m\u001b[39mpred_error\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m~/football/simulating-football-games-into-the-future/simulation/utils.py:144\u001b[0m, in \u001b[0;36madd_pred_error\u001b[0;34m(frames_df)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39madd_pred_error\u001b[39m(frames_df):\n\u001b[1;32m    143\u001b[0m     \u001b[39m# Create a vector with the Eculidian distance between the true position and the predicted position\u001b[39;00m\n\u001b[0;32m--> 144\u001b[0m     frames_df[\u001b[39m'\u001b[39m\u001b[39mpred_error\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mround\u001b[39m(((frames_df[\u001b[39m'\u001b[39m\u001b[39mx_future_pred\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m-\u001b[39m frames_df[\u001b[39m'\u001b[39;49m\u001b[39mx_future\u001b[39;49m\u001b[39m'\u001b[39;49m])\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m \u001b[39m+\u001b[39m (frames_df[\u001b[39m'\u001b[39m\u001b[39my_future_pred\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m-\u001b[39m frames_df[\u001b[39m'\u001b[39m\u001b[39my_future\u001b[39m\u001b[39m'\u001b[39m])\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m)\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m0.5\u001b[39m, \u001b[39m2\u001b[39m)\n",
      "File \u001b[0;32m/apps/Arch/software/SciPy-bundle/2022.05-foss-2022a/lib/python3.10/site-packages/pandas/core/frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3503\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3504\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3505\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3506\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3507\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/apps/Arch/software/SciPy-bundle/2022.05-foss-2022a/lib/python3.10/site-packages/pandas/core/indexes/base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3623\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3624\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3625\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3626\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3627\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3628\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'x_future'"
     ]
    }
   ],
   "source": [
    "# Example match\n",
    "DATA_FOLDER_UNPROCESSED = f\"{DATA_LOCAL_FOLDER}/data/2023/Allsvenskan/unprocessed\"\n",
    "match_id = '8ef97096-db3b-4597-8dfb-3bca4e69586b'\n",
    "file_path_match = f\"{DATA_FOLDER_UNPROCESSED}/{match_id}.parquet\"\n",
    "\n",
    "# Convert parquet file to a DataFrame\n",
    "frames_df = pd.read_parquet(file_path_match).iloc[1000:10000]\n",
    "\n",
    "# Make the prediction\n",
    "model_name = \"LSTM_best_v1\"\n",
    "frames_df = make_predictions(frames_df, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3506b3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_prediction_animation(frames_df, 300, 380, model_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "My Python",
   "language": "python",
   "name": "my_python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
