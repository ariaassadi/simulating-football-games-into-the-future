{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c078666b",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa43b454-7b17-42fc-be8a-de1770ba3a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-18 14:37:11.767828: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import glob\n",
    "import os\n",
    "\n",
    "from add_features import add_xy_future, add_velocity_xy, add_acceleration_xy, add_average_velocity, add_orientation, add_ball_in_motion, add_distance_to_ball, add_angle_to_ball, add_offside, load_FM_data, add_FM_data, add_tiredness, add_tiredness_short_term\n",
    "from visualize_game import visualize_game_animation, visualize_prediction_animation\n",
    "from utils import google_sheet_to_df, load_processed_frames, extract_variables, load_tf_model, prepare_EL_input_data, prepare_df, total_error_loss, smooth_predictions_xy, run_model\n",
    "from settings import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9ceda5",
   "metadata": {},
   "source": [
    "### Necessary columns\n",
    "| Column Name    | Description                                        |\n",
    "|----------------|----------------------------------------------------|\n",
    "| player         | The name of the player                             |\n",
    "| jersey_number  | The jersey number of the player                    |\n",
    "| team           | 'home_team', 'away_team', or 'ball'                |\n",
    "| team_name      | The team of the player                             |\n",
    "| period         | The period of the game (1 or 2)                    |\n",
    "| minute         | The minute of the game                             |\n",
    "| second         | The second within the current minute               |\n",
    "| frame          | The frame of the game                              |\n",
    "| distance_ran   | The cumulative distance covered by the player      |\n",
    "| x              | The x-coordinate of the player                     |\n",
    "| y              | The y-coordinate of the player                     |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc047404",
   "metadata": {},
   "source": [
    "## Define make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0022d7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add all features\n",
    "def add_all_features(frames_df):\n",
    "    # Add the following features\n",
    "    frames_df = add_xy_future(frames_df, FPS * seconds_into_the_future)\n",
    "    frames_df = add_velocity_xy(frames_df, 1, smooth=True)\n",
    "    frames_df = add_acceleration_xy(frames_df, 1, smooth=True)\n",
    "    frames_df = add_average_velocity(frames_df)\n",
    "    frames_df = add_orientation(frames_df)\n",
    "    frames_df = add_ball_in_motion(frames_df)\n",
    "    frames_df = add_distance_to_ball(frames_df)\n",
    "    frames_df = add_angle_to_ball(frames_df)\n",
    "    frames_df = add_offside(frames_df)\n",
    "    frames_df = add_FM_data(frames_df, load_FM_data())\n",
    "    frames_df = add_tiredness(frames_df)\n",
    "    frames_df = add_tiredness_short_term(frames_df, window=FPS*20)\n",
    "\n",
    "    return frames_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "547d39c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage: run_model(test_frames_dfs, \"NN_model_v1\") \n",
    "def run_model(frames_dfs, model_name):\n",
    "    # Load varibles\n",
    "    numerical_cols, categorical_cols, positions, sequence_length = extract_variables(model_name)\n",
    "\n",
    "    # Load model\n",
    "    model = load_tf_model(f\"models/{model_name}.h5\", euclidean_distance_loss=True)\n",
    "\n",
    "    # Prepare the input data for LSTM model\n",
    "    if \"LSTM\" in model_name:\n",
    "        # Prepare data for LSTM\n",
    "        prepared_frames_df = prepare_LSTM_df(frames_dfs, numerical_cols, categorical_cols, sequence_length, positions)\n",
    "\n",
    "        # # Only keep rows that can be sequentialized\n",
    "        # print(prepared_frames_df)\n",
    "\n",
    "        # # Sort the DataFrame by 'team', 'match_id', and most importantly 'player'\n",
    "        # prepared_frames_df = prepared_frames_df.sort_values(by=['team', 'match_id', 'player'])\n",
    "\n",
    "    # Prepare the input data for non-LSTM model\n",
    "    else:\n",
    "        X_test_input, y_test = prepare_EL_input_data(frames_dfs, numerical_cols, categorical_cols, positions, downsampling_factor=1)\n",
    "\n",
    "        # Prepared the DataFrames and concatenate into a single large DataFrame\n",
    "        prepared_frames_dfs = [prepare_df(frames_df, numerical_cols, categorical_cols, positions=positions, downsampling_factor=1) for frames_df in frames_dfs]\n",
    "        prepared_frames_df = pd.concat(prepared_frames_dfs, ignore_index=True)\n",
    "\n",
    "    # Make predictions using the loaded tf model\n",
    "    predictions = model.predict(X_test_input)\n",
    "\n",
    "    # Extract the predicted values\n",
    "    x_future_pred = predictions[:, 0]\n",
    "    y_future_pred = predictions[:, 1]\n",
    "\n",
    "    # Add the predicted values to 'prepared_frames_df'\n",
    "    prepared_frames_df['x_future_pred'] = x_future_pred\n",
    "    prepared_frames_df['y_future_pred'] = y_future_pred\n",
    "\n",
    "    # Clip values to stay on the pitch\n",
    "    prepared_frames_df['x_future_pred'] = prepared_frames_df['x_future_pred'].clip(lower=0, upper=pitch_length)\n",
    "    prepared_frames_df['y_future_pred'] = prepared_frames_df['y_future_pred'].clip(lower=0, upper=pitch_width)\n",
    "\n",
    "    # Smooth the predicted coordinates\n",
    "    # smooth_predictions_xy(frames_df, alpha=0.98)\n",
    "\n",
    "    return prepared_frames_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28974278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the vectors 'x_future_pred' and 'y_future_pred' on frames_df\n",
    "def make_predictions(frames_df, model_name):\n",
    "    # Prepare the DataFrame by adding all features\n",
    "    frames_df = add_all_features(frames_df)\n",
    "\n",
    "    # Run the model and add the vectors 'x_future_pred' and 'y_future_pred' to frames_df\n",
    "    frames_df = run_model([frames_df], model_name)\n",
    "\n",
    "    # Calculate the error\n",
    "    error = total_error_loss(frames_df)\n",
    "    print(f\"Error: {error}\")\n",
    "\n",
    "    return frames_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d69186",
   "metadata": {},
   "source": [
    "## Example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33a0fe33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-18 14:37:45.427398: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 31133 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:8a:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105135/105135 [==============================] - 65s 609us/step\n",
      "Error: 2.843\n"
     ]
    }
   ],
   "source": [
    "# Example match\n",
    "DATA_FOLDER_UNPROCESSED = f\"{DATA_LOCAL_FOLDER}/data/2023/Allsvenskan/unprocessed\"\n",
    "match_id = '8ef97096-db3b-4597-8dfb-3bca4e69586b'\n",
    "file_path_match = f\"{DATA_FOLDER_UNPROCESSED}/{match_id}.parquet\"\n",
    "\n",
    "# Convert parquet file to a DataFrame\n",
    "frames_df = pd.read_parquet(file_path_match)\n",
    "\n",
    "# Make the prediction\n",
    "frames_df = make_predictions(frames_df, \"NN_best_v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3506b3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_prediction_animation(frames_df, 1100, 1200, \"NN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07441d45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['team', 'team_name', 'team_direction', 'jersey_number', 'player',\n",
       "       'role', 'distance_ran', 'x', 'y', 'frame', 'minute', 'second', 'period',\n",
       "       'events', 'objects_tracked', 'x_future', 'y_future', 'v_x', 'v_y',\n",
       "       'a_x', 'a_y', 'v_x_avg', 'v_y_avg', 'orientation', 'ball_in_motion',\n",
       "       'distance_to_ball', 'angle_to_ball', 'offside', 'nationality', 'height',\n",
       "       'weight', 'acc', 'pac', 'sta', 'position', 'tiredness',\n",
       "       'tiredness_short', 'x_future_pred', 'y_future_pred', 'pred_error'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f714f1d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'match_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m [\u001b[39m1\u001b[39m, \u001b[39m0.99\u001b[39m, \u001b[39m0.90\u001b[39m, \u001b[39m0.80\u001b[39m, \u001b[39m0.60\u001b[39m]:\n\u001b[0;32m----> 2\u001b[0m     frames_smooth_df \u001b[39m=\u001b[39m smooth_predictions_xy(frames_df\u001b[39m.\u001b[39;49mcopy(), alpha\u001b[39m=\u001b[39;49m\u001b[39m0.98\u001b[39;49m)\n\u001b[1;32m      4\u001b[0m     \u001b[39m# Calculate the error\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     error \u001b[39m=\u001b[39m total_error_loss(frames_smooth_df)\n",
      "File \u001b[0;32m~/football/simulating-football-games-into-the-future/simulation/utils.py:457\u001b[0m, in \u001b[0;36msmooth_predictions_xy\u001b[0;34m(frames_df, alpha)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msmooth_predictions_xy\u001b[39m(frames_df, alpha\u001b[39m=\u001b[39m\u001b[39m0.93\u001b[39m):\n\u001b[1;32m    456\u001b[0m     \u001b[39m# Group by unique combinations of 'team', 'jersey_number', and 'match_id'\u001b[39;00m\n\u001b[0;32m--> 457\u001b[0m     grouped \u001b[39m=\u001b[39m frames_df\u001b[39m.\u001b[39;49mgroupby([\u001b[39m'\u001b[39;49m\u001b[39mteam\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mjersey_number\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mmatch_id\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m    459\u001b[0m     \u001b[39m# Apply the Exponential Moving Average filter to smooth the predictions\u001b[39;00m\n\u001b[1;32m    460\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mapply_ema\u001b[39m(x):\n",
      "File \u001b[0;32m/apps/Arch/software/SciPy-bundle/2022.05-foss-2022a/lib/python3.10/site-packages/pandas/core/frame.py:7712\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, squeeze, observed, dropna)\u001b[0m\n\u001b[1;32m   7707\u001b[0m axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_axis_number(axis)\n\u001b[1;32m   7709\u001b[0m \u001b[39m# https://github.com/python/mypy/issues/7642\u001b[39;00m\n\u001b[1;32m   7710\u001b[0m \u001b[39m# error: Argument \"squeeze\" to \"DataFrameGroupBy\" has incompatible type\u001b[39;00m\n\u001b[1;32m   7711\u001b[0m \u001b[39m# \"Union[bool, NoDefault]\"; expected \"bool\"\u001b[39;00m\n\u001b[0;32m-> 7712\u001b[0m \u001b[39mreturn\u001b[39;00m DataFrameGroupBy(\n\u001b[1;32m   7713\u001b[0m     obj\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   7714\u001b[0m     keys\u001b[39m=\u001b[39;49mby,\n\u001b[1;32m   7715\u001b[0m     axis\u001b[39m=\u001b[39;49maxis,\n\u001b[1;32m   7716\u001b[0m     level\u001b[39m=\u001b[39;49mlevel,\n\u001b[1;32m   7717\u001b[0m     as_index\u001b[39m=\u001b[39;49mas_index,\n\u001b[1;32m   7718\u001b[0m     sort\u001b[39m=\u001b[39;49msort,\n\u001b[1;32m   7719\u001b[0m     group_keys\u001b[39m=\u001b[39;49mgroup_keys,\n\u001b[1;32m   7720\u001b[0m     squeeze\u001b[39m=\u001b[39;49msqueeze,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   7721\u001b[0m     observed\u001b[39m=\u001b[39;49mobserved,\n\u001b[1;32m   7722\u001b[0m     dropna\u001b[39m=\u001b[39;49mdropna,\n\u001b[1;32m   7723\u001b[0m )\n",
      "File \u001b[0;32m/apps/Arch/software/SciPy-bundle/2022.05-foss-2022a/lib/python3.10/site-packages/pandas/core/groupby/groupby.py:882\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, observed, mutated, dropna)\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[39mif\u001b[39;00m grouper \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    880\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgroupby\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgrouper\u001b[39;00m \u001b[39mimport\u001b[39;00m get_grouper\n\u001b[0;32m--> 882\u001b[0m     grouper, exclusions, obj \u001b[39m=\u001b[39m get_grouper(\n\u001b[1;32m    883\u001b[0m         obj,\n\u001b[1;32m    884\u001b[0m         keys,\n\u001b[1;32m    885\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[1;32m    886\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[1;32m    887\u001b[0m         sort\u001b[39m=\u001b[39;49msort,\n\u001b[1;32m    888\u001b[0m         observed\u001b[39m=\u001b[39;49mobserved,\n\u001b[1;32m    889\u001b[0m         mutated\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmutated,\n\u001b[1;32m    890\u001b[0m         dropna\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropna,\n\u001b[1;32m    891\u001b[0m     )\n\u001b[1;32m    893\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj \u001b[39m=\u001b[39m obj\n\u001b[1;32m    894\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39m_get_axis_number(axis)\n",
      "File \u001b[0;32m/apps/Arch/software/SciPy-bundle/2022.05-foss-2022a/lib/python3.10/site-packages/pandas/core/groupby/grouper.py:882\u001b[0m, in \u001b[0;36mget_grouper\u001b[0;34m(obj, key, axis, level, sort, observed, mutated, validate, dropna)\u001b[0m\n\u001b[1;32m    880\u001b[0m         in_axis, level, gpr \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m, gpr, \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    881\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 882\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(gpr)\n\u001b[1;32m    883\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(gpr, Grouper) \u001b[39mand\u001b[39;00m gpr\u001b[39m.\u001b[39mkey \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    884\u001b[0m     \u001b[39m# Add key to exclusions\u001b[39;00m\n\u001b[1;32m    885\u001b[0m     exclusions\u001b[39m.\u001b[39madd(gpr\u001b[39m.\u001b[39mkey)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'match_id'"
     ]
    }
   ],
   "source": [
    "for i in [1, 0.99, 0.90, 0.80, 0.60]:\n",
    "    frames_smooth_df = smooth_predictions_xy(frames_df.copy(), alpha=0.98)\n",
    "\n",
    "    # Calculate the error\n",
    "    error = total_error_loss(frames_smooth_df)\n",
    "    print(f\"Error: {error} with alpha={i}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "My Python",
   "language": "python",
   "name": "my_python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
