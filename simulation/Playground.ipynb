{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playground for Exploring the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-10 16:30:32.042970: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from collections import OrderedDict\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import json\n",
    "import glob\n",
    "import os\n",
    "\n",
    "from utils import load_processed_frames, prepare_LSTM_input_data\n",
    "from settings import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the frames\n",
    "test_id = 'd762199f-8457-4066-b744-09e115f6884d'\n",
    "frames_df = load_processed_frames(match_id=test_id)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Playing Around"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store as xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store frames_df as xslx\n",
    "frames_df_head = frames_df.head(19979)\n",
    "\n",
    "# Specify the file path for the Excel file\n",
    "excel_file_path = f\"{DATA_LOCAL_FOLDER}/Brommapojkarna_vs_Sirius.xlsx\"\n",
    "\n",
    "# Write the DataFrame to an Excel file\n",
    "frames_df_head.to_excel(excel_file_path, index=False)\n",
    "\n",
    "print(f\"DataFrame saved to {excel_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract all unique player names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a set to store unique player names along with their teams\n",
    "player_names = set()\n",
    "\n",
    "# Iterate through each game DataFrame\n",
    "for frames_df in frames_list:\n",
    "    # Extract unique player names and their teams\n",
    "    players = frames_df[['player', 'team_name']].drop_duplicates()\n",
    "    \n",
    "    # Update the set of unique player names\n",
    "    player_names.update(zip(players['player'], players['team_name']))\n",
    "\n",
    "# Convert to a DataFrame\n",
    "players_df = pd.DataFrame(list(player_names), columns=['Player', 'Team'])\n",
    "\n",
    "# Sort values\n",
    "players_df = players_df.sort_values(by=['Player', 'Team'], ascending=[True, True])\n",
    "\n",
    "# Store as xlsx\n",
    "players_df.to_excel(f\"{DATA_LOCAL_FOLDER}/data/players/Players_2023.xlsx\", index=False)\n",
    "\n",
    "players_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only used buildup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the file as a DataFrame\n",
    "build_up_events_df = pd.read_csv(f\"{DATA_LOCAL_FOLDER}/data/buildup_events_2023.csv\")\n",
    "build_up_df = pd.read_csv(f\"{DATA_LOCAL_FOLDER}/data/buildup_synced_2023.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build_up_events_df.iloc[0:20]\n",
    "# for column in build_up_events_df.columns:\n",
    "#     print(column)\n",
    "possession_cols = [\n",
    "    'possession_set_piece_attack',\n",
    "    'possession_attack',\n",
    "    'possession_free_kick',\n",
    "    'possession_corner',\n",
    "    'possession_throw_in',\n",
    "    'possession_transition_low',\n",
    "    'possession_free_kick_cross',\n",
    "    'possession_transition_high',\n",
    "    'possession_transition_medium',\n",
    "    'possession_counterattack',\n",
    "    'possession_direct_free_kick',\n",
    "    'possession_penalty'\n",
    "]\n",
    "\n",
    "build_up_ev_ef = build_up_events_df.copy()\n",
    "\n",
    "build_up_ev_ef = build_up_ev_ef[build_up_ev_ef['first_event']]\n",
    "build_up_ev_ef['possession_duration']  = (np.floor(build_up_ev_ef['possession_duration'])).astype(int)\n",
    "build_up_ev_ef['match_time_event_start'] = build_up_ev_ef['match_time']\n",
    "build_up_ev_ef['match_time_event_end'] = build_up_ev_ef['match_time'] + build_up_ev_ef['possession_duration']\n",
    "build_up_ev_ef[['match_id', 'minute', 'second', 'match_time_event_start', 'match_time_event_end','possession_duration']]\n",
    "build_up_ev_ef = build_up_ev_ef[build_up_ev_ef['match_id'] == 5420660]\n",
    "build_up_ev_ef[possession_cols + ['minute', 'second', 'match_time_event_start', 'match_time_event_end','possession_duration']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'match_id' and sum 'possession_duration' for each group\n",
    "match_possession_duration = build_up_ev_ef.groupby('match_id')['possession_duration'].sum().reset_index()\n",
    "\n",
    "# Calculate the average possession duration\n",
    "average_possession_duration = match_possession_duration['possession_duration'].mean()\n",
    "\n",
    "# Display the average possession duration\n",
    "print(\"Average Possession Duration:\", average_possession_duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in build_up_events_df.columns:\n",
    "    print(column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use a smaller frames_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import old_utils as old\n",
    "sequence_length=10\n",
    "numerical_cols=['x', 'y', 'v_x', 'v_y', 'a_x', 'a_y', 'distance_to_ball', 'tiredness']\n",
    "categorical_cols=['position']\n",
    "positions=['Attacking Midfielder', 'Central Midfielder', 'Centre-Back', 'Defensive Midfielder', 'Forward', 'Full-Back', 'Goalkeeper', 'Wide Midfielder', 'Winger']\n",
    "downsampling_factor = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_df = frames_df\n",
    "small_df = small_df[small_df['frame'] % 5 == 0]\n",
    "small_df = small_df[small_df['position'] == 'Central Midfielder']#.iloc[10:20]\n",
    "small_df['x'] = round(small_df['x'], 1)\n",
    "small_df['y'] = round(small_df['y'], 1)\n",
    "small_df['v_x'] = round(small_df['v_x'], 1)\n",
    "\n",
    "numerical_cols = ['x', 'y', 'v_x']\n",
    "small_df['numerical_cols_list'] = small_df[numerical_cols].values.tolist()\n",
    "# small_df[['player', 'team_name', 'frame', 'x', 'y', 'v_x', 'x_future', 'y_future', 'can_be_sequentialized']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize add_can_be_seq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_can_be_sequentialized(frames_df, sequence_length, downsampling_factor):\n",
    "    # Initialize vector\n",
    "    frames_df['can_be_sequentialized'] = False\n",
    "\n",
    "    # Create temporary vectors with the expected frame for each sequence step\n",
    "    for i in range(sequence_length):\n",
    "        frames_df[f'sequence_step_{i}'] = frames_df['frame'] - i * downsampling_factor\n",
    "\n",
    "    # Group by each unique player\n",
    "    grouped = frames_df.groupby(['team', 'jersey_number', 'match_id'])\n",
    "\n",
    "    # Iterate through each group and find if we can create sequences\n",
    "    for _, group in grouped:\n",
    "        # Convert the frame column to a set for efficient lookups\n",
    "        frame_set = set(group['frame'])\n",
    "\n",
    "        # Check if all sequence steps exist\n",
    "        group['temp_sequential'] = group.apply(\n",
    "            lambda x: all((x[f'sequence_step_{i}'] in frame_set) for i in range(sequence_length)),\n",
    "            axis=1\n",
    "        )\n",
    "\n",
    "        # Update the main DataFrame\n",
    "        frames_df.loc[group.index, 'can_be_sequentialized'] = group['temp_sequential']\n",
    "\n",
    "    # Drop temporary columns\n",
    "    frames_df.drop(columns=[f'sequence_step_{i}' for i in range(sequence_length)], inplace=True)\n",
    "\n",
    "    return frames_df\n",
    "\n",
    "# Add a vector indicating if the row can be sequentialized, i.e. the player has 'sequence_length' consecutive frames\n",
    "def add_can_be_sequentialized_opt(frames_df, sequence_length, downsampling_factor):\n",
    "    # Initialize vector\n",
    "    frames_df['can_be_sequentialized'] = False\n",
    "\n",
    "    # Create temporary vectors with the expexted frame for each sequence step\n",
    "    for i in range(sequence_length):\n",
    "        frames_df[f'sequence_step_{i}'] = frames_df['frame'] - i * downsampling_factor\n",
    "\n",
    "    # Group by each unique player\n",
    "    grouped = frames_df.groupby(['team', 'jersey_number', 'match_id'])\n",
    "\n",
    "    # Iterate through each player and find if we can create sequences\n",
    "    for _, group in grouped:\n",
    "        # Convert the frame column to a set for efficient lookups\n",
    "        frame_set = set(group['frame'])\n",
    "\n",
    "        # Create temporary columns indicating if each step in the sequences exists\n",
    "        for i in range(sequence_length):\n",
    "            group[f'sequence_step_exists_{i}'] = group[f'sequence_step_{i}'].isin(frame_set)\n",
    "\n",
    "        # Aggregate 'sequence_step_exists_' checks to set 'can_be_sequentialized'\n",
    "        sequence_steps_exist_cols = [f'sequence_step_exists_{i}' for i in range(sequence_length)]\n",
    "        group['can_be_sequentialized'] = group[sequence_steps_exist_cols].all(axis=1)\n",
    "\n",
    "        # Update the main DataFrame\n",
    "        frames_df.loc[group.index, 'can_be_sequentialized'] = group['can_be_sequentialized']\n",
    "    \n",
    "    # Drop temporary columns\n",
    "    frames_df.drop(columns=[f'sequence_step_{i}' for i in range(sequence_length)], inplace=True)\n",
    "\n",
    "    return frames_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_df = frames_df[frames_df['frame'] % 5 == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames_df.equals(frames_df_opt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8 (default, Jan 15 2024, 23:09:02) \n[GCC 8.5.0 20210514 (Red Hat 8.5.0-20)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
