{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35312186",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c078666b",
   "metadata": {},
   "source": [
    "# Notebook for training predictive models\n",
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa43b454-7b17-42fc-be8a-de1770ba3a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-08 17:47:21.244687: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Embedding, Flatten, Dense, Concatenate\n",
    "from tensorflow.keras.models import load_model as keras_load_model\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.pipeline import Pipeline\n",
    "from keras.models import Sequential\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import glob\n",
    "import os\n",
    "\n",
    "from utils import load_processed_frames, split_match_ids, euclidean_distance_loss, total_error_loss, smooth_predictions_xy, extract_variables, load_tf_model, prepare_df, prepare_EL_input_data, add_can_be_sequentialized\n",
    "from visualize_game import visualize_frame_prediction, visualize_prediction_animation, visualize_game_animation\n",
    "from settings import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06d4855",
   "metadata": {},
   "source": [
    "### Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f65b211e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_matches = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ef43b7",
   "metadata": {},
   "source": [
    "### Load frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98345c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load every frames_df to a list\n",
    "frames_dfs = load_processed_frames(n_matches=n_matches)\n",
    "\n",
    "# Create an internal match_id for each game\n",
    "match_ids = range(n_matches)\n",
    "\n",
    "# Split match IDs into train, test, and validation sets\n",
    "train_ids, test_ids, val_ids = split_match_ids(match_ids=match_ids)\n",
    "\n",
    "# Select frames data for training, testing, and validation\n",
    "# train_frames_dfs = [frames_dfs[i] for i in train_ids]\n",
    "test_frames_dfs = [frames_dfs[i] for i in test_ids]\n",
    "# val_frames_dfs = [frames_dfs[i] for i in val_ids]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b196e924",
   "metadata": {},
   "source": [
    "## Define NAIVE models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1746338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NAIVE: Always predict that all players will stand still\n",
    "# The calculations are based on x, y\n",
    "def predict_two_seconds_naive_static(frames_df):\n",
    "    frames_df['x_future_pred'] = frames_df['x']\n",
    "    frames_df['y_future_pred'] = frames_df['y']\n",
    "\n",
    "# NAIVE: Always predict that all players will continue with the same velocity\n",
    "# The calculations are based on x, y, v_x, and v_y\n",
    "def predict_two_seconds_naive_velocity(frames_df):\n",
    "    frames_df['x_future_pred'] = frames_df['x'] + frames_df['v_x'] * seconds_into_the_future\n",
    "    frames_df['y_future_pred'] = frames_df['y'] + frames_df['v_y'] * seconds_into_the_future\n",
    "\n",
    "    # Clip values to stay on the pitch\n",
    "    frames_df['x_future_pred'] = frames_df['x_future_pred'].clip(lower=0, upper=pitch_length)\n",
    "    frames_df['y_future_pred'] = frames_df['y_future_pred'].clip(lower=0, upper=pitch_width)\n",
    "\n",
    "    # Smooth the predicted coordinates\n",
    "    smooth_predictions_xy(frames_df, alpha=0.95)\n",
    "\n",
    "# NAIVE: Always predict that all players will continue with the same velocity and acceleration\n",
    "# The calculations are based on x, y, v_x, v_y, a_x, and a_y\n",
    "def predict_two_seconds_naive_acceleration(frames_df):\n",
    "    # Calculate future positions using kinematic equationsnaive_\n",
    "    frames_df['x_future_pred'] = frames_df['x'] + frames_df['v_x'] * seconds_into_the_future + 0.5 * frames_df['a_x'] * (seconds_into_the_future ** 2)\n",
    "    frames_df['y_future_pred'] = frames_df['y'] + frames_df['v_y'] * seconds_into_the_future + 0.5 * frames_df['a_y'] * (seconds_into_the_future ** 2)\n",
    "\n",
    "    # Clip values to stay on the pitch\n",
    "    frames_df['x_future_pred'] = frames_df['x_future_pred'].clip(lower=0, upper=pitch_length)\n",
    "    frames_df['y_future_pred'] = frames_df['y_future_pred'].clip(lower=0, upper=pitch_width)\n",
    "\n",
    "    # Smooth the predicted coordinates\n",
    "    smooth_predictions_xy(frames_df, alpha=0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f24a32",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fca989a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average error for a list of games\n",
    "def calculate_average_error(frames_dfs, predict_function, include_ball, ball_has_to_be_in_motion):\n",
    "    # Predict the future positions\n",
    "    [predict_function(frames_df) for frames_df in frames_dfs]\n",
    "    [add_pred_error(frames_df) for frames_df in frames_dfs]\n",
    "\n",
    "    # Concatenate all frames dataframes into a single dataframe\n",
    "    concatted_frames_df = pd.concat(frames_dfs)    \n",
    "    \n",
    "    # Calculate the total error loss\n",
    "    error = total_error_loss(concatted_frames_df, include_ball, ball_has_to_be_in_motion)\n",
    "    \n",
    "    return error\n",
    "\n",
    "# Find a frame with approximatly the same error as the average_pred_error, with an interval\n",
    "def find_frame_with_average_error(frames_df, average_pred_error, error_margin):\n",
    "    # For all frames\n",
    "    frames = frames_df['frame'].unique()\n",
    "    for frame in frames:\n",
    "        current_error = frames_df[frames_df['frame'] == frame]['pred_error'].mean()\n",
    "        # If the current error is within the error_margin,\n",
    "        if (current_error >= average_pred_error - error_margin) and (current_error <= average_pred_error + error_margin):\n",
    "            # Return the result\n",
    "            return frame\n",
    "\n",
    "    # If no frame was found\n",
    "    print(f\"No frame found within the error margin of {error_margin}\")\n",
    "    return None\n",
    "\n",
    "# Use a naive model to make predictions on a set of games, and calculate the error\n",
    "def predict_and_evaluate_naive_model(naive_model, frames_dfs, include_ball=False, ball_has_to_be_in_motion=True):\n",
    "    # Concatenate the frames DataFrames into a single large DataFrame\n",
    "    frames_concatenated_df = pd.concat(frames_dfs, ignore_index=True)\n",
    "\n",
    "    # Use the custom function to make the predictions\n",
    "    naive_model(frames_concatenated_df)\n",
    "\n",
    "    # Calculate error\n",
    "    error = total_error_loss(frames_concatenated_df, include_ball, ball_has_to_be_in_motion)\n",
    "\n",
    "    return error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4863d61c",
   "metadata": {},
   "source": [
    "## Evaulate NAIVE models\n",
    "### Visualize prediction errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3656ce64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Visualize the predictions of the naive velocity model in an animation\n",
    "# test_frames_df = train_frames_dfs[3]\n",
    "# predict_two_seconds_naive_static(test_frames_df)\n",
    "# total_error_loss(test_frames_df)\n",
    "# visualize_prediction_animation(test_frames_df, 250, 750, \"naive_static\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5e72fe",
   "metadata": {},
   "source": [
    "### Evaulate the NAIVE models with different parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ca1231f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Include Ball</th>\n",
       "      <th>Ball in Motion</th>\n",
       "      <th>Naive Static</th>\n",
       "      <th>Naive Velocity</th>\n",
       "      <th>Naive Acceleration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>4.069</td>\n",
       "      <td>2.148</td>\n",
       "      <td>2.117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Include Ball  Ball in Motion  Naive Static  Naive Velocity  \\\n",
       "0         False            True         4.069           2.148   \n",
       "\n",
       "   Naive Acceleration  \n",
       "0               2.117  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the prediction functions (models) you want to test\n",
    "prediction_functions = {\n",
    "    \"Naive Static\": predict_two_seconds_naive_static,\n",
    "    \"Naive Velocity\": predict_two_seconds_naive_velocity,\n",
    "    \"Naive Acceleration\": predict_two_seconds_naive_acceleration\n",
    "}\n",
    "\n",
    "# Define the combinations of include_ball and ball_has_to_be_in_motion\n",
    "# combinations = [(True, True), (True, False), (False, True), (False, False)]\n",
    "combinations = [(False, True)]\n",
    "\n",
    "# Initialize an empty list to store the results\n",
    "results = []\n",
    "\n",
    "# Loop through each combination\n",
    "for include_ball, ball_has_to_be_in_motion in combinations:\n",
    "    # Add the combination of parameters\n",
    "    result = {\"Include Ball\": include_ball, \"Ball in Motion\": ball_has_to_be_in_motion}\n",
    "    # Loop through each prediction function (model)\n",
    "    for model_name, predict_function in prediction_functions.items():\n",
    "        # Calculate error for the current prediction function (model)\n",
    "        error = predict_and_evaluate_naive_model(predict_function, test_frames_dfs, include_ball, ball_has_to_be_in_motion)\n",
    "        result[model_name] = error\n",
    "    \n",
    "    # Append the results to the list\n",
    "    results.append(result)\n",
    "\n",
    "# Create a DataFrame from the list of results\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad99574",
   "metadata": {},
   "source": [
    "## Evaluate NN models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0b5fc535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define denominators for normalization\n",
    "denominators = {\n",
    "    'x': pitch_length,\n",
    "    'y': pitch_width,\n",
    "    'v_y': 13,\n",
    "    'v_y': 13,\n",
    "    'a_y': 10,\n",
    "    'a_y': 10,\n",
    "    'acc': 20,\n",
    "    'pac': 20,\n",
    "    'sta': 20,\n",
    "    'height': 2.10,\n",
    "    'weight': 110,\n",
    "    'distance_to_ball': round(np.sqrt((pitch_length**2 + pitch_width**2)), 2),\n",
    "    'angle_to_ball': 360,\n",
    "    'orientation': 360,\n",
    "    'tiredness': 10,\n",
    "    'minute': 45,\n",
    "    'period': 2,\n",
    "}\n",
    "y_cols = ['x_future', 'y_future']\n",
    "\n",
    "\"\"\" Dont include the above \"\"\"\n",
    "\n",
    "# Add the columns 'sequential_numerical_data', 'sequential_categorical_data', and 'future_xy' as arrays\n",
    "def add_sequentialized_data(X_df, numerical_cols, categorical_cols, sequence_length, downsampling_factor):\n",
    "    # Combine the values in y_df with X_df\n",
    "    X_df['future_xy'] = X_df[y_cols].values.tolist()\n",
    "\n",
    "    # Create a vector containing a list of all values in the numerical columns\n",
    "    X_df['numerical_data_list'] = X_df[numerical_cols].values.tolist()\n",
    "    \n",
    "    # Create a similar list for the categorical columns, if any\n",
    "    if categorical_cols:\n",
    "        X_df['categorical_data_list'] = X_df[categorical_cols].apply(lambda x: x.tolist(), axis=1)\n",
    "\n",
    "    # Add vector 'can_be_sequentialized'\n",
    "    add_can_be_sequentialized(X_df, sequence_length=sequence_length)\n",
    "\n",
    "    # Group by each unique player\n",
    "    grouped = X_df.groupby(['team', 'jersey_number', 'match_id'])\n",
    "\n",
    "    # Iterate through each player and create sequences\n",
    "    for _, group in grouped:\n",
    "        # Create temporary columns with shifted version of 'numerical_cols' and 'categorical_cols'\n",
    "        # Shift it with the downsampling_factor since that is how the training process works\n",
    "        for i in range(sequence_length):\n",
    "            group[f'numerical_data_list_{i}'] = group[\"numerical_data_list\"].shift(i * downsampling_factor)\n",
    "\n",
    "        # Concatenate the temporary columns to create the column 'sequential_numerical_data'\n",
    "        columns_to_sequentialize = [f'numerical_data_list_{i}' for i in range(sequence_length)][::-1]\n",
    "        group['sequential_numerical_data'] = group[columns_to_sequentialize].values.tolist()\n",
    "        \n",
    "        print(group[['player', 'frame', 'future_xy', 'can_be_sequentialized']])\n",
    "\n",
    "        # Only consider rows that can be sequentialized\n",
    "        group = group[group['can_be_sequentialized']]\n",
    "\n",
    "        # Add the sequentialized data to X_df using loc\n",
    "        X_df.loc[group.index, 'sequential_numerical_data'] = group['sequential_numerical_data']\n",
    "        \n",
    "        if categorical_cols:\n",
    "            X_df.loc[group.index, 'sequential_categorical_data'] = group['categorical_data_list']\n",
    "\n",
    "    return X_df\n",
    "\n",
    "def prepare_LSTM_evaluation_input_data(X_df, numerical_cols, categorical_cols, sequence_length, positions=[]):\n",
    "    # Apply label encoding to categorical variables\n",
    "    for col in categorical_cols:\n",
    "        label_encoder = LabelEncoder()\n",
    "        X_df[col] = label_encoder.fit_transform(X_df[col])\n",
    "\n",
    "    # Apply custom normalization\n",
    "    for col in numerical_cols:\n",
    "        if col in denominators:\n",
    "            X_df[col] = X_df[col] / denominators[col]\n",
    "\n",
    "    # Convert categorical columns to int\n",
    "    X_df[categorical_cols] = X_df[categorical_cols].astype('int8')\n",
    "\n",
    "    # Convert numerical columns to float\n",
    "    X_df[numerical_cols] = X_df[numerical_cols].astype('float32')\n",
    "\n",
    "    # Add vectors with sequentialized data\n",
    "    X_df = add_sequentialized_data(X_df, numerical_cols, categorical_cols, sequence_length, downsampling_factor)\n",
    "\n",
    "    # print(X_df[['player', 'frame', 'future_xy', 'sequential_numerical_data']])\n",
    "\n",
    "    # Create Pandas Series\n",
    "    y_seq = X_df[X_df['can_be_sequentialized']]['future_xy']\n",
    "    X_seq_num = X_df[X_df['can_be_sequentialized']]['sequential_numerical_data']\n",
    "    X_seq_cat = X_df[X_df['can_be_sequentialized']]['sequential_categorical_data']\n",
    "\n",
    "    # Convert the Pandas Series of lists to a NumPy array\n",
    "    X_seq_num_np = np.array(X_seq_num.tolist()).astype('float32')\n",
    "    y_seq_np = np.array(y_seq.tolist()).astype('float32')\n",
    "\n",
    "    # Add the data from categorical columns to X_seq_np\n",
    "    if categorical_cols:\n",
    "        X_seq_cat_np = np.array(X_seq_cat.tolist()).astype('float32')\n",
    "        X_seq_np = [X_seq_cat_np, X_seq_num_np]\n",
    "\n",
    "        return X_seq_np, y_seq_np\n",
    "\n",
    "    # Return the resuls without adding categorical data\n",
    "    else:\n",
    "        return X_seq_num_np, y_seq_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "29080973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage: run_model(test_frames_dfs, \"NN_model_v1\") \n",
    "def run_model(frames_dfs, model_name):\n",
    "    # Load varibles\n",
    "    numerical_cols, categorical_cols, positions, sequence_length = extract_variables(model_name)\n",
    "\n",
    "    # Load model\n",
    "    model = load_tf_model(f\"models/{model_name}.h5\", euclidean_distance_loss=True)\n",
    "\n",
    "    # Prepare the input data for LSTM model\n",
    "    if \"LSTM\" in model_name:\n",
    "        # Prepared the DataFrames and concatenate into a single large DataFrame\n",
    "        prepared_frames_dfs = [prepare_df(frames_df, numerical_cols, categorical_cols, positions=positions, downsampling_factor=1) for frames_df in frames_dfs]\n",
    "        frames_concat_df = pd.concat(prepared_frames_dfs, ignore_index=True)\n",
    "\n",
    "        # Preapre input data for LSTM evaluation \n",
    "        X_test_input, y_test = prepare_LSTM_evaluation_input_data(frames_concat_df, numerical_cols, categorical_cols, sequence_length)\n",
    "\n",
    "        print(\"Prepare step completed\")\n",
    "\n",
    "        # Make predictions using the loaded tf model\n",
    "        predictions = model.predict(X_test_input)\n",
    "\n",
    "        # Extract the predicted values\n",
    "        x_future_pred = predictions[:, 0]\n",
    "        y_future_pred = predictions[:, 1]\n",
    "\n",
    "        # Add the predicted values to 'frames_concat_df'\n",
    "        frames_concat_df.loc[frames_concat_df['can_be_sequentialized'], 'x_future_pred'] = x_future_pred#.clip(lower=0, upper=pitch_length)\n",
    "        frames_concat_df.loc[frames_concat_df['can_be_sequentialized'], 'y_future_pred'] = y_future_pred#.clip(lower=0, upper=pitch_width)\n",
    "\n",
    "    # Prepare the input data for non-LSTM model\n",
    "    else:\n",
    "        # Prepared the DataFrames and concatenate into a single large DataFrame\n",
    "        prepared_frames_dfs = [prepare_df(frames_df, numerical_cols, categorical_cols, positions=positions, downsampling_factor=downsampling_factor) for frames_df in frames_dfs]\n",
    "        frames_concat_df = pd.concat(prepared_frames_dfs, ignore_index=True)\n",
    "\n",
    "        X_test_input, y_test = prepare_EL_input_data(frames_dfs, numerical_cols, categorical_cols, positions)\n",
    "\n",
    "        # Make predictions using the loaded tf model\n",
    "        predictions = model.predict(X_test_input)\n",
    "\n",
    "        # Extract the predicted values\n",
    "        x_future_pred = predictions[:, 0]\n",
    "        y_future_pred = predictions[:, 1]\n",
    "\n",
    "        # Add the predicted values to 'frames_concat_df'\n",
    "        frames_concat_df.loc['x_future_pred'] = x_future_pred#.clip(lower=0, upper=pitch_length)\n",
    "        frames_concat_df.loc['y_future_pred'] = y_future_pred#.clip(lower=0, upper=pitch_width)\n",
    "\n",
    "    return frames_concat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6f8fd5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_df = test_frames_dfs[0]\n",
    "# frames_df = frames_df[frames_df['frame'] % 5 == 0]\n",
    "frames_df = frames_df[frames_df['team_direction'] == 'right']\n",
    "frames_df = frames_df[frames_df['position'] == \"Goalkeeper\"].iloc[0:15]\n",
    "frames_df['x'] = round(frames_df['x'], 1)\n",
    "frames_df['y'] = round(frames_df['y'], 1)\n",
    "frames_df['v_x'] = round(frames_df['v_x'], 1)\n",
    "\n",
    "add_can_be_sequentialized(frames_df, 10)\n",
    "\n",
    "# frames_df[['player', 'frame', 'x', 'y', 'v_x', 'x_future', 'y_future', 'can_be_sequentialized']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "24a6c45f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "          player  frame      future_xy  can_be_sequentialized\n",
      "0   Johan Dahlin      0  [8.16, 32.98]                  False\n",
      "1   Johan Dahlin      1  [8.16, 32.96]                  False\n",
      "2   Johan Dahlin      2  [8.18, 32.94]                  False\n",
      "3   Johan Dahlin      3  [8.21, 32.94]                  False\n",
      "4   Johan Dahlin      4  [8.25, 32.95]                  False\n",
      "5   Johan Dahlin      5   [8.3, 32.96]                  False\n",
      "6   Johan Dahlin      6  [8.35, 32.98]                  False\n",
      "7   Johan Dahlin      7  [8.42, 33.01]                  False\n",
      "8   Johan Dahlin      8  [8.48, 33.04]                  False\n",
      "9   Johan Dahlin      9  [8.54, 33.07]                  False\n",
      "10  Johan Dahlin     10    [8.6, 33.1]                  False\n",
      "11  Johan Dahlin     11  [8.66, 33.13]                  False\n",
      "12  Johan Dahlin     12   [8.7, 33.16]                  False\n",
      "13  Johan Dahlin     13  [8.74, 33.17]                  False\n",
      "14  Johan Dahlin     14  [8.76, 33.19]                  False\n",
      "Prepare step completed\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unexpected result of `predict_function` (Empty batch_outputs). Please use `Model.compile(..., run_eagerly=True)`, or `tf.config.run_functions_eagerly(True)` for more information of where went wrong, or file a issue/bug to `tf.keras`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [61], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m frames_concat_df \u001b[39m=\u001b[39m run_model([frames_df], \u001b[39m\"\u001b[39;49m\u001b[39mLSTM_model_v3\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn [57], line 21\u001b[0m, in \u001b[0;36mrun_model\u001b[0;34m(frames_dfs, model_name)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mPrepare step completed\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     20\u001b[0m \u001b[39m# Make predictions using the loaded tf model\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m predictions \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(X_test_input)\n\u001b[1;32m     23\u001b[0m \u001b[39m# Extract the predicted values\u001b[39;00m\n\u001b[1;32m     24\u001b[0m x_future_pred \u001b[39m=\u001b[39m predictions[:, \u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m/apps/Arch/software/TensorFlow/2.11.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/apps/Arch/software/TensorFlow/2.11.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/keras/engine/training.py:2375\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   2371\u001b[0m                 callbacks\u001b[39m.\u001b[39mon_predict_batch_end(\n\u001b[1;32m   2372\u001b[0m                     end_step, {\u001b[39m\"\u001b[39m\u001b[39moutputs\u001b[39m\u001b[39m\"\u001b[39m: batch_outputs}\n\u001b[1;32m   2373\u001b[0m                 )\n\u001b[1;32m   2374\u001b[0m     \u001b[39mif\u001b[39;00m batch_outputs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 2375\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   2376\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mUnexpected result of `predict_function` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2377\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m(Empty batch_outputs). Please use \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2378\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m`Model.compile(..., run_eagerly=True)`, or \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2379\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m`tf.config.run_functions_eagerly(True)` for more \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2380\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39minformation of where went wrong, or file a \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2381\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39missue/bug to `tf.keras`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2382\u001b[0m         )\n\u001b[1;32m   2383\u001b[0m     callbacks\u001b[39m.\u001b[39mon_predict_end()\n\u001b[1;32m   2384\u001b[0m all_outputs \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39m__internal__\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mmap_structure_up_to(\n\u001b[1;32m   2385\u001b[0m     batch_outputs, potentially_ragged_concat, outputs\n\u001b[1;32m   2386\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: Unexpected result of `predict_function` (Empty batch_outputs). Please use `Model.compile(..., run_eagerly=True)`, or `tf.config.run_functions_eagerly(True)` for more information of where went wrong, or file a issue/bug to `tf.keras`."
     ]
    }
   ],
   "source": [
    "frames_concat_df = run_model([frames_df], \"LSTM_model_v3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf83e6f4",
   "metadata": {},
   "source": [
    "## Evaluate on different parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be630934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Print column variance for position\n",
    "# column_to_analyze = 'position'\n",
    "# model_name = \"LSTM_model_v9\"\n",
    "# print_column_variance(val_frames_dfs, model_name, column_to_analyze)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "My Python",
   "language": "python",
   "name": "my_python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4 (main, Feb  1 2024, 03:10:29) [GCC 11.3.0]"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
