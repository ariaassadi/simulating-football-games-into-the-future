{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c078666b",
   "metadata": {},
   "source": [
    "# Model Evaluation\n",
    "This notebook contains the test results for each model, how the predictions differ based on parameters such as 'position', and some animated visualisations\n",
    "\n",
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa43b454-7b17-42fc-be8a-de1770ba3a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-02 11:32:24.052078: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Embedding, Flatten, Dense, Concatenate\n",
    "from tensorflow.keras.models import load_model as keras_load_model\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.pipeline import Pipeline\n",
    "from keras.models import Sequential\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import glob\n",
    "import os\n",
    "\n",
    "from utils import load_processed_frames, split_match_ids, total_error_loss, run_model, evaluate_model, test_model, print_column_variance, add_pred_error, smooth_predictions_xy, prepare_LSTM_df\n",
    "from visualize_game import visualize_prediction_animation, visualize_game_animation\n",
    "from settings import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b196e924",
   "metadata": {},
   "source": [
    "## Define NAIVE models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1746338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NAIVE: Always predict that all players will stand still\n",
    "# The calculations are based on x, y\n",
    "def predict_two_seconds_naive_static(frames_df, seconds=None):\n",
    "    frames_df['x_future_pred'] = frames_df['x']\n",
    "    frames_df['y_future_pred'] = frames_df['y']\n",
    "\n",
    "# NAIVE: Always predict that all players will continue with the same velocity\n",
    "# The calculations are based on x, y, v_x, and v_y\n",
    "def predict_two_seconds_naive_velocity(frames_df, seconds=seconds_into_the_future):\n",
    "    frames_df['x_future_pred'] = frames_df['x'] + frames_df['v_x'] * seconds\n",
    "    frames_df['y_future_pred'] = frames_df['y'] + frames_df['v_y'] * seconds\n",
    "\n",
    "    # Clip values to stay on the pitch\n",
    "    frames_df['x_future_pred'] = frames_df['x_future_pred'].clip(lower=0, upper=pitch_length)\n",
    "    frames_df['y_future_pred'] = frames_df['y_future_pred'].clip(lower=0, upper=pitch_width)\n",
    "\n",
    "    # Smooth the predicted coordinates\n",
    "    # smooth_predictions_xy(frames_df, alpha=0.95)\n",
    "\n",
    "# NAIVE: Always predict that all players will continue with the same velocity and acceleration\n",
    "# The calculations are based on x, y, v_x, v_y, a_x, and a_y\n",
    "def predict_two_seconds_naive_acceleration(frames_df, seconds=seconds_into_the_future):\n",
    "    # Calculate future positions using kinematic equationsnaive_\n",
    "    frames_df['x_future_pred'] = frames_df['x'] + frames_df['v_x'] * seconds + 0.5 * frames_df['a_x'] * (seconds ** 2)\n",
    "    frames_df['y_future_pred'] = frames_df['y'] + frames_df['v_y'] * seconds + 0.5 * frames_df['a_y'] * (seconds ** 2)\n",
    "\n",
    "    # Clip values to stay on the pitch\n",
    "    frames_df['x_future_pred'] = frames_df['x_future_pred'].clip(lower=0, upper=pitch_length)\n",
    "    frames_df['y_future_pred'] = frames_df['y_future_pred'].clip(lower=0, upper=pitch_width)\n",
    "\n",
    "    # Smooth the predicted coordinates\n",
    "    # smooth_predictions_xy(frames_df, alpha=0.95)\n",
    "\n",
    "# Define the prediction functions (models) you want to test\n",
    "prediction_functions = {\n",
    "    \"Naive Static\": predict_two_seconds_naive_static,\n",
    "    \"Naive Velocity\": predict_two_seconds_naive_velocity,\n",
    "    \"Naive Acceleration\": predict_two_seconds_naive_acceleration\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f24a32",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fca989a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find a frame with approximatly the same error as the average_pred_error, with an interval\n",
    "def find_frame_with_average_error(frames_df, average_pred_error, error_margin):\n",
    "    # For all frames\n",
    "    frames = frames_df['frame'].unique()\n",
    "    for frame in frames:\n",
    "        current_error = frames_df[frames_df['frame'] == frame]['pred_error'].mean()\n",
    "        # If the current error is within the error_margin,\n",
    "        if (current_error >= average_pred_error - error_margin) and (current_error <= average_pred_error + error_margin):\n",
    "            # Return the result\n",
    "            return frame\n",
    "\n",
    "    # If no frame was found\n",
    "    print(f\"No frame found within the error margin of {error_margin}\")\n",
    "    return None\n",
    "\n",
    "# Use a naive model to make predictions on a set of games, and calculate the error\n",
    "def predict_and_evaluate_naive_model(naive_model_name, test_df, seconds=seconds_into_the_future):\n",
    "    # Find the prediction function for the naive model\n",
    "    naive_model = prediction_functions[naive_model_name]\n",
    "\n",
    "    # Use the custom function to make the predictions\n",
    "    naive_model(test_df, seconds)\n",
    "\n",
    "    # Calculate error\n",
    "    error = total_error_loss(test_df)\n",
    "\n",
    "    return test_df, error\n",
    "\n",
    "# Visualize model prediction\n",
    "def predict_and_visualize(match_id, model_name, start_frame, end_frame, image_frame=None):\n",
    "    # Load game\n",
    "    frames_df = load_processed_frames(match_id=match_id)[0]\n",
    "    frames_df = frames_df[(frames_df['frame'] > start_frame - seconds_into_the_future*FPS) & (frames_df['frame'] <= end_frame)].copy()\n",
    "\n",
    "    if 'Naive' in model_name:\n",
    "        # Run naive model\n",
    "        frames_df, _ = predict_and_evaluate_naive_model(model_name, frames_df)\n",
    "    else:\n",
    "        # Run model for NN/ LSTM model\n",
    "        frames_df = run_model([], model_name, downsampling_factor_testing=1, preloaded_frames_df=frames_df)\n",
    "        frames_df = add_pred_error(frames_df)\n",
    "    \n",
    "    # Flip the 'y' coordinate\n",
    "    frames_df['y'] = round(pitch_width - frames_df['y'], 2)\n",
    "    frames_df['y_future'] = round(pitch_width - frames_df['y_future'], 2)\n",
    "    frames_df['y_future_pred'] = round(pitch_width - frames_df['y_future_pred'], 2)\n",
    "\n",
    "    # Visualize predictions with an animation\n",
    "    visualize_prediction_animation(frames_df, start_frame, end_frame, model_name, image_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4863d61c",
   "metadata": {},
   "source": [
    "## Evaulate NAIVE models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5311d048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test frames\n",
    "_, test_ids, _ = split_match_ids(560)\n",
    "\n",
    "unchanged_cols = ['team_name', 'jersey_number', 'player', 'x', 'y', 'frame', 'minute', 'second', 'period',\n",
    "    'v_x', 'v_y', 'a_x', 'a_y', 'ball_in_motion', 'distance_to_ball', 'angle_to_ball', 'offside',\n",
    "    'distance_to_onside', 'nationality', 'height', 'weight', 'acc', 'pac', 'sta',\n",
    "    'position', 'specific_position', 'tiredness', 'tiredness_short',\n",
    "    'x_future_25', 'y_future_25', 'x_future_50', 'y_future_50', 'x_future_75', 'y_future_75',\n",
    "    'x_future', 'y_future', 'match_id', 'v_x_avg', 'v_y_avg', 'age']\n",
    "\n",
    "# Load DataFrame with the given parameters\n",
    "sequence_length = 10\n",
    "downsampling_factor_testing = 5\n",
    "positions = ['Attacking Midfielder', 'Central Midfielder', 'Centre-Back', 'Defensive Midfielder', 'Forward', 'Full-Back', 'Goalkeeper', 'Wide Midfielder', 'Winger']\n",
    "test_df = prepare_LSTM_df(test_ids, pd.DataFrame(), [], [], unchanged_cols, sequence_length, positions, downsampling_factor_testing)\n",
    "\n",
    "# Clean up temporary columns\n",
    "test_df = test_df.drop(columns=['y_values', 'sequential_numerical_data'])\n",
    "\n",
    "# Only keep rows that can be sequentialized\n",
    "test_df = test_df[test_df['can_be_sequentialized']]\n",
    "\n",
    "# Set pred_error to None for rows where 'team_name' is 'ball'\n",
    "test_df.loc[test_df['team_name'] == 'ball', 'pred_error'] = None\n",
    "\n",
    "# Set pred_error to None for frames where the ball is not in motion\n",
    "test_df.loc[test_df['ball_in_motion'] != True, 'pred_error'] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5e72fe",
   "metadata": {},
   "source": [
    "### Evaulate the NAIVE models with different parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ca1231f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Seconds</th>\n",
       "      <th>Naive Static</th>\n",
       "      <th>Naive Velocity</th>\n",
       "      <th>Naive Acceleration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2.16</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.15</td>\n",
       "      <td>2.12</td>\n",
       "      <td>2.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>5.94</td>\n",
       "      <td>3.94</td>\n",
       "      <td>3.89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Seconds  Naive Static  Naive Velocity  Naive Acceleration\n",
       "0        1          2.16            0.70                0.69\n",
       "1        2          4.15            2.12                2.09\n",
       "2        3          5.94            3.94                3.89"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a list with how many seconds into the future we want to predict\n",
    "list_of_seconds = [1, 2, 3]\n",
    "\n",
    "# Initialize an empty list to store the results\n",
    "results = []\n",
    "\n",
    "# Loop through each combination\n",
    "for seconds in list_of_seconds:\n",
    "    # Set 'x_future' and 'y_future'\n",
    "    test_df['x_future'] = test_df[f'x_future_{seconds*FPS}']\n",
    "    test_df['y_future'] = test_df[f'y_future_{seconds*FPS}']\n",
    "    \n",
    "    # Add the combination of parameters\n",
    "    result = {\"Seconds\": seconds}\n",
    "\n",
    "    # Loop through each prediction function (model)\n",
    "    for model_name, predict_function in prediction_functions.items():\n",
    "        # Calculate error for the current prediction function (model)\n",
    "        _, error = predict_and_evaluate_naive_model(model_name, test_df, seconds)\n",
    "        result[model_name] = round(error, 2)\n",
    "    \n",
    "    # Append the results to the list\n",
    "    results.append(result)\n",
    "\n",
    "# Go back to previous values\n",
    "test_df['x_future'] = test_df[f'x_future_{seconds_into_the_future*FPS}']\n",
    "test_df['y_future'] = test_df[f'y_future_{seconds_into_the_future*FPS}']\n",
    "\n",
    "# Create a DataFrame from the list of results\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c9356f",
   "metadata": {},
   "source": [
    "### Naive models position analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8dad0df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Naive Static</th>\n",
       "      <th>Naive Velocity</th>\n",
       "      <th>Naive Acceleration</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>position</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Attacking Midfielder</th>\n",
       "      <td>4.59</td>\n",
       "      <td>2.29</td>\n",
       "      <td>2.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Central Midfielder</th>\n",
       "      <td>4.72</td>\n",
       "      <td>2.35</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Centre-Back</th>\n",
       "      <td>4.02</td>\n",
       "      <td>2.09</td>\n",
       "      <td>2.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Defensive Midfielder</th>\n",
       "      <td>4.62</td>\n",
       "      <td>2.33</td>\n",
       "      <td>2.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Forward</th>\n",
       "      <td>4.32</td>\n",
       "      <td>2.20</td>\n",
       "      <td>2.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Full-Back</th>\n",
       "      <td>4.29</td>\n",
       "      <td>2.17</td>\n",
       "      <td>2.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Goalkeeper</th>\n",
       "      <td>1.81</td>\n",
       "      <td>1.14</td>\n",
       "      <td>1.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wide Midfielder</th>\n",
       "      <td>4.55</td>\n",
       "      <td>2.31</td>\n",
       "      <td>2.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Winger</th>\n",
       "      <td>4.49</td>\n",
       "      <td>2.24</td>\n",
       "      <td>2.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>4.15</td>\n",
       "      <td>2.12</td>\n",
       "      <td>2.09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Naive Static  Naive Velocity  Naive Acceleration\n",
       "position                                                              \n",
       "Attacking Midfielder          4.59            2.29                2.26\n",
       "Central Midfielder            4.72            2.35                2.31\n",
       "Centre-Back                   4.02            2.09                2.06\n",
       "Defensive Midfielder          4.62            2.33                2.29\n",
       "Forward                       4.32            2.20                2.17\n",
       "Full-Back                     4.29            2.17                2.14\n",
       "Goalkeeper                    1.81            1.14                1.14\n",
       "Wide Midfielder               4.55            2.31                2.28\n",
       "Winger                        4.49            2.24                2.21\n",
       "Total                         4.15            2.12                2.09"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Column to analyze\n",
    "column_to_analyze = 'position'  # Removed the list brackets assuming it's a single column\n",
    "\n",
    "# Create an empty DataFrame to store the results\n",
    "results_df = pd.DataFrame()\n",
    "\n",
    "# Create an empty list to store the total prediction error\n",
    "total_error = []\n",
    "\n",
    "# Loop through each prediction function (model)\n",
    "for model_name in prediction_functions.keys():\n",
    "    # Calculate error for the current prediction function (model)\n",
    "    test_df, error = predict_and_evaluate_naive_model(model_name, test_df, 2)\n",
    "\n",
    "    # Group by 'column_to_analyze' and calculate the average 'pred_error'\n",
    "    column_variance_df = test_df.groupby(column_to_analyze)['pred_error'].mean().reset_index()\n",
    "\n",
    "    # Round to 2 decimal places\n",
    "    column_variance_df['pred_error'] = round(column_variance_df['pred_error'], 2)\n",
    "\n",
    "    # Sort by 'column_to_analyze' in ascending order\n",
    "    column_variance_df = column_variance_df.sort_values(by=column_to_analyze, ascending=True)\n",
    "\n",
    "    # Set model_name as the index for easy indexing\n",
    "    column_variance_df.set_index(column_to_analyze, inplace=True)\n",
    "\n",
    "    # Add column_variance_df to results_df using iloc\n",
    "    results_df[model_name] = column_variance_df['pred_error']\n",
    "\n",
    "    # Append error for the current model to total_error list\n",
    "    total_error.append(round(error, 2))\n",
    "\n",
    "# Add the 'Total' row to the results_df\n",
    "results_df.loc['Total'] = total_error\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad99574",
   "metadata": {},
   "source": [
    "## Evaluate NN models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "519f12f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-01 12:53:21.719865: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 31133 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:8a:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-01 13:04:29.659471: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "658495/658495 [==============================] - 655s 992us/step\n",
      "Error: 1.634 m\n",
      "Testing results added to the file.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "658495/658495 [==============================] - 658s 999us/step\n",
      "Error: 1.646 m\n",
      "Testing results added to the file.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "658495/658495 [==============================] - 657s 997us/step\n",
      "Error: 1.628 m\n",
      "Testing results added to the file.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "658495/658495 [==============================] - 651s 988us/step\n",
      "Error: 1.753 m\n",
      "Testing results added to the file.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "658495/658495 [==============================] - 655s 994us/step\n",
      "Error: 1.77 m\n",
      "Testing results added to the file.\n"
     ]
    }
   ],
   "source": [
    "# model_name = \"NN_Model\"\n",
    "test_model(\"LSTM_model_v3\", downsampling_factor_testing=5)\n",
    "test_model(\"LSTM_model_v4\", downsampling_factor_testing=5)\n",
    "test_model(\"LSTM_model_v5\", downsampling_factor_testing=5)\n",
    "test_model(\"LSTM_model_v6\", downsampling_factor_testing=5)\n",
    "test_model(\"LSTM_model_v7\", downsampling_factor_testing=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fc685b",
   "metadata": {},
   "source": [
    "### Print Column Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045db0e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "True\n",
      "True\n",
      "658495/658495 [==============================] - 497s 755us/step\n",
      "True\n",
      "Average error: 1.763\n",
      "Average pred error per position:\n",
      "   position  pred_error\n",
      "0         0        1.89\n",
      "1         1        1.92\n",
      "2         2        1.75\n",
      "3         3        1.90\n",
      "4         4        1.82\n",
      "5         5        1.83\n",
      "6         6        0.96\n",
      "7         7        1.92\n",
      "8         8        1.86\n"
     ]
    }
   ],
   "source": [
    "# Load test frames\n",
    "_, test_ids, _ = split_match_ids(560)\n",
    "\n",
    "# Print column variance for 'position' with preloaded frames\n",
    "print_column_variance([], \"NN_model_v1\", 'position', preloaded_frames_df=test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485e8e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print column variance for 'position' with test_ids\n",
    "print_column_variance(test_ids, \"LSTM_model_v1\", 'position')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7e68f3",
   "metadata": {},
   "source": [
    "## Visualize All Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19f0efbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-02 11:35:07.256411: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 31133 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:8a:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220/220 [==============================] - 1s 677us/step\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-02 11:35:52.936290: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214/214 [==============================] - 1s 974us/step\n"
     ]
    }
   ],
   "source": [
    "# Create an animation for the sequence (without predictions)\n",
    "test_id = 'a641b1a0-0603-4a57-81e4-2cbc188ab05c'\n",
    "start_frame = 94450\n",
    "end_frame = 94720\n",
    "image_frame = 94537\n",
    "offset_2_sec = 2*25\n",
    "\n",
    "# Visualize the sequence\n",
    "frames_df = load_processed_frames(match_id=test_id)[0]\n",
    "frames_df['y'] = round(pitch_width - frames_df['y'], 2)\n",
    "visualize_game_animation(frames_df, start_frame + offset_2_sec, end_frame + offset_2_sec, image_frame + offset_2_sec)\n",
    "\n",
    "# Visualize predictions error for any naive model\n",
    "predict_and_visualize(test_id, 'Naive Static', start_frame, end_frame, image_frame)\n",
    "predict_and_visualize(test_id, 'Naive Velocity', start_frame, end_frame, image_frame)\n",
    "predict_and_visualize(test_id, 'Naive Acceleration', start_frame, end_frame, image_frame)\n",
    "predict_and_visualize(test_id, 'NN_Model', start_frame, end_frame, image_frame)\n",
    "predict_and_visualize(test_id, 'LSTM_Model', start_frame, end_frame, image_frame)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "My Python",
   "language": "python",
   "name": "my_python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
