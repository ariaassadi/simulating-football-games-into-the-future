{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c078666b",
   "metadata": {},
   "source": [
    "# Notebook for training predictive models\n",
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa43b454-7b17-42fc-be8a-de1770ba3a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-08 18:10:31.699915: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Embedding, Flatten, Dense, Concatenate\n",
    "from tensorflow.keras.models import load_model as keras_load_model\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.pipeline import Pipeline\n",
    "from keras.models import Sequential\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import glob\n",
    "import os\n",
    "\n",
    "from settings import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06d4855",
   "metadata": {},
   "source": [
    "### Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f65b211e",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = ['x', 'y', 'v_x', 'v_y', 'a_x', 'a_y']\n",
    "categorical_cols = ['team_direction', 'role']\n",
    "y_cols = ['x_future', 'y_future']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59f6979",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ca3207c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the games into train, test, and validtion. This way, each game will be treated seperatly\n",
    "def split_match_ids(match_ids, train_size=0.7, test_size=0.1, val_size=0.2, random_state=42):\n",
    "    # Calculate the remaining size after the test and validation sizes are removed\n",
    "    remaining_size = 1.0 - train_size\n",
    "\n",
    "    # Check if the sum of sizes is not equal to 1\n",
    "    if remaining_size < 0 or abs(train_size + test_size + val_size - 1.0) > 1e-6:\n",
    "        raise ValueError(\"The sum of train_size, test_size, and val_size must be equal to 1.\")\n",
    "    \n",
    "    # Split the match IDs into train, test, and validation sets\n",
    "    train_ids, remaining_ids = train_test_split(match_ids, train_size=train_size, random_state=random_state)\n",
    "    val_ids, test_ids = train_test_split(remaining_ids, test_size=test_size / remaining_size, random_state=random_state)\n",
    "    \n",
    "    return train_ids, test_ids, val_ids\n",
    "    \n",
    "# Helper function for NN with embeddings models\n",
    "def adjust_for_embeddings(X_data_df):\n",
    "    # Split the DataFrame into numerical and categorical components\n",
    "    X_numerical = X_data_df.drop(columns=categorical_cols)\n",
    "    X_categorical = {col: X_data_df[col].values for col in categorical_cols}\n",
    "    \n",
    "    return X_numerical, X_categorical\n",
    "\n",
    "# Get the latest model, for a given 'model_name', based on the number of current models\n",
    "def get_latest_model_filename(model_name):\n",
    "    models_folder = \"./models/\"\n",
    "\n",
    "    # Get a list of existing model filenames in the models folder\n",
    "    existing_models = [filename for filename in os.listdir(models_folder) if filename.startswith(model_name) and filename.endswith('.h5')]\n",
    "\n",
    "    # Sort the existing models by name\n",
    "    existing_models.sort()\n",
    "\n",
    "    if existing_models:\n",
    "        # Get the latest model filename\n",
    "        latest_model_filename = existing_models[-1]\n",
    "    else:\n",
    "        ValueError(f\"No existing model available with the given name: models/{model_name}_XX.h5\")\n",
    "\n",
    "    return os.path.join(models_folder, latest_model_filename)\n",
    "\n",
    "# Load a tf model\n",
    "def load_model(model_path):\n",
    "    try:\n",
    "        # Load the model using Keras's load_model function\n",
    "        return keras_load_model(model_path)\n",
    "    \n",
    "    except ValueError as e:\n",
    "        print(e)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da023dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data before training\n",
    "def prepare_data(frames_dfs):\n",
    "\n",
    "    # Initialize lists to store features and labels\n",
    "    X_data = []\n",
    "    y_data = []\n",
    "\n",
    "    # For each game\n",
    "    for frames_df in frames_dfs:\n",
    "        # Fill NaN values with zeros for numerical columns\n",
    "        frames_df[numerical_cols] = frames_df[numerical_cols].fillna(0)\n",
    "\n",
    "        # Drop rows with NaN values in the labels (y)\n",
    "        frames_df.dropna(subset=y_cols, inplace=True)\n",
    "\n",
    "        # Extract features and labels from group\n",
    "        X = frames_df[numerical_cols + categorical_cols]\n",
    "        y = frames_df[y_cols]\n",
    "\n",
    "        # Append the data\n",
    "        X_data.append(X)\n",
    "        y_data.append(y)\n",
    "\n",
    "    # Concatenate the lists to create the final feature and label DataFrame\n",
    "    X_data_df = pd.concat(X_data)\n",
    "    y_data_df = pd.concat(y_data)\n",
    "\n",
    "    # Apply label encoding to categorical variables\n",
    "    for col in categorical_cols:\n",
    "        label_encoder = LabelEncoder()\n",
    "        X_data_df[col] = label_encoder.fit_transform(X_data_df[col])\n",
    "\n",
    "    # Define column transformer for standard scaling numerical features\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', StandardScaler(), numerical_cols)\n",
    "        ],\n",
    "        remainder='passthrough'\n",
    "    )\n",
    "\n",
    "    # Create pipeline for preprocessing and apply it to X_data\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor)])\n",
    "    X_data_scaled = pipeline.fit_transform(X_data_df)\n",
    "\n",
    "    # Retrieve the transformed feature names from ColumnTransformer\n",
    "    transformed_column_names = numerical_cols + categorical_cols\n",
    "\n",
    "    # Create a DataFrame from the preprocessed feature data\n",
    "    X_data_scaled_df = pd.DataFrame(X_data_scaled, columns=transformed_column_names)\n",
    "\n",
    "    # Convert categorical columns to int\n",
    "    X_data_scaled_df[categorical_cols] = X_data_scaled_df[categorical_cols].astype('int8')\n",
    "\n",
    "    return X_data_scaled_df, y_data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ef43b7",
   "metadata": {},
   "source": [
    "### Load frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98345c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the processed/frames\n",
    "def load_all_processed_frames():\n",
    "    # Create DataFrame for storing all frames\n",
    "    frames_dfs = []\n",
    "    # Load frames_df\n",
    "    for selected_season in seasons:\n",
    "        for selected_competition in competitions:\n",
    "            # Define paths\n",
    "            DATA_FOLDER_PROCESSED = f\"{DATA_LOCAL_FOLDER}/data/{selected_season}/{selected_competition}/processed\"\n",
    "\n",
    "            # Find all frames parquet files\n",
    "            match_paths = glob.glob(os.path.join(DATA_FOLDER_PROCESSED, \"*.parquet\"))\n",
    "\n",
    "            # Extract IDs without the \".parquet\" extension\n",
    "            match_ids = [os.path.splitext(os.path.basename(path))[0] for path in match_paths][0:10]\n",
    "            # match_ids = ['49e6bfdf-abf3-499d-b60e-cf727c6523c1']\n",
    "\n",
    "            # For all matches\n",
    "            for match_id in match_ids:\n",
    "                # Convert parquet file to a DataFrame\n",
    "                file_path_match = f\"{DATA_FOLDER_PROCESSED}/{match_id}.parquet\"\n",
    "                frames_df = pd.read_parquet(file_path_match)\n",
    "                \n",
    "                # Append the DataFrame to frames_dfs\n",
    "                frames_dfs.append(frames_df)\n",
    "\n",
    "    return frames_dfs\n",
    "\n",
    "# Load every frames_df to a list\n",
    "frames_dfs = load_all_processed_frames()\n",
    "\n",
    "# Create an internal match_id for each game\n",
    "match_ids = range(len(frames_dfs))\n",
    "\n",
    "# Split match IDs into train, test, and validation sets\n",
    "train_ids, test_ids, val_ids = split_match_ids(match_ids=match_ids)\n",
    "\n",
    "# Select frames data for training, testing, and validation\n",
    "train_frames_dfs = [frames_dfs[i] for i in train_ids]\n",
    "test_frames_dfs = [frames_dfs[i] for i in test_ids]\n",
    "val_frames_dfs = [frames_dfs[i] for i in val_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8a22661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the test data\n",
    "X_test, y_test = prepare_data(test_frames_dfs)\n",
    "\n",
    "# Adjust for embeddings\n",
    "X_test_numerical, X_test_categorical = adjust_for_embeddings(X_test)\n",
    "\n",
    "# Construct input data suitable for the embedding layers\n",
    "X_test_input = [X_test_categorical['team_direction'].reshape(-1, 1), X_test_categorical['role'].reshape(-1, 1), X_test_numerical]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b196e924",
   "metadata": {},
   "source": [
    "### Load predictive models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1746338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NAIVE: Always predict that all players will stand still\n",
    "# The calculations are based on x, y\n",
    "def predict_two_seconds_naive_static(frames_df):\n",
    "    frames_df['x_future_pred'] = frames_df['x']\n",
    "    frames_df['y_future_pred'] = frames_df['y']\n",
    "\n",
    "# NAIVE: Always predict that all players will continue with the same velocity\n",
    "# The calculations are based on x, y, v_x, and v_y\n",
    "def predict_two_seconds_naive_velocity(frames_df):\n",
    "    frames_df['x_future_pred'] = frames_df['x'] + frames_df['v_x'] * seconds_into_the_future\n",
    "    frames_df['y_future_pred'] = frames_df['y'] + frames_df['v_y'] * seconds_into_the_future\n",
    "\n",
    "# NAIVE: Always predict that all players will continue with the same velocity and acceleration\n",
    "# The calculations are based on x, y, v_x, v_y, a_x, and a_y\n",
    "def predict_two_seconds_naive_acceleration(frames_df):\n",
    "    # Calculate future positions using kinematic equations\n",
    "    frames_df['x_future_pred'] = frames_df['x'] + frames_df['v_x'] * seconds_into_the_future + 0.5 * frames_df['a_x'] * (seconds_into_the_future ** 2)\n",
    "    frames_df['y_future_pred'] = frames_df['y'] + frames_df['v_y'] * seconds_into_the_future + 0.5 * frames_df['a_y'] * (seconds_into_the_future ** 2)\n",
    "\n",
    "# Make a prediction with a LSTM neural network model\n",
    "def predict_two_seconds_LSTM(frames_df):\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7d9f556f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a prediction with a neural network model\n",
    "def predict_two_seconds_NN_model(frames_dfs, model, X_data):\n",
    "    # Concatenate the frames DataFrames into a single large DataFrame\n",
    "    frames_concatenated_df = pd.concat(frames_dfs, ignore_index=True)\n",
    "\n",
    "    # Make predictions using the loaded tf model\n",
    "    predictions = model.predict(X_data)\n",
    "\n",
    "    # Extract the predicted values\n",
    "    x_future_pred = predictions[:, 0]\n",
    "    y_future_pred = predictions[:, 1]\n",
    "\n",
    "    # Add the predicted values to 'frames_concatenated_df'\n",
    "    frames_concatenated_df['x_future_pred'] = x_future_pred\n",
    "    frames_concatenated_df['y_future_pred'] = y_future_pred\n",
    "\n",
    "    return frames_concatenated_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f24a32",
   "metadata": {},
   "source": [
    "### Functions for calculating error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1fca989a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column for distance wrongly predicted (in metres) for each object\n",
    "def add_pred_error(frames_df):\n",
    "    # Create a vector with the Eculidian distance between the true position and the predicted position\n",
    "    frames_df['pred_error'] = round(((frames_df['x_future_pred'] - frames_df['x_future'])**2 + (frames_df['y_future_pred'] - frames_df['y_future'])**2)**0.5, 2)\n",
    "    \n",
    "# Add a column for distance wrongly predicted (in metres) for each object. Also return average_pred_error\n",
    "def total_error_loss(frames_df, include_ball=False, ball_has_to_be_in_motion=True):\n",
    "    # Add 'pred_error' column if empty\n",
    "    if 'pred_error' not in frames_df:\n",
    "        add_pred_error(frames_df)\n",
    "    \n",
    "    # Create a new column to store modified pred_error values\n",
    "    frames_df['pred_error_tmp'] = frames_df['pred_error']\n",
    "    \n",
    "    # If specified, set pred_error to None for frames where the ball is not in motion\n",
    "    if ball_has_to_be_in_motion:\n",
    "        frames_df.loc[frames_df[\"ball_in_motion\"] != True, 'pred_error_tmp'] = None\n",
    "\n",
    "    # If specified, set pred_error to None for rows where 'team' is 'ball'\n",
    "    if not include_ball:\n",
    "        frames_df.loc[frames_df['team'] == 'ball', 'pred_error_tmp'] = None\n",
    "\n",
    "    # Calculate average pred_error_tmp, excluding rows where pred_error is None\n",
    "    average_pred_error = frames_df['pred_error_tmp'].mean()\n",
    "\n",
    "    # Drop the temporary column\n",
    "    frames_df.drop(columns=['pred_error_tmp'], inplace=True)\n",
    "\n",
    "    return round(average_pred_error, 2)\n",
    "\n",
    "# Calculate the average error for a list of games\n",
    "def calculate_average_error(frames_dfs, predict_function, include_ball, ball_has_to_be_in_motion):\n",
    "    # Predict the future positions\n",
    "    [predict_function(frames_df) for frames_df in frames_dfs]\n",
    "    [add_pred_error(frames_df) for frames_df in frames_dfs]\n",
    "\n",
    "    # Concatenate all frames dataframes into a single dataframe\n",
    "    concatted_frames_df = pd.concat(frames_dfs)    \n",
    "    \n",
    "    # Calculate the total error loss\n",
    "    error = total_error_loss(concatted_frames_df, include_ball, ball_has_to_be_in_motion)\n",
    "    \n",
    "    return error\n",
    "\n",
    "# Find a frame with approximatly the same error as the average_pred_error, with an interval\n",
    "def find_frame_with_average_error(frames_df, average_pred_error, error_margin):\n",
    "    # For all frames\n",
    "    frames = frames_df['frame'].unique()\n",
    "    for frame in frames:\n",
    "        current_error = frames_df[frames_df['frame'] == frame]['pred_error'].mean()\n",
    "        # If the current error is within the error_margin,\n",
    "        if (current_error >= average_pred_error - error_margin) and (current_error <= average_pred_error + error_margin):\n",
    "            # Return the result\n",
    "            return frame\n",
    "\n",
    "    # If no frame was found\n",
    "    print(f\"No frame found within the error margin of {error_margin}\")\n",
    "    return None\n",
    "\n",
    "# Use a model to make predictions on a set of games, and calculate the error\n",
    "def predict_and_evaluate(model, X_data, frames_dfs, include_ball=False, ball_has_to_be_in_motion=True):\n",
    "    # Concatenate the frames DataFrames into a single large DataFrame\n",
    "    frames_concatenated_df = pd.concat(frames_dfs, ignore_index=True)\n",
    "\n",
    "    # If model is a tf model\n",
    "    if isinstance(model, tf.keras.Model):\n",
    "        # Make predictions using the loaded tf model\n",
    "        predictions = model.predict(X_data)\n",
    "\n",
    "        # Extract the predicted values\n",
    "        x_future_pred = predictions[:, 0]\n",
    "        y_future_pred = predictions[:, 1]\n",
    "\n",
    "        # Add the predicted values to 'frames_concatenated_df'\n",
    "        frames_concatenated_df['x_future_pred'] = x_future_pred\n",
    "        frames_concatenated_df['y_future_pred'] = y_future_pred\n",
    "        model(frames_concatenated_df, )\n",
    "\n",
    "    else:\n",
    "        # Use the custom function to make the predictions\n",
    "        model(frames_concatenated_df)\n",
    "\n",
    "    # Calculate error\n",
    "    error = total_error_loss(frames_concatenated_df, include_ball, ball_has_to_be_in_motion)\n",
    "\n",
    "    return error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4863d61c",
   "metadata": {},
   "source": [
    "## Evaulate models\n",
    "### Visualize prediction errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75155a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test model 1\n",
    "# error_naive_static = calculate_average_error(test_frames_dfs, predict_two_seconds_naive_static, include_ball=False, ball_has_to_be_in_motion=True)\n",
    "# print(f\"Model error naive static: {error_naive_static}\")\n",
    "\n",
    "# # Test model 2\n",
    "# error_naive_velocity = calculate_average_error(test_frames_dfs, predict_two_seconds_naive_velocity, include_ball=False, ball_has_to_be_in_motion=True)\n",
    "# print(f\"Model error naive velocity: {error_naive_velocity}\")\n",
    "\n",
    "# # Visualize one frame with average error for the first model, together with the corresponding frame for the second model\n",
    "# frames_df = test_frames_dfs[0]\n",
    "# frame_with_average_error = find_frame_with_average_error(frames_df, error_naive_static, error_margin=0.1)\n",
    "# visualize_frame_prediction(frames_df, frame_with_average_error, \"naive_static\")\n",
    "# visualize_frame_prediction(frames_df, frame_with_average_error, \"naive_velocity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5e72fe",
   "metadata": {},
   "source": [
    "### Evaulate the NAIVE models with different parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ca1231f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Include Ball</th>\n",
       "      <th>Ball in Motion</th>\n",
       "      <th>Naive Static</th>\n",
       "      <th>Naive Velocity</th>\n",
       "      <th>Naive Acceleration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>4.45</td>\n",
       "      <td>2.74</td>\n",
       "      <td>2.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>3.97</td>\n",
       "      <td>2.40</td>\n",
       "      <td>2.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>4.07</td>\n",
       "      <td>2.16</td>\n",
       "      <td>2.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3.69</td>\n",
       "      <td>1.99</td>\n",
       "      <td>2.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Include Ball  Ball in Motion  Naive Static  Naive Velocity  \\\n",
       "0          True            True          4.45            2.74   \n",
       "1          True           False          3.97            2.40   \n",
       "2         False            True          4.07            2.16   \n",
       "3         False           False          3.69            1.99   \n",
       "\n",
       "   Naive Acceleration  \n",
       "0                2.89  \n",
       "1                2.55  \n",
       "2                2.25  \n",
       "3                2.10  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the prediction functions (models) you want to test\n",
    "prediction_functions = {\n",
    "    \"Naive Static\": predict_two_seconds_naive_static,\n",
    "    \"Naive Velocity\": predict_two_seconds_naive_velocity,\n",
    "    \"Naive Acceleration\": predict_two_seconds_naive_acceleration\n",
    "}\n",
    "\n",
    "# Define the combinations of include_ball and ball_has_to_be_in_motion\n",
    "combinations = [(True, True), (True, False), (False, True), (False, False)]\n",
    "\n",
    "# Initialize an empty list to store the results\n",
    "results = []\n",
    "\n",
    "# Loop through each combination\n",
    "for include_ball, ball_has_to_be_in_motion in combinations:\n",
    "    # Add the combination of parameters\n",
    "    result = {\"Include Ball\": include_ball, \"Ball in Motion\": ball_has_to_be_in_motion}\n",
    "    # Loop through each prediction function (model)\n",
    "    for model_name, predict_function in prediction_functions.items():\n",
    "        # Calculate error for the current prediction function (model)\n",
    "        error = predict_and_evaluate(predict_function, test_frames_dfs, include_ball, ball_has_to_be_in_motion)\n",
    "        result[model_name] = error\n",
    "    \n",
    "    # Append the results to the list\n",
    "    results.append(result)\n",
    "\n",
    "# Create a DataFrame from the list of results\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "29080973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99538/99538 [==============================] - 100s 1ms/step\n",
      "99538/99538 [==============================] - 148s 1ms/step\n",
      "   Include Ball  Ball in Motion  NN_model_3  NN_embedding_model_1\n",
      "0          True            True        5.42                  5.51\n",
      "1          True           False        5.26                  5.35\n",
      "2         False            True        5.08                  5.16\n",
      "3         False           False        5.02                  5.10\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  # Ensure pandas is imported\n",
    "\n",
    "# Define the prediction functions (models) you want to test\n",
    "NN_prediction_functions = {\n",
    "    \"NN_model_3\": {\"model\": load_model(\"models/NN_model_3.h5\"), \"X_data\": X_test[numerical_cols]},\n",
    "    \"NN_embedding_model_1\": {\"model\": load_model(\"models/NN_embedding_model_1.h5\"), \"X_data\": X_test_input}\n",
    "}\n",
    "\n",
    "# Define the combinations of include_ball and ball_has_to_be_in_motion\n",
    "combinations = [(True, True), (True, False), (False, True), (False, False)]\n",
    "\n",
    "# Initialize an empty list to store the results\n",
    "results = []\n",
    "\n",
    "# Pre-calculate predictions for each model only once\n",
    "predictions_dict = {}\n",
    "for model_name, model_info in NN_prediction_functions.items():\n",
    "    # Make predictions for the current model and store them in the dictionary\n",
    "    predictions_dict[model_name] = predict_two_seconds_NN_model(test_frames_dfs, model_info[\"model\"], model_info[\"X_data\"])\n",
    "\n",
    "# Loop through each combination\n",
    "for include_ball, ball_has_to_be_in_motion in combinations:\n",
    "    # Initialize a result dictionary for the current combination\n",
    "    result = {\"Include Ball\": include_ball, \"Ball in Motion\": ball_has_to_be_in_motion}\n",
    "    \n",
    "    # Calculate and store the error for each model within the same combination\n",
    "    for model_name in NN_prediction_functions.keys():\n",
    "        # Retrieve the pre-calculated predictions for the current model\n",
    "        test_with_predictions_df = predictions_dict[model_name]\n",
    "        # Calculate error\n",
    "        error = total_error_loss(test_with_predictions_df, include_ball, ball_has_to_be_in_motion)\n",
    "        # Store the error in the result dictionary\n",
    "        result[model_name] = error\n",
    "    \n",
    "    # Append the result to the results list\n",
    "    results.append(result)\n",
    "\n",
    "# Create a DataFrame from the list of results\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "My Python",
   "language": "python",
   "name": "my_python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
